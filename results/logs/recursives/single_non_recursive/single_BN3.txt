

CONFIGURATION
-------------
+-----------------+------------------------+
| Python Version  |         3.6.5          |
+-----------------+------------------------+
| PyTorch Version |         1.0.0          |
+-----------------+------------------------+
|     Device      |  Tesla V100-SXM2-16GB  |
+-----------------+------------------------+
|      Cores      |           8            |
+-----------------+------------------------+
|      GPUs       |           1            |
+-----------------+------------------------+
|  CUDNN Enabled  |          True          |
+-----------------+------------------------+
|   Single Net    |  Single_Non_Recursive  |
+-----------------+------------------------+
|  Ensemble Nets  | Ensemble_Non_Recursive |
+-----------------+------------------------+
|     Dataset     |        CIFAR10         |
+-----------------+------------------------+
|     Epochs      |          500           |
+-----------------+------------------------+
|   Batch Size    |          128           |
+-----------------+------------------------+
|   Initial LR    |         0.001          |
+-----------------+------------------------+
|  LR Schedules   |         [400]          |
+-----------------+------------------------+


DEFINITION OF PATHS
-------------------

[OK]: Paths Validated Successfully
Root path:  /home/ec2-user/Single_vs_Ensemble_of_NNs
Script path:  /home/ec2-user/Single_vs_Ensemble_of_NNs/scripts
Results path:  /home/ec2-user/Single_vs_Ensemble_of_NNs/results
DataFolder path:  /home/ec2-user/datasets
Models to save path:  /home/ec2-user/Single_vs_Ensemble_of_NNs/results/models/recursives/ensemble_recursives
Models to load path:  /home/ec2-user/Single_vs_Ensemble_of_NNs/results/models/recursives/ensemble_recursives/definitives


IMPORTING DATA
--------------
Files already downloaded and verified


LOADING MODELS
----------------
Regular net
Conv_Net(
  (act): ReLU()
  (d1): Dropout2d(p=0.1)
  (d2): Dropout2d(p=0.5)
  (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (V): Conv2d(3, 32, kernel_size=(8, 8), stride=(1, 1), padding=(3, 3))
  (P): MaxPool2d(kernel_size=4, stride=4, padding=2, dilation=1, ceil_mode=False)
  (W): ModuleList(
    (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (5): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (6): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (7): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (8): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (9): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (10): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (11): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (12): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (13): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (14): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (15): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  )
  (C): Linear(in_features=2048, out_features=10, bias=True)
)


		Parameters: 0.174762M
Non Recursive ConvNet
Conv_Net(
  (act): ReLU()
  (V): Conv2d(3, 32, kernel_size=(8, 8), stride=(1, 1), padding=(3, 3))
  (P): MaxPool2d(kernel_size=4, stride=4, padding=2, dilation=1, ceil_mode=False)
  (W): ModuleList(
    (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (5): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (6): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (7): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (8): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (9): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (10): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (11): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (12): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (13): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (14): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (15): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  )
  (C): Linear(in_features=2048, out_features=10, bias=True)
)


		Parameters: 0.174634M


TRAINING
--------
Current set up
[ALERT]: Path to results (this may overwrite /home/ec2-user/Single_vs_Ensemble_of_NNs/results
[ALERT]: Path to checkpoint (this may overwrite None
Do you want to continue? [Y/n]: [OK]: Starting Training of Recursive Ensemble Model

Starting Single Model Training...

 ** Time 15:1

 ** Train ** Epoch: [1/500] Iter: [391/195500] Loss: 1.914 Acc: 23.75%

 ** Valid ** Epoch: [1/500] Iter: [391/195500] Loss: 2.983 Acc: 22.97%

 ** Time 15:1

 ** Train ** Epoch: [2/500] Iter: [782/195500] Loss: 1.502 Acc: 51.25%

 ** Valid ** Epoch: [2/500] Iter: [782/195500] Loss: 2.894 Acc: 22.55%

 ** Time 15:1

 ** Train ** Epoch: [3/500] Iter: [1173/195500] Loss: 1.534 Acc: 33.75%

 ** Valid ** Epoch: [3/500] Iter: [1173/195500] Loss: 3.602 Acc: 21.84%

 ** Time 15:1

 ** Train ** Epoch: [4/500] Iter: [1564/195500] Loss: 1.501 Acc: 43.75%

 ** Valid ** Epoch: [4/500] Iter: [1564/195500] Loss: 3.752 Acc: 24.19%

 ** Time 15:1

 ** Train ** Epoch: [5/500] Iter: [1955/195500] Loss: 1.729 Acc: 35.0%

 ** Valid ** Epoch: [5/500] Iter: [1955/195500] Loss: 4.429 Acc: 22.6%

 ** Time 15:2

 ** Train ** Epoch: [6/500] Iter: [2346/195500] Loss: 1.227 Acc: 53.75%

 ** Valid ** Epoch: [6/500] Iter: [2346/195500] Loss: 4.507 Acc: 25.88%

 ** Time 15:2

 ** Train ** Epoch: [7/500] Iter: [2737/195500] Loss: 1.338 Acc: 53.75%

 ** Valid ** Epoch: [7/500] Iter: [2737/195500] Loss: 3.25 Acc: 26.23%

 ** Time 15:2

 ** Train ** Epoch: [8/500] Iter: [3128/195500] Loss: 1.317 Acc: 52.5%

 ** Valid ** Epoch: [8/500] Iter: [3128/195500] Loss: 3.231 Acc: 28.16%

 ** Time 15:2

 ** Train ** Epoch: [9/500] Iter: [3519/195500] Loss: 1.236 Acc: 60.0%

 ** Valid ** Epoch: [9/500] Iter: [3519/195500] Loss: 3.387 Acc: 30.37%

 ** Time 15:2

 ** Train ** Epoch: [10/500] Iter: [3910/195500] Loss: 1.388 Acc: 55.0%

 ** Valid ** Epoch: [10/500] Iter: [3910/195500] Loss: 3.373 Acc: 28.96%

 ** Time 15:2

 ** Train ** Epoch: [11/500] Iter: [4301/195500] Loss: 1.29 Acc: 56.25%

 ** Valid ** Epoch: [11/500] Iter: [4301/195500] Loss: 3.573 Acc: 31.28%

 ** Time 15:2

 ** Train ** Epoch: [12/500] Iter: [4692/195500] Loss: 1.226 Acc: 53.75%

 ** Valid ** Epoch: [12/500] Iter: [4692/195500] Loss: 2.301 Acc: 31.31%

 ** Time 15:3

 ** Train ** Epoch: [13/500] Iter: [5083/195500] Loss: 1.433 Acc: 48.75%

 ** Valid ** Epoch: [13/500] Iter: [5083/195500] Loss: 2.902 Acc: 30.91%

 ** Time 15:3

 ** Train ** Epoch: [14/500] Iter: [5474/195500] Loss: 1.168 Acc: 60.0%

 ** Valid ** Epoch: [14/500] Iter: [5474/195500] Loss: 3.144 Acc: 29.48%

 ** Time 15:3

 ** Train ** Epoch: [15/500] Iter: [5865/195500] Loss: 0.945 Acc: 66.25%

 ** Valid ** Epoch: [15/500] Iter: [5865/195500] Loss: 2.127 Acc: 35.17%

 ** Time 15:3

 ** Train ** Epoch: [16/500] Iter: [6256/195500] Loss: 0.986 Acc: 65.0%

 ** Valid ** Epoch: [16/500] Iter: [6256/195500] Loss: 2.383 Acc: 32.65%

 ** Time 15:3

 ** Train ** Epoch: [17/500] Iter: [6647/195500] Loss: 1.515 Acc: 47.5%

 ** Valid ** Epoch: [17/500] Iter: [6647/195500] Loss: 3.336 Acc: 31.05%

 ** Time 15:3

 ** Train ** Epoch: [18/500] Iter: [7038/195500] Loss: 1.144 Acc: 61.25%

 ** Valid ** Epoch: [18/500] Iter: [7038/195500] Loss: 2.041 Acc: 30.99%

 ** Time 15:3

 ** Train ** Epoch: [19/500] Iter: [7429/195500] Loss: 0.959 Acc: 71.25%

 ** Valid ** Epoch: [19/500] Iter: [7429/195500] Loss: 1.582 Acc: 35.19%

 ** Time 15:3

 ** Train ** Epoch: [20/500] Iter: [7820/195500] Loss: 1.058 Acc: 61.25%

 ** Valid ** Epoch: [20/500] Iter: [7820/195500] Loss: 1.556 Acc: 38.39%

 ** Time 15:4

 ** Train ** Epoch: [21/500] Iter: [8211/195500] Loss: 1.142 Acc: 66.25%

 ** Valid ** Epoch: [21/500] Iter: [8211/195500] Loss: 1.579 Acc: 37.02%

 ** Time 15:4

 ** Train ** Epoch: [22/500] Iter: [8602/195500] Loss: 1.234 Acc: 57.5%

 ** Valid ** Epoch: [22/500] Iter: [8602/195500] Loss: 1.84 Acc: 34.88%

 ** Time 15:4

 ** Train ** Epoch: [23/500] Iter: [8993/195500] Loss: 0.962 Acc: 67.5%

 ** Valid ** Epoch: [23/500] Iter: [8993/195500] Loss: 1.264 Acc: 40.36%

 ** Time 15:4

 ** Train ** Epoch: [24/500] Iter: [9384/195500] Loss: 1.251 Acc: 58.75%

 ** Valid ** Epoch: [24/500] Iter: [9384/195500] Loss: 1.825 Acc: 37.67%

 ** Time 15:4

 ** Train ** Epoch: [25/500] Iter: [9775/195500] Loss: 1.137 Acc: 65.0%

 ** Valid ** Epoch: [25/500] Iter: [9775/195500] Loss: 1.564 Acc: 42.2%

 ** Time 15:4

 ** Train ** Epoch: [26/500] Iter: [10166/195500] Loss: 1.03 Acc: 62.5%

 ** Valid ** Epoch: [26/500] Iter: [10166/195500] Loss: 1.628 Acc: 40.92%

 ** Time 15:4

 ** Train ** Epoch: [27/500] Iter: [10557/195500] Loss: 0.844 Acc: 67.5%

 ** Valid ** Epoch: [27/500] Iter: [10557/195500] Loss: 1.356 Acc: 41.43%

 ** Time 15:4

 ** Train ** Epoch: [28/500] Iter: [10948/195500] Loss: 0.92 Acc: 70.0%

 ** Valid ** Epoch: [28/500] Iter: [10948/195500] Loss: 1.531 Acc: 43.54%

 ** Time 15:5

 ** Train ** Epoch: [29/500] Iter: [11339/195500] Loss: 1.121 Acc: 61.25%

 ** Valid ** Epoch: [29/500] Iter: [11339/195500] Loss: 1.263 Acc: 42.84%

 ** Time 15:5

 ** Train ** Epoch: [30/500] Iter: [11730/195500] Loss: 0.926 Acc: 68.75%

 ** Valid ** Epoch: [30/500] Iter: [11730/195500] Loss: 1.334 Acc: 42.12%

 ** Time 15:5

 ** Train ** Epoch: [31/500] Iter: [12121/195500] Loss: 1.001 Acc: 60.0%

 ** Valid ** Epoch: [31/500] Iter: [12121/195500] Loss: 1.194 Acc: 43.73%

 ** Time 15:5

 ** Train ** Epoch: [32/500] Iter: [12512/195500] Loss: 0.905 Acc: 73.75%

 ** Valid ** Epoch: [32/500] Iter: [12512/195500] Loss: 1.402 Acc: 43.11%

 ** Time 15:5

 ** Train ** Epoch: [33/500] Iter: [12903/195500] Loss: 0.948 Acc: 66.25%

 ** Valid ** Epoch: [33/500] Iter: [12903/195500] Loss: 1.245 Acc: 48.47%

 ** Time 15:5

 ** Train ** Epoch: [34/500] Iter: [13294/195500] Loss: 1.053 Acc: 62.5%

 ** Valid ** Epoch: [34/500] Iter: [13294/195500] Loss: 1.326 Acc: 45.68%

 ** Time 15:5

 ** Train ** Epoch: [35/500] Iter: [13685/195500] Loss: 1.081 Acc: 61.25%

 ** Valid ** Epoch: [35/500] Iter: [13685/195500] Loss: 1.403 Acc: 45.68%

 ** Time 15:6

 ** Train ** Epoch: [36/500] Iter: [14076/195500] Loss: 0.907 Acc: 67.5%

 ** Valid ** Epoch: [36/500] Iter: [14076/195500] Loss: 1.432 Acc: 43.15%

 ** Time 15:6

 ** Train ** Epoch: [37/500] Iter: [14467/195500] Loss: 0.954 Acc: 63.75%

 ** Valid ** Epoch: [37/500] Iter: [14467/195500] Loss: 1.206 Acc: 49.24%

 ** Time 15:6

 ** Train ** Epoch: [38/500] Iter: [14858/195500] Loss: 0.872 Acc: 70.0%

 ** Valid ** Epoch: [38/500] Iter: [14858/195500] Loss: 1.325 Acc: 48.98%

 ** Time 15:6

 ** Train ** Epoch: [39/500] Iter: [15249/195500] Loss: 0.675 Acc: 75.0%

 ** Valid ** Epoch: [39/500] Iter: [15249/195500] Loss: 1.216 Acc: 51.57%

 ** Time 15:6

 ** Train ** Epoch: [40/500] Iter: [15640/195500] Loss: 0.737 Acc: 72.5%

 ** Valid ** Epoch: [40/500] Iter: [15640/195500] Loss: 1.414 Acc: 49.51%

 ** Time 15:6

 ** Train ** Epoch: [41/500] Iter: [16031/195500] Loss: 0.785 Acc: 72.5%

 ** Valid ** Epoch: [41/500] Iter: [16031/195500] Loss: 1.169 Acc: 49.7%

 ** Time 15:6

 ** Train ** Epoch: [42/500] Iter: [16422/195500] Loss: 0.766 Acc: 72.5%

 ** Valid ** Epoch: [42/500] Iter: [16422/195500] Loss: 1.202 Acc: 51.3%

 ** Time 15:6

 ** Train ** Epoch: [43/500] Iter: [16813/195500] Loss: 1.045 Acc: 61.25%

 ** Valid ** Epoch: [43/500] Iter: [16813/195500] Loss: 1.44 Acc: 48.82%

 ** Time 15:7

 ** Train ** Epoch: [44/500] Iter: [17204/195500] Loss: 0.851 Acc: 71.25%

 ** Valid ** Epoch: [44/500] Iter: [17204/195500] Loss: 1.423 Acc: 50.74%

 ** Time 15:7

 ** Train ** Epoch: [45/500] Iter: [17595/195500] Loss: 1.16 Acc: 58.75%

 ** Valid ** Epoch: [45/500] Iter: [17595/195500] Loss: 1.328 Acc: 51.72%

 ** Time 15:7

 ** Train ** Epoch: [46/500] Iter: [17986/195500] Loss: 0.827 Acc: 68.75%

 ** Valid ** Epoch: [46/500] Iter: [17986/195500] Loss: 1.483 Acc: 51.26%

 ** Time 15:7

 ** Train ** Epoch: [47/500] Iter: [18377/195500] Loss: 0.758 Acc: 73.75%

 ** Valid ** Epoch: [47/500] Iter: [18377/195500] Loss: 1.31 Acc: 50.36%

 ** Time 15:7

 ** Train ** Epoch: [48/500] Iter: [18768/195500] Loss: 0.681 Acc: 77.5%

 ** Valid ** Epoch: [48/500] Iter: [18768/195500] Loss: 1.288 Acc: 53.26%

 ** Time 15:7

 ** Train ** Epoch: [49/500] Iter: [19159/195500] Loss: 0.856 Acc: 70.0%

 ** Valid ** Epoch: [49/500] Iter: [19159/195500] Loss: 1.39 Acc: 52.33%

 ** Time 15:7

 ** Train ** Epoch: [50/500] Iter: [19550/195500] Loss: 0.734 Acc: 72.5%

 ** Valid ** Epoch: [50/500] Iter: [19550/195500] Loss: 1.326 Acc: 53.02%

 ** Time 15:8

 ** Train ** Epoch: [51/500] Iter: [19941/195500] Loss: 0.886 Acc: 67.5%

 ** Valid ** Epoch: [51/500] Iter: [19941/195500] Loss: 1.216 Acc: 55.13%

 ** Time 15:8

 ** Train ** Epoch: [52/500] Iter: [20332/195500] Loss: 0.805 Acc: 68.75%

 ** Valid ** Epoch: [52/500] Iter: [20332/195500] Loss: 1.202 Acc: 54.98%

 ** Time 15:8

 ** Train ** Epoch: [53/500] Iter: [20723/195500] Loss: 0.919 Acc: 66.25%

 ** Valid ** Epoch: [53/500] Iter: [20723/195500] Loss: 1.272 Acc: 54.1%

 ** Time 15:8

 ** Train ** Epoch: [54/500] Iter: [21114/195500] Loss: 0.847 Acc: 70.0%

 ** Valid ** Epoch: [54/500] Iter: [21114/195500] Loss: 1.177 Acc: 55.61%

 ** Time 15:8

 ** Train ** Epoch: [55/500] Iter: [21505/195500] Loss: 0.957 Acc: 71.25%

 ** Valid ** Epoch: [55/500] Iter: [21505/195500] Loss: 1.162 Acc: 56.98%

 ** Time 15:8

 ** Train ** Epoch: [56/500] Iter: [21896/195500] Loss: 0.909 Acc: 67.5%

 ** Valid ** Epoch: [56/500] Iter: [21896/195500] Loss: 1.145 Acc: 55.14%

 ** Time 15:8

 ** Train ** Epoch: [57/500] Iter: [22287/195500] Loss: 0.726 Acc: 71.25%

 ** Valid ** Epoch: [57/500] Iter: [22287/195500] Loss: 1.333 Acc: 53.26%

 ** Time 15:8

 ** Train ** Epoch: [58/500] Iter: [22678/195500] Loss: 0.769 Acc: 75.0%

 ** Valid ** Epoch: [58/500] Iter: [22678/195500] Loss: 1.419 Acc: 52.79%

 ** Time 15:9

 ** Train ** Epoch: [59/500] Iter: [23069/195500] Loss: 0.857 Acc: 70.0%

 ** Valid ** Epoch: [59/500] Iter: [23069/195500] Loss: 1.422 Acc: 52.03%

 ** Time 15:9

 ** Train ** Epoch: [60/500] Iter: [23460/195500] Loss: 0.743 Acc: 70.0%

 ** Valid ** Epoch: [60/500] Iter: [23460/195500] Loss: 1.261 Acc: 53.4%

 ** Time 15:9

 ** Train ** Epoch: [61/500] Iter: [23851/195500] Loss: 0.449 Acc: 87.5%

 ** Valid ** Epoch: [61/500] Iter: [23851/195500] Loss: 1.294 Acc: 53.09%

 ** Time 15:9

 ** Train ** Epoch: [62/500] Iter: [24242/195500] Loss: 0.537 Acc: 82.5%

 ** Valid ** Epoch: [62/500] Iter: [24242/195500] Loss: 1.26 Acc: 50.44%

 ** Time 15:9

 ** Train ** Epoch: [63/500] Iter: [24633/195500] Loss: 0.814 Acc: 71.25%

 ** Valid ** Epoch: [63/500] Iter: [24633/195500] Loss: 1.258 Acc: 53.62%

 ** Time 15:9

 ** Train ** Epoch: [64/500] Iter: [25024/195500] Loss: 0.795 Acc: 75.0%

 ** Valid ** Epoch: [64/500] Iter: [25024/195500] Loss: 1.24 Acc: 55.09%

 ** Time 15:9

 ** Train ** Epoch: [65/500] Iter: [25415/195500] Loss: 0.699 Acc: 72.5%

 ** Valid ** Epoch: [65/500] Iter: [25415/195500] Loss: 1.269 Acc: 52.61%

 ** Time 15:10

 ** Train ** Epoch: [66/500] Iter: [25806/195500] Loss: 0.645 Acc: 75.0%

 ** Valid ** Epoch: [66/500] Iter: [25806/195500] Loss: 1.338 Acc: 52.61%

 ** Time 15:10

 ** Train ** Epoch: [67/500] Iter: [26197/195500] Loss: 0.584 Acc: 77.5%

 ** Valid ** Epoch: [67/500] Iter: [26197/195500] Loss: 1.36 Acc: 54.95%

 ** Time 15:10

 ** Train ** Epoch: [68/500] Iter: [26588/195500] Loss: 0.686 Acc: 73.75%

 ** Valid ** Epoch: [68/500] Iter: [26588/195500] Loss: 1.259 Acc: 55.3%

 ** Time 15:10

 ** Train ** Epoch: [69/500] Iter: [26979/195500] Loss: 0.624 Acc: 80.0%

 ** Valid ** Epoch: [69/500] Iter: [26979/195500] Loss: 1.233 Acc: 53.42%

 ** Time 15:10

 ** Train ** Epoch: [70/500] Iter: [27370/195500] Loss: 0.57 Acc: 78.75%

 ** Valid ** Epoch: [70/500] Iter: [27370/195500] Loss: 1.131 Acc: 55.72%

 ** Time 15:10

 ** Train ** Epoch: [71/500] Iter: [27761/195500] Loss: 0.617 Acc: 76.25%

 ** Valid ** Epoch: [71/500] Iter: [27761/195500] Loss: 1.171 Acc: 54.41%

 ** Time 15:10

 ** Train ** Epoch: [72/500] Iter: [28152/195500] Loss: 0.585 Acc: 82.5%

 ** Valid ** Epoch: [72/500] Iter: [28152/195500] Loss: 1.248 Acc: 54.01%

 ** Time 15:10

 ** Train ** Epoch: [73/500] Iter: [28543/195500] Loss: 0.559 Acc: 77.5%

 ** Valid ** Epoch: [73/500] Iter: [28543/195500] Loss: 1.276 Acc: 52.81%

 ** Time 15:11

 ** Train ** Epoch: [74/500] Iter: [28934/195500] Loss: 0.727 Acc: 77.5%

 ** Valid ** Epoch: [74/500] Iter: [28934/195500] Loss: 1.193 Acc: 54.47%

 ** Time 15:11

 ** Train ** Epoch: [75/500] Iter: [29325/195500] Loss: 0.528 Acc: 81.25%

 ** Valid ** Epoch: [75/500] Iter: [29325/195500] Loss: 1.259 Acc: 53.81%

 ** Time 15:11

 ** Train ** Epoch: [76/500] Iter: [29716/195500] Loss: 0.664 Acc: 70.0%

 ** Valid ** Epoch: [76/500] Iter: [29716/195500] Loss: 1.269 Acc: 53.32%

 ** Time 15:11

 ** Train ** Epoch: [77/500] Iter: [30107/195500] Loss: 0.629 Acc: 77.5%

 ** Valid ** Epoch: [77/500] Iter: [30107/195500] Loss: 1.147 Acc: 51.5%

 ** Time 15:11

 ** Train ** Epoch: [78/500] Iter: [30498/195500] Loss: 0.598 Acc: 78.75%

 ** Valid ** Epoch: [78/500] Iter: [30498/195500] Loss: 1.167 Acc: 55.06%

 ** Time 15:11

 ** Train ** Epoch: [79/500] Iter: [30889/195500] Loss: 0.788 Acc: 68.75%

 ** Valid ** Epoch: [79/500] Iter: [30889/195500] Loss: 1.24 Acc: 53.62%

 ** Time 15:11

 ** Train ** Epoch: [80/500] Iter: [31280/195500] Loss: 0.804 Acc: 76.25%

 ** Valid ** Epoch: [80/500] Iter: [31280/195500] Loss: 1.168 Acc: 51.56%

 ** Time 15:12

 ** Train ** Epoch: [81/500] Iter: [31671/195500] Loss: 0.859 Acc: 67.5%

 ** Valid ** Epoch: [81/500] Iter: [31671/195500] Loss: 1.076 Acc: 54.34%

 ** Time 15:12

 ** Train ** Epoch: [82/500] Iter: [32062/195500] Loss: 0.667 Acc: 70.0%

 ** Valid ** Epoch: [82/500] Iter: [32062/195500] Loss: 1.209 Acc: 53.18%

 ** Time 15:12

 ** Train ** Epoch: [83/500] Iter: [32453/195500] Loss: 0.804 Acc: 70.0%

 ** Valid ** Epoch: [83/500] Iter: [32453/195500] Loss: 1.206 Acc: 53.07%

 ** Time 15:12

 ** Train ** Epoch: [84/500] Iter: [32844/195500] Loss: 0.676 Acc: 73.75%

 ** Valid ** Epoch: [84/500] Iter: [32844/195500] Loss: 1.233 Acc: 54.57%

 ** Time 15:12

 ** Train ** Epoch: [85/500] Iter: [33235/195500] Loss: 0.703 Acc: 76.25%

 ** Valid ** Epoch: [85/500] Iter: [33235/195500] Loss: 1.107 Acc: 53.65%

 ** Time 15:12

 ** Train ** Epoch: [86/500] Iter: [33626/195500] Loss: 0.604 Acc: 77.5%

 ** Valid ** Epoch: [86/500] Iter: [33626/195500] Loss: 1.091 Acc: 53.0%

 ** Time 15:12

 ** Train ** Epoch: [87/500] Iter: [34017/195500] Loss: 0.54 Acc: 83.75%

 ** Valid ** Epoch: [87/500] Iter: [34017/195500] Loss: 1.136 Acc: 56.53%

 ** Time 15:12

 ** Train ** Epoch: [88/500] Iter: [34408/195500] Loss: 1.021 Acc: 61.25%

 ** Valid ** Epoch: [88/500] Iter: [34408/195500] Loss: 1.241 Acc: 51.32%

 ** Time 15:13

 ** Train ** Epoch: [89/500] Iter: [34799/195500] Loss: 0.721 Acc: 72.5%

 ** Valid ** Epoch: [89/500] Iter: [34799/195500] Loss: 1.167 Acc: 51.19%

 ** Time 15:13

 ** Train ** Epoch: [90/500] Iter: [35190/195500] Loss: 0.662 Acc: 76.25%

 ** Valid ** Epoch: [90/500] Iter: [35190/195500] Loss: 1.103 Acc: 53.96%

 ** Time 15:13

 ** Train ** Epoch: [91/500] Iter: [35581/195500] Loss: 0.639 Acc: 75.0%

 ** Valid ** Epoch: [91/500] Iter: [35581/195500] Loss: 1.174 Acc: 50.99%

 ** Time 15:13

 ** Train ** Epoch: [92/500] Iter: [35972/195500] Loss: 0.629 Acc: 78.75%

 ** Valid ** Epoch: [92/500] Iter: [35972/195500] Loss: 1.007 Acc: 51.97%

 ** Time 15:13

 ** Train ** Epoch: [93/500] Iter: [36363/195500] Loss: 0.694 Acc: 75.0%

 ** Valid ** Epoch: [93/500] Iter: [36363/195500] Loss: 1.181 Acc: 54.77%

 ** Time 15:13

 ** Train ** Epoch: [94/500] Iter: [36754/195500] Loss: 0.628 Acc: 77.5%

 ** Valid ** Epoch: [94/500] Iter: [36754/195500] Loss: 1.009 Acc: 53.74%

 ** Time 15:13

 ** Train ** Epoch: [95/500] Iter: [37145/195500] Loss: 0.571 Acc: 82.5%

 ** Valid ** Epoch: [95/500] Iter: [37145/195500] Loss: 1.127 Acc: 52.95%

 ** Time 15:13

 ** Train ** Epoch: [96/500] Iter: [37536/195500] Loss: 0.474 Acc: 82.5%

 ** Valid ** Epoch: [96/500] Iter: [37536/195500] Loss: 1.04 Acc: 56.52%

 ** Time 15:14

 ** Train ** Epoch: [97/500] Iter: [37927/195500] Loss: 0.616 Acc: 77.5%

 ** Valid ** Epoch: [97/500] Iter: [37927/195500] Loss: 0.99 Acc: 53.23%

 ** Time 15:14

 ** Train ** Epoch: [98/500] Iter: [38318/195500] Loss: 0.711 Acc: 77.5%

 ** Valid ** Epoch: [98/500] Iter: [38318/195500] Loss: 0.953 Acc: 54.37%

 ** Time 15:14

 ** Train ** Epoch: [99/500] Iter: [38709/195500] Loss: 0.587 Acc: 82.5%

 ** Valid ** Epoch: [99/500] Iter: [38709/195500] Loss: 1.171 Acc: 55.12%

 ** Time 15:14

 ** Train ** Epoch: [100/500] Iter: [39100/195500] Loss: 0.545 Acc: 82.5%

 ** Valid ** Epoch: [100/500] Iter: [39100/195500] Loss: 1.153 Acc: 51.43%

 ** Time 15:14

 ** Train ** Epoch: [101/500] Iter: [39491/195500] Loss: 0.608 Acc: 76.25%

 ** Valid ** Epoch: [101/500] Iter: [39491/195500] Loss: 1.147 Acc: 51.22%

 ** Time 15:14

 ** Train ** Epoch: [102/500] Iter: [39882/195500] Loss: 0.506 Acc: 80.0%

 ** Valid ** Epoch: [102/500] Iter: [39882/195500] Loss: 1.027 Acc: 52.24%

 ** Time 15:14

 ** Train ** Epoch: [103/500] Iter: [40273/195500] Loss: 0.446 Acc: 87.5%

 ** Valid ** Epoch: [103/500] Iter: [40273/195500] Loss: 1.072 Acc: 50.52%

 ** Time 15:15

 ** Train ** Epoch: [104/500] Iter: [40664/195500] Loss: 0.681 Acc: 75.0%

 ** Valid ** Epoch: [104/500] Iter: [40664/195500] Loss: 0.888 Acc: 53.7%

 ** Time 15:15

 ** Train ** Epoch: [105/500] Iter: [41055/195500] Loss: 0.591 Acc: 77.5%

 ** Valid ** Epoch: [105/500] Iter: [41055/195500] Loss: 0.811 Acc: 56.24%

 ** Time 15:15

 ** Train ** Epoch: [106/500] Iter: [41446/195500] Loss: 0.82 Acc: 70.0%

 ** Valid ** Epoch: [106/500] Iter: [41446/195500] Loss: 0.759 Acc: 53.39%

 ** Time 15:15

 ** Train ** Epoch: [107/500] Iter: [41837/195500] Loss: 0.643 Acc: 72.5%

 ** Valid ** Epoch: [107/500] Iter: [41837/195500] Loss: 0.901 Acc: 49.72%

 ** Time 15:15

 ** Train ** Epoch: [108/500] Iter: [42228/195500] Loss: 1.007 Acc: 66.25%

 ** Valid ** Epoch: [108/500] Iter: [42228/195500] Loss: 0.792 Acc: 55.18%

 ** Time 15:15

 ** Train ** Epoch: [109/500] Iter: [42619/195500] Loss: 0.707 Acc: 78.75%

 ** Valid ** Epoch: [109/500] Iter: [42619/195500] Loss: 0.933 Acc: 50.48%

 ** Time 15:15

 ** Train ** Epoch: [110/500] Iter: [43010/195500] Loss: 0.71 Acc: 73.75%

 ** Valid ** Epoch: [110/500] Iter: [43010/195500] Loss: 0.937 Acc: 53.55%

 ** Time 15:15

 ** Train ** Epoch: [111/500] Iter: [43401/195500] Loss: 0.647 Acc: 75.0%

 ** Valid ** Epoch: [111/500] Iter: [43401/195500] Loss: 0.761 Acc: 55.05%

 ** Time 15:16

 ** Train ** Epoch: [112/500] Iter: [43792/195500] Loss: 0.497 Acc: 82.5%

 ** Valid ** Epoch: [112/500] Iter: [43792/195500] Loss: 0.972 Acc: 52.5%

 ** Time 15:16

 ** Train ** Epoch: [113/500] Iter: [44183/195500] Loss: 0.618 Acc: 80.0%

 ** Valid ** Epoch: [113/500] Iter: [44183/195500] Loss: 1.007 Acc: 52.95%

 ** Time 15:16

 ** Train ** Epoch: [114/500] Iter: [44574/195500] Loss: 0.604 Acc: 72.5%

 ** Valid ** Epoch: [114/500] Iter: [44574/195500] Loss: 0.869 Acc: 55.36%

 ** Time 15:16

 ** Train ** Epoch: [115/500] Iter: [44965/195500] Loss: 0.797 Acc: 70.0%

 ** Valid ** Epoch: [115/500] Iter: [44965/195500] Loss: 1.054 Acc: 52.52%

 ** Time 15:16

 ** Train ** Epoch: [116/500] Iter: [45356/195500] Loss: 0.465 Acc: 85.0%

 ** Valid ** Epoch: [116/500] Iter: [45356/195500] Loss: 0.926 Acc: 50.96%

 ** Time 15:16

 ** Train ** Epoch: [117/500] Iter: [45747/195500] Loss: 0.602 Acc: 75.0%

 ** Valid ** Epoch: [117/500] Iter: [45747/195500] Loss: 0.929 Acc: 51.78%

 ** Time 15:16

 ** Train ** Epoch: [118/500] Iter: [46138/195500] Loss: 0.475 Acc: 80.0%

 ** Valid ** Epoch: [118/500] Iter: [46138/195500] Loss: 0.955 Acc: 52.41%

 ** Time 15:17

 ** Train ** Epoch: [119/500] Iter: [46529/195500] Loss: 0.737 Acc: 77.5%

 ** Valid ** Epoch: [119/500] Iter: [46529/195500] Loss: 0.82 Acc: 53.77%

 ** Time 15:17

 ** Train ** Epoch: [120/500] Iter: [46920/195500] Loss: 0.504 Acc: 85.0%

 ** Valid ** Epoch: [120/500] Iter: [46920/195500] Loss: 0.982 Acc: 50.23%

 ** Time 15:17

 ** Train ** Epoch: [121/500] Iter: [47311/195500] Loss: 0.51 Acc: 81.25%

 ** Valid ** Epoch: [121/500] Iter: [47311/195500] Loss: 0.939 Acc: 53.43%

 ** Time 15:17

 ** Train ** Epoch: [122/500] Iter: [47702/195500] Loss: 0.479 Acc: 85.0%

 ** Valid ** Epoch: [122/500] Iter: [47702/195500] Loss: 0.899 Acc: 53.42%

 ** Time 15:17

 ** Train ** Epoch: [123/500] Iter: [48093/195500] Loss: 0.442 Acc: 82.5%

 ** Valid ** Epoch: [123/500] Iter: [48093/195500] Loss: 0.936 Acc: 51.35%

 ** Time 15:17

 ** Train ** Epoch: [124/500] Iter: [48484/195500] Loss: 0.505 Acc: 81.25%

 ** Valid ** Epoch: [124/500] Iter: [48484/195500] Loss: 1.037 Acc: 51.41%

 ** Time 15:17

 ** Train ** Epoch: [125/500] Iter: [48875/195500] Loss: 0.403 Acc: 87.5%

 ** Valid ** Epoch: [125/500] Iter: [48875/195500] Loss: 0.913 Acc: 53.09%

 ** Time 15:17

 ** Train ** Epoch: [126/500] Iter: [49266/195500] Loss: 0.412 Acc: 87.5%

 ** Valid ** Epoch: [126/500] Iter: [49266/195500] Loss: 0.844 Acc: 51.06%

 ** Time 15:18

 ** Train ** Epoch: [127/500] Iter: [49657/195500] Loss: 0.579 Acc: 80.0%

 ** Valid ** Epoch: [127/500] Iter: [49657/195500] Loss: 0.967 Acc: 52.62%

 ** Time 15:18

 ** Train ** Epoch: [128/500] Iter: [50048/195500] Loss: 0.651 Acc: 76.25%

 ** Valid ** Epoch: [128/500] Iter: [50048/195500] Loss: 0.875 Acc: 50.12%

 ** Time 15:18

 ** Train ** Epoch: [129/500] Iter: [50439/195500] Loss: 0.48 Acc: 83.75%

 ** Valid ** Epoch: [129/500] Iter: [50439/195500] Loss: 1.079 Acc: 50.25%

 ** Time 15:18

 ** Train ** Epoch: [130/500] Iter: [50830/195500] Loss: 0.487 Acc: 82.5%

 ** Valid ** Epoch: [130/500] Iter: [50830/195500] Loss: 1.053 Acc: 49.68%

 ** Time 15:18

 ** Train ** Epoch: [131/500] Iter: [51221/195500] Loss: 0.603 Acc: 81.25%

 ** Valid ** Epoch: [131/500] Iter: [51221/195500] Loss: 1.001 Acc: 48.9%

 ** Time 15:18

 ** Train ** Epoch: [132/500] Iter: [51612/195500] Loss: 0.549 Acc: 87.5%

 ** Valid ** Epoch: [132/500] Iter: [51612/195500] Loss: 0.916 Acc: 52.79%

 ** Time 15:18

 ** Train ** Epoch: [133/500] Iter: [52003/195500] Loss: 0.654 Acc: 73.75%

 ** Valid ** Epoch: [133/500] Iter: [52003/195500] Loss: 0.851 Acc: 49.81%

 ** Time 15:19

 ** Train ** Epoch: [134/500] Iter: [52394/195500] Loss: 0.527 Acc: 78.75%

 ** Valid ** Epoch: [134/500] Iter: [52394/195500] Loss: 0.881 Acc: 49.39%

 ** Time 15:19

 ** Train ** Epoch: [135/500] Iter: [52785/195500] Loss: 0.51 Acc: 81.25%

 ** Valid ** Epoch: [135/500] Iter: [52785/195500] Loss: 1.08 Acc: 52.61%

 ** Time 15:19

 ** Train ** Epoch: [136/500] Iter: [53176/195500] Loss: 0.545 Acc: 81.25%

 ** Valid ** Epoch: [136/500] Iter: [53176/195500] Loss: 0.99 Acc: 52.39%

 ** Time 15:19

 ** Train ** Epoch: [137/500] Iter: [53567/195500] Loss: 0.433 Acc: 87.5%

 ** Valid ** Epoch: [137/500] Iter: [53567/195500] Loss: 1.145 Acc: 51.7%

 ** Time 15:19

 ** Train ** Epoch: [138/500] Iter: [53958/195500] Loss: 0.598 Acc: 77.5%

 ** Valid ** Epoch: [138/500] Iter: [53958/195500] Loss: 1.123 Acc: 48.69%

 ** Time 15:19

 ** Train ** Epoch: [139/500] Iter: [54349/195500] Loss: 0.443 Acc: 82.5%

 ** Valid ** Epoch: [139/500] Iter: [54349/195500] Loss: 0.998 Acc: 52.33%

 ** Time 15:19

 ** Train ** Epoch: [140/500] Iter: [54740/195500] Loss: 0.572 Acc: 80.0%

 ** Valid ** Epoch: [140/500] Iter: [54740/195500] Loss: 1.01 Acc: 52.52%

 ** Time 15:19

 ** Train ** Epoch: [141/500] Iter: [55131/195500] Loss: 0.652 Acc: 75.0%

 ** Valid ** Epoch: [141/500] Iter: [55131/195500] Loss: 1.053 Acc: 50.91%

 ** Time 15:20

 ** Train ** Epoch: [142/500] Iter: [55522/195500] Loss: 0.358 Acc: 86.25%

 ** Valid ** Epoch: [142/500] Iter: [55522/195500] Loss: 0.988 Acc: 53.64%

 ** Time 15:20

 ** Train ** Epoch: [143/500] Iter: [55913/195500] Loss: 0.406 Acc: 82.5%

 ** Valid ** Epoch: [143/500] Iter: [55913/195500] Loss: 1.112 Acc: 52.5%

 ** Time 15:20

 ** Train ** Epoch: [144/500] Iter: [56304/195500] Loss: 0.846 Acc: 66.25%

 ** Valid ** Epoch: [144/500] Iter: [56304/195500] Loss: 1.072 Acc: 48.59%

 ** Time 15:20

 ** Train ** Epoch: [145/500] Iter: [56695/195500] Loss: 0.509 Acc: 86.25%

 ** Valid ** Epoch: [145/500] Iter: [56695/195500] Loss: 0.962 Acc: 50.67%

 ** Time 15:20

 ** Train ** Epoch: [146/500] Iter: [57086/195500] Loss: 0.384 Acc: 85.0%

 ** Valid ** Epoch: [146/500] Iter: [57086/195500] Loss: 0.962 Acc: 49.83%

 ** Time 15:20

 ** Train ** Epoch: [147/500] Iter: [57477/195500] Loss: 0.559 Acc: 82.5%

 ** Valid ** Epoch: [147/500] Iter: [57477/195500] Loss: 0.893 Acc: 51.56%

 ** Time 15:20

 ** Train ** Epoch: [148/500] Iter: [57868/195500] Loss: 0.38 Acc: 85.0%

 ** Valid ** Epoch: [148/500] Iter: [57868/195500] Loss: 1.121 Acc: 52.12%

 ** Time 15:21

 ** Train ** Epoch: [149/500] Iter: [58259/195500] Loss: 0.476 Acc: 80.0%

 ** Valid ** Epoch: [149/500] Iter: [58259/195500] Loss: 1.16 Acc: 47.76%

 ** Time 15:21

 ** Train ** Epoch: [150/500] Iter: [58650/195500] Loss: 0.306 Acc: 91.25%

 ** Valid ** Epoch: [150/500] Iter: [58650/195500] Loss: 0.947 Acc: 52.09%

 ** Time 15:21

 ** Train ** Epoch: [151/500] Iter: [59041/195500] Loss: 0.519 Acc: 78.75%

 ** Valid ** Epoch: [151/500] Iter: [59041/195500] Loss: 0.927 Acc: 51.08%

 ** Time 15:21

 ** Train ** Epoch: [152/500] Iter: [59432/195500] Loss: 0.707 Acc: 75.0%

 ** Valid ** Epoch: [152/500] Iter: [59432/195500] Loss: 1.002 Acc: 51.38%

 ** Time 15:21

 ** Train ** Epoch: [153/500] Iter: [59823/195500] Loss: 0.699 Acc: 80.0%

 ** Valid ** Epoch: [153/500] Iter: [59823/195500] Loss: 0.836 Acc: 54.23%

 ** Time 15:21

 ** Train ** Epoch: [154/500] Iter: [60214/195500] Loss: 0.301 Acc: 92.5%

 ** Valid ** Epoch: [154/500] Iter: [60214/195500] Loss: 0.909 Acc: 50.83%

 ** Time 15:21

 ** Train ** Epoch: [155/500] Iter: [60605/195500] Loss: 0.546 Acc: 78.75%

 ** Valid ** Epoch: [155/500] Iter: [60605/195500] Loss: 1.006 Acc: 50.82%

 ** Time 15:21

 ** Train ** Epoch: [156/500] Iter: [60996/195500] Loss: 0.464 Acc: 82.5%

 ** Valid ** Epoch: [156/500] Iter: [60996/195500] Loss: 1.146 Acc: 50.18%

 ** Time 15:22

 ** Train ** Epoch: [157/500] Iter: [61387/195500] Loss: 0.5 Acc: 85.0%

 ** Valid ** Epoch: [157/500] Iter: [61387/195500] Loss: 1.398 Acc: 46.53%

 ** Time 15:22

 ** Train ** Epoch: [158/500] Iter: [61778/195500] Loss: 0.538 Acc: 81.25%

 ** Valid ** Epoch: [158/500] Iter: [61778/195500] Loss: 0.932 Acc: 53.24%

 ** Time 15:22

 ** Train ** Epoch: [159/500] Iter: [62169/195500] Loss: 0.357 Acc: 87.5%

 ** Valid ** Epoch: [159/500] Iter: [62169/195500] Loss: 1.135 Acc: 44.93%

 ** Time 15:22

 ** Train ** Epoch: [160/500] Iter: [62560/195500] Loss: 0.541 Acc: 82.5%

 ** Valid ** Epoch: [160/500] Iter: [62560/195500] Loss: 0.905 Acc: 49.17%

 ** Time 15:22

 ** Train ** Epoch: [161/500] Iter: [62951/195500] Loss: 0.781 Acc: 81.25%

 ** Valid ** Epoch: [161/500] Iter: [62951/195500] Loss: 0.998 Acc: 48.98%

 ** Time 15:22

 ** Train ** Epoch: [162/500] Iter: [63342/195500] Loss: 0.622 Acc: 78.75%

 ** Valid ** Epoch: [162/500] Iter: [63342/195500] Loss: 1.1 Acc: 53.67%

 ** Time 15:22

 ** Train ** Epoch: [163/500] Iter: [63733/195500] Loss: 0.461 Acc: 85.0%

 ** Valid ** Epoch: [163/500] Iter: [63733/195500] Loss: 0.857 Acc: 49.73%

 ** Time 15:22

 ** Train ** Epoch: [164/500] Iter: [64124/195500] Loss: 0.37 Acc: 87.5%

 ** Valid ** Epoch: [164/500] Iter: [64124/195500] Loss: 0.984 Acc: 52.1%

 ** Time 15:23

 ** Train ** Epoch: [165/500] Iter: [64515/195500] Loss: 0.39 Acc: 88.75%

 ** Valid ** Epoch: [165/500] Iter: [64515/195500] Loss: 0.872 Acc: 53.55%

 ** Time 15:23

 ** Train ** Epoch: [166/500] Iter: [64906/195500] Loss: 0.34 Acc: 85.0%

 ** Valid ** Epoch: [166/500] Iter: [64906/195500] Loss: 1.103 Acc: 50.2%

 ** Time 15:23

 ** Train ** Epoch: [167/500] Iter: [65297/195500] Loss: 0.486 Acc: 81.25%

 ** Valid ** Epoch: [167/500] Iter: [65297/195500] Loss: 1.256 Acc: 46.35%

 ** Time 15:23

 ** Train ** Epoch: [168/500] Iter: [65688/195500] Loss: 0.495 Acc: 81.25%

 ** Valid ** Epoch: [168/500] Iter: [65688/195500] Loss: 1.154 Acc: 48.45%

 ** Time 15:23

 ** Train ** Epoch: [169/500] Iter: [66079/195500] Loss: 0.566 Acc: 83.75%

 ** Valid ** Epoch: [169/500] Iter: [66079/195500] Loss: 1.42 Acc: 49.9%

 ** Time 15:23

 ** Train ** Epoch: [170/500] Iter: [66470/195500] Loss: 0.456 Acc: 87.5%

 ** Valid ** Epoch: [170/500] Iter: [66470/195500] Loss: 1.086 Acc: 50.48%

 ** Time 15:23

 ** Train ** Epoch: [171/500] Iter: [66861/195500] Loss: 0.527 Acc: 80.0%

 ** Valid ** Epoch: [171/500] Iter: [66861/195500] Loss: 1.092 Acc: 49.97%

 ** Time 15:24

 ** Train ** Epoch: [172/500] Iter: [67252/195500] Loss: 0.438 Acc: 85.0%

 ** Valid ** Epoch: [172/500] Iter: [67252/195500] Loss: 1.167 Acc: 53.11%

 ** Time 15:24

 ** Train ** Epoch: [173/500] Iter: [67643/195500] Loss: 0.547 Acc: 75.0%

 ** Valid ** Epoch: [173/500] Iter: [67643/195500] Loss: 1.035 Acc: 49.79%

 ** Time 15:24

 ** Train ** Epoch: [174/500] Iter: [68034/195500] Loss: 0.532 Acc: 82.5%

 ** Valid ** Epoch: [174/500] Iter: [68034/195500] Loss: 1.032 Acc: 48.81%

 ** Time 15:24

 ** Train ** Epoch: [175/500] Iter: [68425/195500] Loss: 0.753 Acc: 76.25%

 ** Valid ** Epoch: [175/500] Iter: [68425/195500] Loss: 1.215 Acc: 51.17%

 ** Time 15:24

 ** Train ** Epoch: [176/500] Iter: [68816/195500] Loss: 0.64 Acc: 77.5%

 ** Valid ** Epoch: [176/500] Iter: [68816/195500] Loss: 1.035 Acc: 50.41%

 ** Time 15:24

 ** Train ** Epoch: [177/500] Iter: [69207/195500] Loss: 0.719 Acc: 76.25%

 ** Valid ** Epoch: [177/500] Iter: [69207/195500] Loss: 1.093 Acc: 51.5%

 ** Time 15:24

 ** Train ** Epoch: [178/500] Iter: [69598/195500] Loss: 0.544 Acc: 82.5%

 ** Valid ** Epoch: [178/500] Iter: [69598/195500] Loss: 0.966 Acc: 52.75%

 ** Time 15:24

 ** Train ** Epoch: [179/500] Iter: [69989/195500] Loss: 0.386 Acc: 88.75%

 ** Valid ** Epoch: [179/500] Iter: [69989/195500] Loss: 1.085 Acc: 51.88%

 ** Time 15:25

 ** Train ** Epoch: [180/500] Iter: [70380/195500] Loss: 0.475 Acc: 82.5%

 ** Valid ** Epoch: [180/500] Iter: [70380/195500] Loss: 1.19 Acc: 52.26%

 ** Time 15:25

 ** Train ** Epoch: [181/500] Iter: [70771/195500] Loss: 0.669 Acc: 81.25%

 ** Valid ** Epoch: [181/500] Iter: [70771/195500] Loss: 1.047 Acc: 51.0%

 ** Time 15:25

 ** Train ** Epoch: [182/500] Iter: [71162/195500] Loss: 0.489 Acc: 80.0%

 ** Valid ** Epoch: [182/500] Iter: [71162/195500] Loss: 1.147 Acc: 51.81%

 ** Time 15:25

 ** Train ** Epoch: [183/500] Iter: [71553/195500] Loss: 0.456 Acc: 80.0%

 ** Valid ** Epoch: [183/500] Iter: [71553/195500] Loss: 1.19 Acc: 50.96%

 ** Time 15:25

 ** Train ** Epoch: [184/500] Iter: [71944/195500] Loss: 0.565 Acc: 81.25%

 ** Valid ** Epoch: [184/500] Iter: [71944/195500] Loss: 1.124 Acc: 49.53%

 ** Time 15:25

 ** Train ** Epoch: [185/500] Iter: [72335/195500] Loss: 0.443 Acc: 86.25%

 ** Valid ** Epoch: [185/500] Iter: [72335/195500] Loss: 1.169 Acc: 49.13%

 ** Time 15:25

 ** Train ** Epoch: [186/500] Iter: [72726/195500] Loss: 0.422 Acc: 82.5%

 ** Valid ** Epoch: [186/500] Iter: [72726/195500] Loss: 1.06 Acc: 48.63%

 ** Time 15:26

 ** Train ** Epoch: [187/500] Iter: [73117/195500] Loss: 0.355 Acc: 85.0%

 ** Valid ** Epoch: [187/500] Iter: [73117/195500] Loss: 1.215 Acc: 46.93%

 ** Time 15:26

 ** Train ** Epoch: [188/500] Iter: [73508/195500] Loss: 0.456 Acc: 83.75%

 ** Valid ** Epoch: [188/500] Iter: [73508/195500] Loss: 0.861 Acc: 49.88%

 ** Time 15:26

 ** Train ** Epoch: [189/500] Iter: [73899/195500] Loss: 0.63 Acc: 85.0%

 ** Valid ** Epoch: [189/500] Iter: [73899/195500] Loss: 0.97 Acc: 47.18%

 ** Time 15:26

 ** Train ** Epoch: [190/500] Iter: [74290/195500] Loss: 0.477 Acc: 86.25%

 ** Valid ** Epoch: [190/500] Iter: [74290/195500] Loss: 1.145 Acc: 45.82%

 ** Time 15:26

 ** Train ** Epoch: [191/500] Iter: [74681/195500] Loss: 0.468 Acc: 81.25%

 ** Valid ** Epoch: [191/500] Iter: [74681/195500] Loss: 0.913 Acc: 48.1%

 ** Time 15:26

 ** Train ** Epoch: [192/500] Iter: [75072/195500] Loss: 0.567 Acc: 77.5%

 ** Valid ** Epoch: [192/500] Iter: [75072/195500] Loss: 1.062 Acc: 46.79%

 ** Time 15:26

 ** Train ** Epoch: [193/500] Iter: [75463/195500] Loss: 0.473 Acc: 82.5%

 ** Valid ** Epoch: [193/500] Iter: [75463/195500] Loss: 1.157 Acc: 47.42%

 ** Time 15:26

 ** Train ** Epoch: [194/500] Iter: [75854/195500] Loss: 0.274 Acc: 91.25%

 ** Valid ** Epoch: [194/500] Iter: [75854/195500] Loss: 1.016 Acc: 51.08%

 ** Time 15:27

 ** Train ** Epoch: [195/500] Iter: [76245/195500] Loss: 0.466 Acc: 82.5%

 ** Valid ** Epoch: [195/500] Iter: [76245/195500] Loss: 1.12 Acc: 52.09%

 ** Time 15:27

 ** Train ** Epoch: [196/500] Iter: [76636/195500] Loss: 0.572 Acc: 77.5%

 ** Valid ** Epoch: [196/500] Iter: [76636/195500] Loss: 1.273 Acc: 51.68%

 ** Time 15:27

 ** Train ** Epoch: [197/500] Iter: [77027/195500] Loss: 0.524 Acc: 78.75%

 ** Valid ** Epoch: [197/500] Iter: [77027/195500] Loss: 1.023 Acc: 48.17%

 ** Time 15:27

 ** Train ** Epoch: [198/500] Iter: [77418/195500] Loss: 0.668 Acc: 78.75%

 ** Valid ** Epoch: [198/500] Iter: [77418/195500] Loss: 1.248 Acc: 49.32%

 ** Time 15:27

 ** Train ** Epoch: [199/500] Iter: [77809/195500] Loss: 0.496 Acc: 81.25%

 ** Valid ** Epoch: [199/500] Iter: [77809/195500] Loss: 1.103 Acc: 50.88%

 ** Time 15:27

 ** Train ** Epoch: [200/500] Iter: [78200/195500] Loss: 0.323 Acc: 86.25%

 ** Valid ** Epoch: [200/500] Iter: [78200/195500] Loss: 1.07 Acc: 49.0%

 ** Time 15:27

 ** Train ** Epoch: [201/500] Iter: [78591/195500] Loss: 0.521 Acc: 83.75%

 ** Valid ** Epoch: [201/500] Iter: [78591/195500] Loss: 0.869 Acc: 50.47%

 ** Time 15:28

 ** Train ** Epoch: [202/500] Iter: [78982/195500] Loss: 0.53 Acc: 83.75%

 ** Valid ** Epoch: [202/500] Iter: [78982/195500] Loss: 0.926 Acc: 50.03%

 ** Time 15:28

 ** Train ** Epoch: [203/500] Iter: [79373/195500] Loss: 0.295 Acc: 90.0%

 ** Valid ** Epoch: [203/500] Iter: [79373/195500] Loss: 1.032 Acc: 50.84%

 ** Time 15:28

 ** Train ** Epoch: [204/500] Iter: [79764/195500] Loss: 0.439 Acc: 86.25%

 ** Valid ** Epoch: [204/500] Iter: [79764/195500] Loss: 1.144 Acc: 50.36%

 ** Time 15:28

 ** Train ** Epoch: [205/500] Iter: [80155/195500] Loss: 0.583 Acc: 85.0%

 ** Valid ** Epoch: [205/500] Iter: [80155/195500] Loss: 1.115 Acc: 50.79%

 ** Time 15:28

 ** Train ** Epoch: [206/500] Iter: [80546/195500] Loss: 0.459 Acc: 83.75%

 ** Valid ** Epoch: [206/500] Iter: [80546/195500] Loss: 1.235 Acc: 50.76%

 ** Time 15:28

 ** Train ** Epoch: [207/500] Iter: [80937/195500] Loss: 0.616 Acc: 80.0%

 ** Valid ** Epoch: [207/500] Iter: [80937/195500] Loss: 1.045 Acc: 52.6%

 ** Time 15:28

 ** Train ** Epoch: [208/500] Iter: [81328/195500] Loss: 0.387 Acc: 90.0%

 ** Valid ** Epoch: [208/500] Iter: [81328/195500] Loss: 1.196 Acc: 50.89%

 ** Time 15:28

 ** Train ** Epoch: [209/500] Iter: [81719/195500] Loss: 0.387 Acc: 85.0%

 ** Valid ** Epoch: [209/500] Iter: [81719/195500] Loss: 1.231 Acc: 46.61%

 ** Time 15:29

 ** Train ** Epoch: [210/500] Iter: [82110/195500] Loss: 0.363 Acc: 81.25%

 ** Valid ** Epoch: [210/500] Iter: [82110/195500] Loss: 1.101 Acc: 50.01%

 ** Time 15:29

 ** Train ** Epoch: [211/500] Iter: [82501/195500] Loss: 0.514 Acc: 78.75%

 ** Valid ** Epoch: [211/500] Iter: [82501/195500] Loss: 0.984 Acc: 50.73%

 ** Time 15:29

 ** Train ** Epoch: [212/500] Iter: [82892/195500] Loss: 0.596 Acc: 82.5%

 ** Valid ** Epoch: [212/500] Iter: [82892/195500] Loss: 1.109 Acc: 51.05%

 ** Time 15:29

 ** Train ** Epoch: [213/500] Iter: [83283/195500] Loss: 0.407 Acc: 87.5%

 ** Valid ** Epoch: [213/500] Iter: [83283/195500] Loss: 1.152 Acc: 51.31%

 ** Time 15:29

 ** Train ** Epoch: [214/500] Iter: [83674/195500] Loss: 0.561 Acc: 86.25%

 ** Valid ** Epoch: [214/500] Iter: [83674/195500] Loss: 1.158 Acc: 51.8%

 ** Time 15:29

 ** Train ** Epoch: [215/500] Iter: [84065/195500] Loss: 0.506 Acc: 86.25%

 ** Valid ** Epoch: [215/500] Iter: [84065/195500] Loss: 1.015 Acc: 51.62%

 ** Time 15:29

 ** Train ** Epoch: [216/500] Iter: [84456/195500] Loss: 0.414 Acc: 86.25%

 ** Valid ** Epoch: [216/500] Iter: [84456/195500] Loss: 1.051 Acc: 52.33%

 ** Time 15:29

 ** Train ** Epoch: [217/500] Iter: [84847/195500] Loss: 0.429 Acc: 83.75%

 ** Valid ** Epoch: [217/500] Iter: [84847/195500] Loss: 1.088 Acc: 49.7%

 ** Time 15:30

 ** Train ** Epoch: [218/500] Iter: [85238/195500] Loss: 0.257 Acc: 86.25%

 ** Valid ** Epoch: [218/500] Iter: [85238/195500] Loss: 1.088 Acc: 49.11%

 ** Time 15:30

 ** Train ** Epoch: [219/500] Iter: [85629/195500] Loss: 0.464 Acc: 80.0%

 ** Valid ** Epoch: [219/500] Iter: [85629/195500] Loss: 1.205 Acc: 52.7%

 ** Time 15:30

 ** Train ** Epoch: [220/500] Iter: [86020/195500] Loss: 0.424 Acc: 85.0%

 ** Valid ** Epoch: [220/500] Iter: [86020/195500] Loss: 1.161 Acc: 49.67%

 ** Time 15:30

 ** Train ** Epoch: [221/500] Iter: [86411/195500] Loss: 0.34 Acc: 90.0%

 ** Valid ** Epoch: [221/500] Iter: [86411/195500] Loss: 1.23 Acc: 48.76%

 ** Time 15:30

 ** Train ** Epoch: [222/500] Iter: [86802/195500] Loss: 0.607 Acc: 77.5%

 ** Valid ** Epoch: [222/500] Iter: [86802/195500] Loss: 1.294 Acc: 50.15%

 ** Time 15:30

 ** Train ** Epoch: [223/500] Iter: [87193/195500] Loss: 0.409 Acc: 82.5%

 ** Valid ** Epoch: [223/500] Iter: [87193/195500] Loss: 1.022 Acc: 52.29%

 ** Time 15:30

 ** Train ** Epoch: [224/500] Iter: [87584/195500] Loss: 0.499 Acc: 81.25%

 ** Valid ** Epoch: [224/500] Iter: [87584/195500] Loss: 1.306 Acc: 52.34%

 ** Time 15:31

 ** Train ** Epoch: [225/500] Iter: [87975/195500] Loss: 0.609 Acc: 80.0%

 ** Valid ** Epoch: [225/500] Iter: [87975/195500] Loss: 1.357 Acc: 48.26%

 ** Time 15:31

 ** Train ** Epoch: [226/500] Iter: [88366/195500] Loss: 0.592 Acc: 77.5%

 ** Valid ** Epoch: [226/500] Iter: [88366/195500] Loss: 1.156 Acc: 51.65%

 ** Time 15:31

 ** Train ** Epoch: [227/500] Iter: [88757/195500] Loss: 0.436 Acc: 83.75%

 ** Valid ** Epoch: [227/500] Iter: [88757/195500] Loss: 1.164 Acc: 53.51%

 ** Time 15:31

 ** Train ** Epoch: [228/500] Iter: [89148/195500] Loss: 0.351 Acc: 90.0%

 ** Valid ** Epoch: [228/500] Iter: [89148/195500] Loss: 1.116 Acc: 49.44%

 ** Time 15:31

 ** Train ** Epoch: [229/500] Iter: [89539/195500] Loss: 0.439 Acc: 88.75%

 ** Valid ** Epoch: [229/500] Iter: [89539/195500] Loss: 1.278 Acc: 50.19%

 ** Time 15:31

 ** Train ** Epoch: [230/500] Iter: [89930/195500] Loss: 0.331 Acc: 87.5%

 ** Valid ** Epoch: [230/500] Iter: [89930/195500] Loss: 1.267 Acc: 50.45%

 ** Time 15:31

 ** Train ** Epoch: [231/500] Iter: [90321/195500] Loss: 0.373 Acc: 85.0%

 ** Valid ** Epoch: [231/500] Iter: [90321/195500] Loss: 1.054 Acc: 51.64%

 ** Time 15:31

 ** Train ** Epoch: [232/500] Iter: [90712/195500] Loss: 0.461 Acc: 83.75%

 ** Valid ** Epoch: [232/500] Iter: [90712/195500] Loss: 1.112 Acc: 52.28%

 ** Time 15:32

 ** Train ** Epoch: [233/500] Iter: [91103/195500] Loss: 0.425 Acc: 86.25%

 ** Valid ** Epoch: [233/500] Iter: [91103/195500] Loss: 1.251 Acc: 48.64%

 ** Time 15:32

 ** Train ** Epoch: [234/500] Iter: [91494/195500] Loss: 0.368 Acc: 85.0%

 ** Valid ** Epoch: [234/500] Iter: [91494/195500] Loss: 0.982 Acc: 53.37%

 ** Time 15:32

 ** Train ** Epoch: [235/500] Iter: [91885/195500] Loss: 0.406 Acc: 86.25%

 ** Valid ** Epoch: [235/500] Iter: [91885/195500] Loss: 0.994 Acc: 50.13%

 ** Time 15:32

 ** Train ** Epoch: [236/500] Iter: [92276/195500] Loss: 0.523 Acc: 81.25%

 ** Valid ** Epoch: [236/500] Iter: [92276/195500] Loss: 1.209 Acc: 49.65%

 ** Time 15:32

 ** Train ** Epoch: [237/500] Iter: [92667/195500] Loss: 0.39 Acc: 86.25%

 ** Valid ** Epoch: [237/500] Iter: [92667/195500] Loss: 1.098 Acc: 50.51%

 ** Time 15:32

 ** Train ** Epoch: [238/500] Iter: [93058/195500] Loss: 0.442 Acc: 86.25%

 ** Valid ** Epoch: [238/500] Iter: [93058/195500] Loss: 1.067 Acc: 51.18%

 ** Time 15:32

 ** Train ** Epoch: [239/500] Iter: [93449/195500] Loss: 0.471 Acc: 83.75%

 ** Valid ** Epoch: [239/500] Iter: [93449/195500] Loss: 1.114 Acc: 48.68%

 ** Time 15:33

 ** Train ** Epoch: [240/500] Iter: [93840/195500] Loss: 0.395 Acc: 87.5%

 ** Valid ** Epoch: [240/500] Iter: [93840/195500] Loss: 1.15 Acc: 49.71%

 ** Time 15:33

 ** Train ** Epoch: [241/500] Iter: [94231/195500] Loss: 0.505 Acc: 83.75%

 ** Valid ** Epoch: [241/500] Iter: [94231/195500] Loss: 1.127 Acc: 49.89%

 ** Time 15:33

 ** Train ** Epoch: [242/500] Iter: [94622/195500] Loss: 0.257 Acc: 91.25%

 ** Valid ** Epoch: [242/500] Iter: [94622/195500] Loss: 1.071 Acc: 49.33%

 ** Time 15:33

 ** Train ** Epoch: [243/500] Iter: [95013/195500] Loss: 0.275 Acc: 90.0%

 ** Valid ** Epoch: [243/500] Iter: [95013/195500] Loss: 1.167 Acc: 49.86%

 ** Time 15:33

 ** Train ** Epoch: [244/500] Iter: [95404/195500] Loss: 0.322 Acc: 87.5%

 ** Valid ** Epoch: [244/500] Iter: [95404/195500] Loss: 1.158 Acc: 50.7%

 ** Time 15:33

 ** Train ** Epoch: [245/500] Iter: [95795/195500] Loss: 0.471 Acc: 85.0%

 ** Valid ** Epoch: [245/500] Iter: [95795/195500] Loss: 1.185 Acc: 51.12%

 ** Time 15:33

 ** Train ** Epoch: [246/500] Iter: [96186/195500] Loss: 0.439 Acc: 82.5%

 ** Valid ** Epoch: [246/500] Iter: [96186/195500] Loss: 1.337 Acc: 48.7%

 ** Time 15:33

 ** Train ** Epoch: [247/500] Iter: [96577/195500] Loss: 0.345 Acc: 90.0%

 ** Valid ** Epoch: [247/500] Iter: [96577/195500] Loss: 1.149 Acc: 52.06%

 ** Time 15:34

 ** Train ** Epoch: [248/500] Iter: [96968/195500] Loss: 0.497 Acc: 78.75%

 ** Valid ** Epoch: [248/500] Iter: [96968/195500] Loss: 1.425 Acc: 50.42%

 ** Time 15:34

 ** Train ** Epoch: [249/500] Iter: [97359/195500] Loss: 0.487 Acc: 82.5%

 ** Valid ** Epoch: [249/500] Iter: [97359/195500] Loss: 1.327 Acc: 48.71%

 ** Time 15:34

 ** Train ** Epoch: [250/500] Iter: [97750/195500] Loss: 0.246 Acc: 92.5%

 ** Valid ** Epoch: [250/500] Iter: [97750/195500] Loss: 1.367 Acc: 47.88%

 ** Time 15:34

 ** Train ** Epoch: [251/500] Iter: [98141/195500] Loss: 0.417 Acc: 85.0%

 ** Valid ** Epoch: [251/500] Iter: [98141/195500] Loss: 1.237 Acc: 47.52%

 ** Time 15:34

 ** Train ** Epoch: [252/500] Iter: [98532/195500] Loss: 0.332 Acc: 86.25%

 ** Valid ** Epoch: [252/500] Iter: [98532/195500] Loss: 1.229 Acc: 46.85%

 ** Time 15:34

 ** Train ** Epoch: [253/500] Iter: [98923/195500] Loss: 0.446 Acc: 83.75%

 ** Valid ** Epoch: [253/500] Iter: [98923/195500] Loss: 1.415 Acc: 47.05%

 ** Time 15:34

 ** Train ** Epoch: [254/500] Iter: [99314/195500] Loss: 0.458 Acc: 82.5%

 ** Valid ** Epoch: [254/500] Iter: [99314/195500] Loss: 1.119 Acc: 50.11%

 ** Time 15:35

 ** Train ** Epoch: [255/500] Iter: [99705/195500] Loss: 0.406 Acc: 86.25%

 ** Valid ** Epoch: [255/500] Iter: [99705/195500] Loss: 1.306 Acc: 48.49%

 ** Time 15:35

 ** Train ** Epoch: [256/500] Iter: [100096/195500] Loss: 0.27 Acc: 88.75%

 ** Valid ** Epoch: [256/500] Iter: [100096/195500] Loss: 1.292 Acc: 47.14%

 ** Time 15:35

 ** Train ** Epoch: [257/500] Iter: [100487/195500] Loss: 0.415 Acc: 87.5%

 ** Valid ** Epoch: [257/500] Iter: [100487/195500] Loss: 1.255 Acc: 50.84%

 ** Time 15:35

 ** Train ** Epoch: [258/500] Iter: [100878/195500] Loss: 0.317 Acc: 90.0%

 ** Valid ** Epoch: [258/500] Iter: [100878/195500] Loss: 1.377 Acc: 50.49%

 ** Time 15:35

 ** Train ** Epoch: [259/500] Iter: [101269/195500] Loss: 0.474 Acc: 82.5%

 ** Valid ** Epoch: [259/500] Iter: [101269/195500] Loss: 1.256 Acc: 49.0%

 ** Time 15:35

 ** Train ** Epoch: [260/500] Iter: [101660/195500] Loss: 0.538 Acc: 82.5%

 ** Valid ** Epoch: [260/500] Iter: [101660/195500] Loss: 1.227 Acc: 50.07%

 ** Time 15:35

 ** Train ** Epoch: [261/500] Iter: [102051/195500] Loss: 0.44 Acc: 85.0%

 ** Valid ** Epoch: [261/500] Iter: [102051/195500] Loss: 1.121 Acc: 49.69%

 ** Time 15:35

 ** Train ** Epoch: [262/500] Iter: [102442/195500] Loss: 0.518 Acc: 81.25%

 ** Valid ** Epoch: [262/500] Iter: [102442/195500] Loss: 1.274 Acc: 51.41%

 ** Time 15:36

 ** Train ** Epoch: [263/500] Iter: [102833/195500] Loss: 0.289 Acc: 93.75%

 ** Valid ** Epoch: [263/500] Iter: [102833/195500] Loss: 1.185 Acc: 51.98%

 ** Time 15:36

 ** Train ** Epoch: [264/500] Iter: [103224/195500] Loss: 0.355 Acc: 85.0%

 ** Valid ** Epoch: [264/500] Iter: [103224/195500] Loss: 1.21 Acc: 52.33%

 ** Time 15:36

 ** Train ** Epoch: [265/500] Iter: [103615/195500] Loss: 0.52 Acc: 78.75%

 ** Valid ** Epoch: [265/500] Iter: [103615/195500] Loss: 1.352 Acc: 49.84%

 ** Time 15:36

 ** Train ** Epoch: [266/500] Iter: [104006/195500] Loss: 0.346 Acc: 85.0%

 ** Valid ** Epoch: [266/500] Iter: [104006/195500] Loss: 1.11 Acc: 49.13%

 ** Time 15:36

 ** Train ** Epoch: [267/500] Iter: [104397/195500] Loss: 0.46 Acc: 87.5%

 ** Valid ** Epoch: [267/500] Iter: [104397/195500] Loss: 1.078 Acc: 51.13%

 ** Time 15:36

 ** Train ** Epoch: [268/500] Iter: [104788/195500] Loss: 0.418 Acc: 83.75%

 ** Valid ** Epoch: [268/500] Iter: [104788/195500] Loss: 1.091 Acc: 49.38%

 ** Time 15:36

 ** Train ** Epoch: [269/500] Iter: [105179/195500] Loss: 0.364 Acc: 88.75%

 ** Valid ** Epoch: [269/500] Iter: [105179/195500] Loss: 1.138 Acc: 48.03%

 ** Time 15:37

 ** Train ** Epoch: [270/500] Iter: [105570/195500] Loss: 0.296 Acc: 90.0%

 ** Valid ** Epoch: [270/500] Iter: [105570/195500] Loss: 1.22 Acc: 49.46%

 ** Time 15:37

 ** Train ** Epoch: [271/500] Iter: [105961/195500] Loss: 0.402 Acc: 83.75%

 ** Valid ** Epoch: [271/500] Iter: [105961/195500] Loss: 1.193 Acc: 52.57%

 ** Time 15:37

 ** Train ** Epoch: [272/500] Iter: [106352/195500] Loss: 0.377 Acc: 87.5%

 ** Valid ** Epoch: [272/500] Iter: [106352/195500] Loss: 0.993 Acc: 48.92%

 ** Time 15:37

 ** Train ** Epoch: [273/500] Iter: [106743/195500] Loss: 0.387 Acc: 81.25%

 ** Valid ** Epoch: [273/500] Iter: [106743/195500] Loss: 1.15 Acc: 46.99%

 ** Time 15:37

 ** Train ** Epoch: [274/500] Iter: [107134/195500] Loss: 0.483 Acc: 81.25%

 ** Valid ** Epoch: [274/500] Iter: [107134/195500] Loss: 1.121 Acc: 48.22%

 ** Time 15:37

 ** Train ** Epoch: [275/500] Iter: [107525/195500] Loss: 0.472 Acc: 82.5%

 ** Valid ** Epoch: [275/500] Iter: [107525/195500] Loss: 1.123 Acc: 47.33%

 ** Time 15:37

 ** Train ** Epoch: [276/500] Iter: [107916/195500] Loss: 0.253 Acc: 93.75%

 ** Valid ** Epoch: [276/500] Iter: [107916/195500] Loss: 1.016 Acc: 49.29%

 ** Time 15:37

 ** Train ** Epoch: [277/500] Iter: [108307/195500] Loss: 0.409 Acc: 86.25%

 ** Valid ** Epoch: [277/500] Iter: [108307/195500] Loss: 1.263 Acc: 48.08%

 ** Time 15:38

 ** Train ** Epoch: [278/500] Iter: [108698/195500] Loss: 0.402 Acc: 87.5%

 ** Valid ** Epoch: [278/500] Iter: [108698/195500] Loss: 1.176 Acc: 48.0%

 ** Time 15:38

 ** Train ** Epoch: [279/500] Iter: [109089/195500] Loss: 0.425 Acc: 85.0%

 ** Valid ** Epoch: [279/500] Iter: [109089/195500] Loss: 1.448 Acc: 44.81%

 ** Time 15:38

 ** Train ** Epoch: [280/500] Iter: [109480/195500] Loss: 0.471 Acc: 85.0%

 ** Valid ** Epoch: [280/500] Iter: [109480/195500] Loss: 1.371 Acc: 48.2%

 ** Time 15:38

 ** Train ** Epoch: [281/500] Iter: [109871/195500] Loss: 0.408 Acc: 86.25%

 ** Valid ** Epoch: [281/500] Iter: [109871/195500] Loss: 1.292 Acc: 47.35%

 ** Time 15:38

 ** Train ** Epoch: [282/500] Iter: [110262/195500] Loss: 0.382 Acc: 85.0%

 ** Valid ** Epoch: [282/500] Iter: [110262/195500] Loss: 1.277 Acc: 49.06%

 ** Time 15:38

 ** Train ** Epoch: [283/500] Iter: [110653/195500] Loss: 0.501 Acc: 78.75%

 ** Valid ** Epoch: [283/500] Iter: [110653/195500] Loss: 1.478 Acc: 47.63%

 ** Time 15:38

 ** Train ** Epoch: [284/500] Iter: [111044/195500] Loss: 0.285 Acc: 90.0%

 ** Valid ** Epoch: [284/500] Iter: [111044/195500] Loss: 1.156 Acc: 50.19%

 ** Time 15:39

 ** Train ** Epoch: [285/500] Iter: [111435/195500] Loss: 0.408 Acc: 90.0%

 ** Valid ** Epoch: [285/500] Iter: [111435/195500] Loss: 1.493 Acc: 44.12%

 ** Time 15:39

 ** Train ** Epoch: [286/500] Iter: [111826/195500] Loss: 0.199 Acc: 95.0%

 ** Valid ** Epoch: [286/500] Iter: [111826/195500] Loss: 1.374 Acc: 48.22%

 ** Time 15:39

 ** Train ** Epoch: [287/500] Iter: [112217/195500] Loss: 0.308 Acc: 88.75%

 ** Valid ** Epoch: [287/500] Iter: [112217/195500] Loss: 1.291 Acc: 43.7%

 ** Time 15:39

 ** Train ** Epoch: [288/500] Iter: [112608/195500] Loss: 0.445 Acc: 85.0%

 ** Valid ** Epoch: [288/500] Iter: [112608/195500] Loss: 1.3 Acc: 44.95%

 ** Time 15:39

 ** Train ** Epoch: [289/500] Iter: [112999/195500] Loss: 0.53 Acc: 77.5%

 ** Valid ** Epoch: [289/500] Iter: [112999/195500] Loss: 1.277 Acc: 46.0%

 ** Time 15:39

 ** Train ** Epoch: [290/500] Iter: [113390/195500] Loss: 0.32 Acc: 87.5%

 ** Valid ** Epoch: [290/500] Iter: [113390/195500] Loss: 1.309 Acc: 45.69%

 ** Time 15:39

 ** Train ** Epoch: [291/500] Iter: [113781/195500] Loss: 0.513 Acc: 83.75%

 ** Valid ** Epoch: [291/500] Iter: [113781/195500] Loss: 1.322 Acc: 47.15%

 ** Time 15:39

 ** Train ** Epoch: [292/500] Iter: [114172/195500] Loss: 0.382 Acc: 85.0%

 ** Valid ** Epoch: [292/500] Iter: [114172/195500] Loss: 1.198 Acc: 47.74%

 ** Time 15:40

 ** Train ** Epoch: [293/500] Iter: [114563/195500] Loss: 0.439 Acc: 82.5%

 ** Valid ** Epoch: [293/500] Iter: [114563/195500] Loss: 1.413 Acc: 42.85%

 ** Time 15:40

 ** Train ** Epoch: [294/500] Iter: [114954/195500] Loss: 0.465 Acc: 81.25%

 ** Valid ** Epoch: [294/500] Iter: [114954/195500] Loss: 1.345 Acc: 47.04%

 ** Time 15:40

 ** Train ** Epoch: [295/500] Iter: [115345/195500] Loss: 0.265 Acc: 88.75%

 ** Valid ** Epoch: [295/500] Iter: [115345/195500] Loss: 1.381 Acc: 47.02%

 ** Time 15:40

 ** Train ** Epoch: [296/500] Iter: [115736/195500] Loss: 0.412 Acc: 86.25%

 ** Valid ** Epoch: [296/500] Iter: [115736/195500] Loss: 1.589 Acc: 46.72%

 ** Time 15:40

 ** Train ** Epoch: [297/500] Iter: [116127/195500] Loss: 0.383 Acc: 86.25%

 ** Valid ** Epoch: [297/500] Iter: [116127/195500] Loss: 1.313 Acc: 47.94%

 ** Time 15:40

 ** Train ** Epoch: [298/500] Iter: [116518/195500] Loss: 0.25 Acc: 92.5%

 ** Valid ** Epoch: [298/500] Iter: [116518/195500] Loss: 1.215 Acc: 46.94%

 ** Time 15:40

 ** Train ** Epoch: [299/500] Iter: [116909/195500] Loss: 0.301 Acc: 86.25%

 ** Valid ** Epoch: [299/500] Iter: [116909/195500] Loss: 1.34 Acc: 48.11%

 ** Time 15:40

 ** Train ** Epoch: [300/500] Iter: [117300/195500] Loss: 0.48 Acc: 82.5%

 ** Valid ** Epoch: [300/500] Iter: [117300/195500] Loss: 1.385 Acc: 47.99%

 ** Time 15:41

 ** Train ** Epoch: [301/500] Iter: [117691/195500] Loss: 0.455 Acc: 86.25%

 ** Valid ** Epoch: [301/500] Iter: [117691/195500] Loss: 1.445 Acc: 45.42%

 ** Time 15:41

 ** Train ** Epoch: [302/500] Iter: [118082/195500] Loss: 0.443 Acc: 78.75%

 ** Valid ** Epoch: [302/500] Iter: [118082/195500] Loss: 1.262 Acc: 50.08%

 ** Time 15:41

 ** Train ** Epoch: [303/500] Iter: [118473/195500] Loss: 0.543 Acc: 81.25%

 ** Valid ** Epoch: [303/500] Iter: [118473/195500] Loss: 1.312 Acc: 48.08%

 ** Time 15:41

 ** Train ** Epoch: [304/500] Iter: [118864/195500] Loss: 0.474 Acc: 85.0%

 ** Valid ** Epoch: [304/500] Iter: [118864/195500] Loss: 1.358 Acc: 46.46%

 ** Time 15:41

 ** Train ** Epoch: [305/500] Iter: [119255/195500] Loss: 0.399 Acc: 85.0%

 ** Valid ** Epoch: [305/500] Iter: [119255/195500] Loss: 1.375 Acc: 48.23%

 ** Time 15:41

 ** Train ** Epoch: [306/500] Iter: [119646/195500] Loss: 0.33 Acc: 86.25%

 ** Valid ** Epoch: [306/500] Iter: [119646/195500] Loss: 1.308 Acc: 49.01%

 ** Time 15:41

 ** Train ** Epoch: [307/500] Iter: [120037/195500] Loss: 0.389 Acc: 85.0%

 ** Valid ** Epoch: [307/500] Iter: [120037/195500] Loss: 1.385 Acc: 48.22%

 ** Time 15:42

 ** Train ** Epoch: [308/500] Iter: [120428/195500] Loss: 0.314 Acc: 87.5%

 ** Valid ** Epoch: [308/500] Iter: [120428/195500] Loss: 1.377 Acc: 47.22%

 ** Time 15:42

 ** Train ** Epoch: [309/500] Iter: [120819/195500] Loss: 0.385 Acc: 82.5%

 ** Valid ** Epoch: [309/500] Iter: [120819/195500] Loss: 1.25 Acc: 46.55%

 ** Time 15:42

 ** Train ** Epoch: [310/500] Iter: [121210/195500] Loss: 0.335 Acc: 87.5%

 ** Valid ** Epoch: [310/500] Iter: [121210/195500] Loss: 1.483 Acc: 47.67%

 ** Time 15:42

 ** Train ** Epoch: [311/500] Iter: [121601/195500] Loss: 0.461 Acc: 82.5%

 ** Valid ** Epoch: [311/500] Iter: [121601/195500] Loss: 1.383 Acc: 44.09%

 ** Time 15:42

 ** Train ** Epoch: [312/500] Iter: [121992/195500] Loss: 0.348 Acc: 88.75%

 ** Valid ** Epoch: [312/500] Iter: [121992/195500] Loss: 1.684 Acc: 47.17%

 ** Time 15:42

 ** Train ** Epoch: [313/500] Iter: [122383/195500] Loss: 0.358 Acc: 91.25%

 ** Valid ** Epoch: [313/500] Iter: [122383/195500] Loss: 1.516 Acc: 50.65%

 ** Time 15:42

 ** Train ** Epoch: [314/500] Iter: [122774/195500] Loss: 0.363 Acc: 85.0%

 ** Valid ** Epoch: [314/500] Iter: [122774/195500] Loss: 1.312 Acc: 47.51%

 ** Time 15:42

 ** Train ** Epoch: [315/500] Iter: [123165/195500] Loss: 0.297 Acc: 90.0%

 ** Valid ** Epoch: [315/500] Iter: [123165/195500] Loss: 1.374 Acc: 47.85%

 ** Time 15:43

 ** Train ** Epoch: [316/500] Iter: [123556/195500] Loss: 0.478 Acc: 81.25%

 ** Valid ** Epoch: [316/500] Iter: [123556/195500] Loss: 1.442 Acc: 45.06%

 ** Time 15:43

 ** Train ** Epoch: [317/500] Iter: [123947/195500] Loss: 0.367 Acc: 88.75%

 ** Valid ** Epoch: [317/500] Iter: [123947/195500] Loss: 1.247 Acc: 46.88%

 ** Time 15:43

 ** Train ** Epoch: [318/500] Iter: [124338/195500] Loss: 0.281 Acc: 88.75%

 ** Valid ** Epoch: [318/500] Iter: [124338/195500] Loss: 1.471 Acc: 43.42%

 ** Time 15:43

 ** Train ** Epoch: [319/500] Iter: [124729/195500] Loss: 0.228 Acc: 92.5%

 ** Valid ** Epoch: [319/500] Iter: [124729/195500] Loss: 1.18 Acc: 48.04%

 ** Time 15:43

 ** Train ** Epoch: [320/500] Iter: [125120/195500] Loss: 0.351 Acc: 85.0%

 ** Valid ** Epoch: [320/500] Iter: [125120/195500] Loss: 1.36 Acc: 43.7%

 ** Time 15:43

 ** Train ** Epoch: [321/500] Iter: [125511/195500] Loss: 0.513 Acc: 81.25%

 ** Valid ** Epoch: [321/500] Iter: [125511/195500] Loss: 1.294 Acc: 48.33%

 ** Time 15:43

 ** Train ** Epoch: [322/500] Iter: [125902/195500] Loss: 0.372 Acc: 85.0%

 ** Valid ** Epoch: [322/500] Iter: [125902/195500] Loss: 1.308 Acc: 45.42%

 ** Time 15:44

 ** Train ** Epoch: [323/500] Iter: [126293/195500] Loss: 0.484 Acc: 83.75%

 ** Valid ** Epoch: [323/500] Iter: [126293/195500] Loss: 1.237 Acc: 47.81%

 ** Time 15:44

 ** Train ** Epoch: [324/500] Iter: [126684/195500] Loss: 0.483 Acc: 83.75%

 ** Valid ** Epoch: [324/500] Iter: [126684/195500] Loss: 1.222 Acc: 47.31%

 ** Time 15:44

 ** Train ** Epoch: [325/500] Iter: [127075/195500] Loss: 0.295 Acc: 87.5%

 ** Valid ** Epoch: [325/500] Iter: [127075/195500] Loss: 1.159 Acc: 48.04%

 ** Time 15:44

 ** Train ** Epoch: [326/500] Iter: [127466/195500] Loss: 0.337 Acc: 86.25%

 ** Valid ** Epoch: [326/500] Iter: [127466/195500] Loss: 1.195 Acc: 48.03%

 ** Time 15:44

 ** Train ** Epoch: [327/500] Iter: [127857/195500] Loss: 0.342 Acc: 86.25%

 ** Valid ** Epoch: [327/500] Iter: [127857/195500] Loss: 1.272 Acc: 51.4%

 ** Time 15:44

 ** Train ** Epoch: [328/500] Iter: [128248/195500] Loss: 0.352 Acc: 86.25%

 ** Valid ** Epoch: [328/500] Iter: [128248/195500] Loss: 1.328 Acc: 45.79%

 ** Time 15:44

 ** Train ** Epoch: [329/500] Iter: [128639/195500] Loss: 0.431 Acc: 85.0%

 ** Valid ** Epoch: [329/500] Iter: [128639/195500] Loss: 1.07 Acc: 50.71%

 ** Time 15:44

 ** Train ** Epoch: [330/500] Iter: [129030/195500] Loss: 0.323 Acc: 91.25%

 ** Valid ** Epoch: [330/500] Iter: [129030/195500] Loss: 1.252 Acc: 50.91%

 ** Time 15:45

 ** Train ** Epoch: [331/500] Iter: [129421/195500] Loss: 0.345 Acc: 85.0%

 ** Valid ** Epoch: [331/500] Iter: [129421/195500] Loss: 1.154 Acc: 48.11%

 ** Time 15:45

 ** Train ** Epoch: [332/500] Iter: [129812/195500] Loss: 0.263 Acc: 91.25%

 ** Valid ** Epoch: [332/500] Iter: [129812/195500] Loss: 1.151 Acc: 48.49%

 ** Time 15:45

 ** Train ** Epoch: [333/500] Iter: [130203/195500] Loss: 0.215 Acc: 95.0%

 ** Valid ** Epoch: [333/500] Iter: [130203/195500] Loss: 1.256 Acc: 48.29%

 ** Time 15:45

 ** Train ** Epoch: [334/500] Iter: [130594/195500] Loss: 0.475 Acc: 83.75%

 ** Valid ** Epoch: [334/500] Iter: [130594/195500] Loss: 1.327 Acc: 48.26%

 ** Time 15:45

 ** Train ** Epoch: [335/500] Iter: [130985/195500] Loss: 0.45 Acc: 82.5%

 ** Valid ** Epoch: [335/500] Iter: [130985/195500] Loss: 1.446 Acc: 49.15%

 ** Time 15:45

 ** Train ** Epoch: [336/500] Iter: [131376/195500] Loss: 0.382 Acc: 85.0%

 ** Valid ** Epoch: [336/500] Iter: [131376/195500] Loss: 1.282 Acc: 43.52%

 ** Time 15:45

 ** Train ** Epoch: [337/500] Iter: [131767/195500] Loss: 0.389 Acc: 86.25%

 ** Valid ** Epoch: [337/500] Iter: [131767/195500] Loss: 1.476 Acc: 47.49%

 ** Time 15:46

 ** Train ** Epoch: [338/500] Iter: [132158/195500] Loss: 0.216 Acc: 93.75%

 ** Valid ** Epoch: [338/500] Iter: [132158/195500] Loss: 1.352 Acc: 45.67%

 ** Time 15:46

 ** Train ** Epoch: [339/500] Iter: [132549/195500] Loss: 0.446 Acc: 82.5%

 ** Valid ** Epoch: [339/500] Iter: [132549/195500] Loss: 1.144 Acc: 46.04%

 ** Time 15:46

 ** Train ** Epoch: [340/500] Iter: [132940/195500] Loss: 0.494 Acc: 78.75%

 ** Valid ** Epoch: [340/500] Iter: [132940/195500] Loss: 1.289 Acc: 44.52%

 ** Time 15:46

 ** Train ** Epoch: [341/500] Iter: [133331/195500] Loss: 0.358 Acc: 88.75%

 ** Valid ** Epoch: [341/500] Iter: [133331/195500] Loss: 1.343 Acc: 43.76%

 ** Time 15:46

 ** Train ** Epoch: [342/500] Iter: [133722/195500] Loss: 0.317 Acc: 86.25%

 ** Valid ** Epoch: [342/500] Iter: [133722/195500] Loss: 1.287 Acc: 46.59%

 ** Time 15:46

 ** Train ** Epoch: [343/500] Iter: [134113/195500] Loss: 0.443 Acc: 86.25%

 ** Valid ** Epoch: [343/500] Iter: [134113/195500] Loss: 1.694 Acc: 45.19%

 ** Time 15:46

 ** Train ** Epoch: [344/500] Iter: [134504/195500] Loss: 0.335 Acc: 90.0%

 ** Valid ** Epoch: [344/500] Iter: [134504/195500] Loss: 1.578 Acc: 46.14%

 ** Time 15:46

 ** Train ** Epoch: [345/500] Iter: [134895/195500] Loss: 0.304 Acc: 92.5%

 ** Valid ** Epoch: [345/500] Iter: [134895/195500] Loss: 1.56 Acc: 45.78%

 ** Time 15:47

 ** Train ** Epoch: [346/500] Iter: [135286/195500] Loss: 0.351 Acc: 85.0%

 ** Valid ** Epoch: [346/500] Iter: [135286/195500] Loss: 1.468 Acc: 50.22%

 ** Time 15:47

 ** Train ** Epoch: [347/500] Iter: [135677/195500] Loss: 0.304 Acc: 88.75%

 ** Valid ** Epoch: [347/500] Iter: [135677/195500] Loss: 1.389 Acc: 46.28%

 ** Time 15:47

 ** Train ** Epoch: [348/500] Iter: [136068/195500] Loss: 0.42 Acc: 85.0%

 ** Valid ** Epoch: [348/500] Iter: [136068/195500] Loss: 1.294 Acc: 47.41%

 ** Time 15:47

 ** Train ** Epoch: [349/500] Iter: [136459/195500] Loss: 0.469 Acc: 83.75%

 ** Valid ** Epoch: [349/500] Iter: [136459/195500] Loss: 1.391 Acc: 46.61%

 ** Time 15:47

 ** Train ** Epoch: [350/500] Iter: [136850/195500] Loss: 0.312 Acc: 88.75%

 ** Valid ** Epoch: [350/500] Iter: [136850/195500] Loss: 1.32 Acc: 47.51%

 ** Time 15:47

 ** Train ** Epoch: [351/500] Iter: [137241/195500] Loss: 0.278 Acc: 85.0%

 ** Valid ** Epoch: [351/500] Iter: [137241/195500] Loss: 1.47 Acc: 46.95%

 ** Time 15:47

 ** Train ** Epoch: [352/500] Iter: [137632/195500] Loss: 0.301 Acc: 87.5%

 ** Valid ** Epoch: [352/500] Iter: [137632/195500] Loss: 1.276 Acc: 48.57%

 ** Time 15:48

 ** Train ** Epoch: [353/500] Iter: [138023/195500] Loss: 0.526 Acc: 80.0%

 ** Valid ** Epoch: [353/500] Iter: [138023/195500] Loss: 1.336 Acc: 47.85%

 ** Time 15:48

 ** Train ** Epoch: [354/500] Iter: [138414/195500] Loss: 0.437 Acc: 82.5%

 ** Valid ** Epoch: [354/500] Iter: [138414/195500] Loss: 1.533 Acc: 44.2%

 ** Time 15:48

 ** Train ** Epoch: [355/500] Iter: [138805/195500] Loss: 0.354 Acc: 82.5%

 ** Valid ** Epoch: [355/500] Iter: [138805/195500] Loss: 1.515 Acc: 46.92%

 ** Time 15:48

 ** Train ** Epoch: [356/500] Iter: [139196/195500] Loss: 0.148 Acc: 97.5%

 ** Valid ** Epoch: [356/500] Iter: [139196/195500] Loss: 1.588 Acc: 46.37%

 ** Time 15:48

 ** Train ** Epoch: [357/500] Iter: [139587/195500] Loss: 0.462 Acc: 87.5%

 ** Valid ** Epoch: [357/500] Iter: [139587/195500] Loss: 1.418 Acc: 46.2%

 ** Time 15:48

 ** Train ** Epoch: [358/500] Iter: [139978/195500] Loss: 0.386 Acc: 85.0%

 ** Valid ** Epoch: [358/500] Iter: [139978/195500] Loss: 1.347 Acc: 45.48%

 ** Time 15:48

 ** Train ** Epoch: [359/500] Iter: [140369/195500] Loss: 0.263 Acc: 91.25%

 ** Valid ** Epoch: [359/500] Iter: [140369/195500] Loss: 1.472 Acc: 48.79%

 ** Time 15:48

 ** Train ** Epoch: [360/500] Iter: [140760/195500] Loss: 0.359 Acc: 88.75%

 ** Valid ** Epoch: [360/500] Iter: [140760/195500] Loss: 1.472 Acc: 44.24%

 ** Time 15:49

 ** Train ** Epoch: [361/500] Iter: [141151/195500] Loss: 0.269 Acc: 92.5%

 ** Valid ** Epoch: [361/500] Iter: [141151/195500] Loss: 1.323 Acc: 45.28%

 ** Time 15:49

 ** Train ** Epoch: [362/500] Iter: [141542/195500] Loss: 0.3 Acc: 88.75%

 ** Valid ** Epoch: [362/500] Iter: [141542/195500] Loss: 1.44 Acc: 46.04%

 ** Time 15:49

 ** Train ** Epoch: [363/500] Iter: [141933/195500] Loss: 0.385 Acc: 86.25%

 ** Valid ** Epoch: [363/500] Iter: [141933/195500] Loss: 1.221 Acc: 45.73%

 ** Time 15:49

 ** Train ** Epoch: [364/500] Iter: [142324/195500] Loss: 0.582 Acc: 81.25%

 ** Valid ** Epoch: [364/500] Iter: [142324/195500] Loss: 1.229 Acc: 50.85%

 ** Time 15:49

 ** Train ** Epoch: [365/500] Iter: [142715/195500] Loss: 0.271 Acc: 88.75%

 ** Valid ** Epoch: [365/500] Iter: [142715/195500] Loss: 1.414 Acc: 49.08%

 ** Time 15:49

 ** Train ** Epoch: [366/500] Iter: [143106/195500] Loss: 0.441 Acc: 86.25%

 ** Valid ** Epoch: [366/500] Iter: [143106/195500] Loss: 1.441 Acc: 44.36%

 ** Time 15:49

 ** Train ** Epoch: [367/500] Iter: [143497/195500] Loss: 0.333 Acc: 87.5%

 ** Valid ** Epoch: [367/500] Iter: [143497/195500] Loss: 1.477 Acc: 44.33%

 ** Time 15:49

 ** Train ** Epoch: [368/500] Iter: [143888/195500] Loss: 0.315 Acc: 90.0%

 ** Valid ** Epoch: [368/500] Iter: [143888/195500] Loss: 1.308 Acc: 44.79%

 ** Time 15:50

 ** Train ** Epoch: [369/500] Iter: [144279/195500] Loss: 0.436 Acc: 81.25%

 ** Valid ** Epoch: [369/500] Iter: [144279/195500] Loss: 1.099 Acc: 46.72%

 ** Time 15:50

 ** Train ** Epoch: [370/500] Iter: [144670/195500] Loss: 0.429 Acc: 81.25%

 ** Valid ** Epoch: [370/500] Iter: [144670/195500] Loss: 1.225 Acc: 47.17%

 ** Time 15:50

 ** Train ** Epoch: [371/500] Iter: [145061/195500] Loss: 0.367 Acc: 88.75%

 ** Valid ** Epoch: [371/500] Iter: [145061/195500] Loss: 1.34 Acc: 45.44%

 ** Time 15:50

 ** Train ** Epoch: [372/500] Iter: [145452/195500] Loss: 0.389 Acc: 87.5%

 ** Valid ** Epoch: [372/500] Iter: [145452/195500] Loss: 1.403 Acc: 46.8%

 ** Time 15:50

 ** Train ** Epoch: [373/500] Iter: [145843/195500] Loss: 0.234 Acc: 93.75%

 ** Valid ** Epoch: [373/500] Iter: [145843/195500] Loss: 1.46 Acc: 49.37%

 ** Time 15:50

 ** Train ** Epoch: [374/500] Iter: [146234/195500] Loss: 0.329 Acc: 86.25%

 ** Valid ** Epoch: [374/500] Iter: [146234/195500] Loss: 1.461 Acc: 46.56%

 ** Time 15:50

 ** Train ** Epoch: [375/500] Iter: [146625/195500] Loss: 0.232 Acc: 95.0%

 ** Valid ** Epoch: [375/500] Iter: [146625/195500] Loss: 1.558 Acc: 45.66%

 ** Time 15:51

 ** Train ** Epoch: [376/500] Iter: [147016/195500] Loss: 0.46 Acc: 82.5%

 ** Valid ** Epoch: [376/500] Iter: [147016/195500] Loss: 1.53 Acc: 47.52%

 ** Time 15:51

 ** Train ** Epoch: [377/500] Iter: [147407/195500] Loss: 0.367 Acc: 85.0%

 ** Valid ** Epoch: [377/500] Iter: [147407/195500] Loss: 1.576 Acc: 46.4%

 ** Time 15:51

 ** Train ** Epoch: [378/500] Iter: [147798/195500] Loss: 0.33 Acc: 87.5%

 ** Valid ** Epoch: [378/500] Iter: [147798/195500] Loss: 1.312 Acc: 47.97%

 ** Time 15:51

 ** Train ** Epoch: [379/500] Iter: [148189/195500] Loss: 0.212 Acc: 92.5%

 ** Valid ** Epoch: [379/500] Iter: [148189/195500] Loss: 1.505 Acc: 48.58%

 ** Time 15:51

 ** Train ** Epoch: [380/500] Iter: [148580/195500] Loss: 0.483 Acc: 86.25%

 ** Valid ** Epoch: [380/500] Iter: [148580/195500] Loss: 1.454 Acc: 47.73%

 ** Time 15:51

 ** Train ** Epoch: [381/500] Iter: [148971/195500] Loss: 0.376 Acc: 88.75%

 ** Valid ** Epoch: [381/500] Iter: [148971/195500] Loss: 1.387 Acc: 47.95%

 ** Time 15:51

 ** Train ** Epoch: [382/500] Iter: [149362/195500] Loss: 0.305 Acc: 87.5%

 ** Valid ** Epoch: [382/500] Iter: [149362/195500] Loss: 1.469 Acc: 43.87%

 ** Time 15:51

 ** Train ** Epoch: [383/500] Iter: [149753/195500] Loss: 0.439 Acc: 80.0%

 ** Valid ** Epoch: [383/500] Iter: [149753/195500] Loss: 1.38 Acc: 42.69%

 ** Time 15:52

 ** Train ** Epoch: [384/500] Iter: [150144/195500] Loss: 0.263 Acc: 90.0%

 ** Valid ** Epoch: [384/500] Iter: [150144/195500] Loss: 1.562 Acc: 40.46%

 ** Time 15:52

 ** Train ** Epoch: [385/500] Iter: [150535/195500] Loss: 0.47 Acc: 83.75%

 ** Valid ** Epoch: [385/500] Iter: [150535/195500] Loss: 1.467 Acc: 45.6%

 ** Time 15:52

 ** Train ** Epoch: [386/500] Iter: [150926/195500] Loss: 0.286 Acc: 91.25%

 ** Valid ** Epoch: [386/500] Iter: [150926/195500] Loss: 1.468 Acc: 49.89%

 ** Time 15:52

 ** Train ** Epoch: [387/500] Iter: [151317/195500] Loss: 0.325 Acc: 86.25%

 ** Valid ** Epoch: [387/500] Iter: [151317/195500] Loss: 1.474 Acc: 48.63%

 ** Time 15:52

 ** Train ** Epoch: [388/500] Iter: [151708/195500] Loss: 0.331 Acc: 87.5%

 ** Valid ** Epoch: [388/500] Iter: [151708/195500] Loss: 1.236 Acc: 50.04%

 ** Time 15:52

 ** Train ** Epoch: [389/500] Iter: [152099/195500] Loss: 0.58 Acc: 81.25%

 ** Valid ** Epoch: [389/500] Iter: [152099/195500] Loss: 1.476 Acc: 45.69%

 ** Time 15:52

 ** Train ** Epoch: [390/500] Iter: [152490/195500] Loss: 0.416 Acc: 87.5%

 ** Valid ** Epoch: [390/500] Iter: [152490/195500] Loss: 1.466 Acc: 45.19%

 ** Time 15:53

 ** Train ** Epoch: [391/500] Iter: [152881/195500] Loss: 0.264 Acc: 93.75%

 ** Valid ** Epoch: [391/500] Iter: [152881/195500] Loss: 1.173 Acc: 47.15%

 ** Time 15:53

 ** Train ** Epoch: [392/500] Iter: [153272/195500] Loss: 0.249 Acc: 90.0%

 ** Valid ** Epoch: [392/500] Iter: [153272/195500] Loss: 1.338 Acc: 45.04%

 ** Time 15:53

 ** Train ** Epoch: [393/500] Iter: [153663/195500] Loss: 0.364 Acc: 88.75%

 ** Valid ** Epoch: [393/500] Iter: [153663/195500] Loss: 1.681 Acc: 43.33%

 ** Time 15:53

 ** Train ** Epoch: [394/500] Iter: [154054/195500] Loss: 0.279 Acc: 91.25%

 ** Valid ** Epoch: [394/500] Iter: [154054/195500] Loss: 1.438 Acc: 44.54%

 ** Time 15:53

 ** Train ** Epoch: [395/500] Iter: [154445/195500] Loss: 0.383 Acc: 87.5%

 ** Valid ** Epoch: [395/500] Iter: [154445/195500] Loss: 2.113 Acc: 37.48%

 ** Time 15:53

 ** Train ** Epoch: [396/500] Iter: [154836/195500] Loss: 0.335 Acc: 90.0%

 ** Valid ** Epoch: [396/500] Iter: [154836/195500] Loss: 1.67 Acc: 41.33%

 ** Time 15:53

 ** Train ** Epoch: [397/500] Iter: [155227/195500] Loss: 0.332 Acc: 90.0%

 ** Valid ** Epoch: [397/500] Iter: [155227/195500] Loss: 1.754 Acc: 44.01%

 ** Time 15:53

 ** Train ** Epoch: [398/500] Iter: [155618/195500] Loss: 0.335 Acc: 87.5%

 ** Valid ** Epoch: [398/500] Iter: [155618/195500] Loss: 1.567 Acc: 47.09%

 ** Time 15:54

 ** Train ** Epoch: [399/500] Iter: [156009/195500] Loss: 0.432 Acc: 82.5%

 ** Valid ** Epoch: [399/500] Iter: [156009/195500] Loss: 1.821 Acc: 43.88%

** Changing LR to 0.0001 


 ** Time 15:54

 ** Train ** Epoch: [400/500] Iter: [156400/195500] Loss: 0.346 Acc: 86.25%

 ** Valid ** Epoch: [400/500] Iter: [156400/195500] Loss: 1.718 Acc: 45.97%

 ** Time 15:54

 ** Train ** Epoch: [401/500] Iter: [156791/195500] Loss: 0.206 Acc: 93.75%

 ** Valid ** Epoch: [401/500] Iter: [156791/195500] Loss: 1.771 Acc: 46.23%

 ** Time 15:54

 ** Train ** Epoch: [402/500] Iter: [157182/195500] Loss: 0.356 Acc: 88.75%

 ** Valid ** Epoch: [402/500] Iter: [157182/195500] Loss: 1.71 Acc: 46.12%

 ** Time 15:54

 ** Train ** Epoch: [403/500] Iter: [157573/195500] Loss: 0.205 Acc: 95.0%

 ** Valid ** Epoch: [403/500] Iter: [157573/195500] Loss: 1.586 Acc: 46.46%

 ** Time 15:54

 ** Train ** Epoch: [404/500] Iter: [157964/195500] Loss: 0.274 Acc: 87.5%

 ** Valid ** Epoch: [404/500] Iter: [157964/195500] Loss: 1.663 Acc: 45.69%

 ** Time 15:54

 ** Train ** Epoch: [405/500] Iter: [158355/195500] Loss: 0.295 Acc: 91.25%

 ** Valid ** Epoch: [405/500] Iter: [158355/195500] Loss: 1.686 Acc: 45.3%

 ** Time 15:55

 ** Train ** Epoch: [406/500] Iter: [158746/195500] Loss: 0.317 Acc: 90.0%

 ** Valid ** Epoch: [406/500] Iter: [158746/195500] Loss: 1.593 Acc: 45.18%

 ** Time 15:55

 ** Train ** Epoch: [407/500] Iter: [159137/195500] Loss: 0.378 Acc: 86.25%

 ** Valid ** Epoch: [407/500] Iter: [159137/195500] Loss: 1.656 Acc: 44.47%

 ** Time 15:55

 ** Train ** Epoch: [408/500] Iter: [159528/195500] Loss: 0.229 Acc: 91.25%

 ** Valid ** Epoch: [408/500] Iter: [159528/195500] Loss: 1.644 Acc: 45.95%

 ** Time 15:55

 ** Train ** Epoch: [409/500] Iter: [159919/195500] Loss: 0.256 Acc: 91.25%

 ** Valid ** Epoch: [409/500] Iter: [159919/195500] Loss: 1.661 Acc: 45.55%

 ** Time 15:55

 ** Train ** Epoch: [410/500] Iter: [160310/195500] Loss: 0.298 Acc: 87.5%

 ** Valid ** Epoch: [410/500] Iter: [160310/195500] Loss: 1.738 Acc: 44.94%

 ** Time 15:55

 ** Train ** Epoch: [411/500] Iter: [160701/195500] Loss: 0.243 Acc: 95.0%

 ** Valid ** Epoch: [411/500] Iter: [160701/195500] Loss: 1.699 Acc: 44.38%

 ** Time 15:55

 ** Train ** Epoch: [412/500] Iter: [161092/195500] Loss: 0.199 Acc: 92.5%

 ** Valid ** Epoch: [412/500] Iter: [161092/195500] Loss: 1.692 Acc: 44.66%

 ** Time 15:55

 ** Train ** Epoch: [413/500] Iter: [161483/195500] Loss: 0.487 Acc: 82.5%

 ** Valid ** Epoch: [413/500] Iter: [161483/195500] Loss: 1.656 Acc: 45.27%

 ** Time 15:56

 ** Train ** Epoch: [414/500] Iter: [161874/195500] Loss: 0.37 Acc: 91.25%

 ** Valid ** Epoch: [414/500] Iter: [161874/195500] Loss: 1.675 Acc: 44.88%

 ** Time 15:56

 ** Train ** Epoch: [415/500] Iter: [162265/195500] Loss: 0.442 Acc: 85.0%

 ** Valid ** Epoch: [415/500] Iter: [162265/195500] Loss: 1.78 Acc: 44.25%

 ** Time 15:56

 ** Train ** Epoch: [416/500] Iter: [162656/195500] Loss: 0.279 Acc: 92.5%

 ** Valid ** Epoch: [416/500] Iter: [162656/195500] Loss: 1.808 Acc: 44.19%

 ** Time 15:56

 ** Train ** Epoch: [417/500] Iter: [163047/195500] Loss: 0.266 Acc: 90.0%

 ** Valid ** Epoch: [417/500] Iter: [163047/195500] Loss: 1.81 Acc: 44.46%

 ** Time 15:56

 ** Train ** Epoch: [418/500] Iter: [163438/195500] Loss: 0.198 Acc: 96.25%

 ** Valid ** Epoch: [418/500] Iter: [163438/195500] Loss: 1.791 Acc: 43.68%

 ** Time 15:56

 ** Train ** Epoch: [419/500] Iter: [163829/195500] Loss: 0.309 Acc: 88.75%

 ** Valid ** Epoch: [419/500] Iter: [163829/195500] Loss: 1.759 Acc: 43.94%

 ** Time 15:56

 ** Train ** Epoch: [420/500] Iter: [164220/195500] Loss: 0.148 Acc: 96.25%

 ** Valid ** Epoch: [420/500] Iter: [164220/195500] Loss: 1.771 Acc: 44.25%

 ** Time 15:57

 ** Train ** Epoch: [421/500] Iter: [164611/195500] Loss: 0.237 Acc: 93.75%

 ** Valid ** Epoch: [421/500] Iter: [164611/195500] Loss: 1.737 Acc: 43.94%

 ** Time 15:57

 ** Train ** Epoch: [422/500] Iter: [165002/195500] Loss: 0.256 Acc: 90.0%

 ** Valid ** Epoch: [422/500] Iter: [165002/195500] Loss: 1.785 Acc: 44.33%

 ** Time 15:57

 ** Train ** Epoch: [423/500] Iter: [165393/195500] Loss: 0.299 Acc: 87.5%

 ** Valid ** Epoch: [423/500] Iter: [165393/195500] Loss: 1.719 Acc: 44.06%

 ** Time 15:57

 ** Train ** Epoch: [424/500] Iter: [165784/195500] Loss: 0.187 Acc: 92.5%

 ** Valid ** Epoch: [424/500] Iter: [165784/195500] Loss: 1.761 Acc: 44.88%

 ** Time 15:57

 ** Train ** Epoch: [425/500] Iter: [166175/195500] Loss: 0.313 Acc: 91.25%

 ** Valid ** Epoch: [425/500] Iter: [166175/195500] Loss: 1.622 Acc: 44.4%

 ** Time 15:57

 ** Train ** Epoch: [426/500] Iter: [166566/195500] Loss: 0.369 Acc: 90.0%

 ** Valid ** Epoch: [426/500] Iter: [166566/195500] Loss: 1.723 Acc: 45.25%

 ** Time 15:57

 ** Train ** Epoch: [427/500] Iter: [166957/195500] Loss: 0.311 Acc: 87.5%

 ** Valid ** Epoch: [427/500] Iter: [166957/195500] Loss: 1.753 Acc: 44.72%

 ** Time 15:57

 ** Train ** Epoch: [428/500] Iter: [167348/195500] Loss: 0.346 Acc: 88.75%

 ** Valid ** Epoch: [428/500] Iter: [167348/195500] Loss: 1.761 Acc: 44.54%

 ** Time 15:58

 ** Train ** Epoch: [429/500] Iter: [167739/195500] Loss: 0.325 Acc: 92.5%

 ** Valid ** Epoch: [429/500] Iter: [167739/195500] Loss: 1.674 Acc: 44.63%

 ** Time 15:58

 ** Train ** Epoch: [430/500] Iter: [168130/195500] Loss: 0.182 Acc: 92.5%

 ** Valid ** Epoch: [430/500] Iter: [168130/195500] Loss: 1.657 Acc: 44.09%

 ** Time 15:58

 ** Train ** Epoch: [431/500] Iter: [168521/195500] Loss: 0.367 Acc: 88.75%

 ** Valid ** Epoch: [431/500] Iter: [168521/195500] Loss: 1.661 Acc: 44.0%

 ** Time 15:58

 ** Train ** Epoch: [432/500] Iter: [168912/195500] Loss: 0.253 Acc: 93.75%

 ** Valid ** Epoch: [432/500] Iter: [168912/195500] Loss: 1.65 Acc: 44.37%

 ** Time 15:58

 ** Train ** Epoch: [433/500] Iter: [169303/195500] Loss: 0.295 Acc: 88.75%

 ** Valid ** Epoch: [433/500] Iter: [169303/195500] Loss: 1.741 Acc: 44.34%

 ** Time 15:58

 ** Train ** Epoch: [434/500] Iter: [169694/195500] Loss: 0.279 Acc: 91.25%

 ** Valid ** Epoch: [434/500] Iter: [169694/195500] Loss: 1.66 Acc: 45.04%

 ** Time 15:58

 ** Train ** Epoch: [435/500] Iter: [170085/195500] Loss: 0.296 Acc: 90.0%

 ** Valid ** Epoch: [435/500] Iter: [170085/195500] Loss: 1.756 Acc: 43.93%

 ** Time 15:59

 ** Train ** Epoch: [436/500] Iter: [170476/195500] Loss: 0.217 Acc: 88.75%

 ** Valid ** Epoch: [436/500] Iter: [170476/195500] Loss: 1.751 Acc: 43.35%

 ** Time 15:59

 ** Train ** Epoch: [437/500] Iter: [170867/195500] Loss: 0.215 Acc: 96.25%

 ** Valid ** Epoch: [437/500] Iter: [170867/195500] Loss: 1.746 Acc: 44.55%

 ** Time 15:59

 ** Train ** Epoch: [438/500] Iter: [171258/195500] Loss: 0.248 Acc: 92.5%

 ** Valid ** Epoch: [438/500] Iter: [171258/195500] Loss: 1.681 Acc: 45.25%

 ** Time 15:59

 ** Train ** Epoch: [439/500] Iter: [171649/195500] Loss: 0.249 Acc: 91.25%

 ** Valid ** Epoch: [439/500] Iter: [171649/195500] Loss: 1.612 Acc: 43.92%

 ** Time 15:59

 ** Train ** Epoch: [440/500] Iter: [172040/195500] Loss: 0.169 Acc: 96.25%

 ** Valid ** Epoch: [440/500] Iter: [172040/195500] Loss: 1.577 Acc: 44.54%

 ** Time 15:59

 ** Train ** Epoch: [441/500] Iter: [172431/195500] Loss: 0.2 Acc: 96.25%

 ** Valid ** Epoch: [441/500] Iter: [172431/195500] Loss: 1.499 Acc: 45.99%

 ** Time 15:59

 ** Train ** Epoch: [442/500] Iter: [172822/195500] Loss: 0.23 Acc: 91.25%

 ** Valid ** Epoch: [442/500] Iter: [172822/195500] Loss: 1.63 Acc: 44.95%

 ** Time 15:59

 ** Train ** Epoch: [443/500] Iter: [173213/195500] Loss: 0.224 Acc: 91.25%

 ** Valid ** Epoch: [443/500] Iter: [173213/195500] Loss: 1.581 Acc: 44.0%

 ** Time 16:0

 ** Train ** Epoch: [444/500] Iter: [173604/195500] Loss: 0.388 Acc: 87.5%

 ** Valid ** Epoch: [444/500] Iter: [173604/195500] Loss: 1.674 Acc: 43.47%

 ** Time 16:0

 ** Train ** Epoch: [445/500] Iter: [173995/195500] Loss: 0.276 Acc: 88.75%

 ** Valid ** Epoch: [445/500] Iter: [173995/195500] Loss: 1.691 Acc: 44.04%

 ** Time 16:0

 ** Train ** Epoch: [446/500] Iter: [174386/195500] Loss: 0.288 Acc: 88.75%

 ** Valid ** Epoch: [446/500] Iter: [174386/195500] Loss: 1.695 Acc: 44.28%

 ** Time 16:0

 ** Train ** Epoch: [447/500] Iter: [174777/195500] Loss: 0.197 Acc: 95.0%

 ** Valid ** Epoch: [447/500] Iter: [174777/195500] Loss: 1.715 Acc: 44.31%

 ** Time 16:0

 ** Train ** Epoch: [448/500] Iter: [175168/195500] Loss: 0.253 Acc: 91.25%

 ** Valid ** Epoch: [448/500] Iter: [175168/195500] Loss: 1.735 Acc: 44.33%

 ** Time 16:0

 ** Train ** Epoch: [449/500] Iter: [175559/195500] Loss: 0.196 Acc: 92.5%

 ** Valid ** Epoch: [449/500] Iter: [175559/195500] Loss: 1.729 Acc: 45.16%

 ** Time 16:0

 ** Train ** Epoch: [450/500] Iter: [175950/195500] Loss: 0.201 Acc: 93.75%

 ** Valid ** Epoch: [450/500] Iter: [175950/195500] Loss: 1.702 Acc: 44.24%

 ** Time 16:1

 ** Train ** Epoch: [451/500] Iter: [176341/195500] Loss: 0.18 Acc: 95.0%

 ** Valid ** Epoch: [451/500] Iter: [176341/195500] Loss: 1.776 Acc: 43.04%

 ** Time 16:1

 ** Train ** Epoch: [452/500] Iter: [176732/195500] Loss: 0.317 Acc: 90.0%

 ** Valid ** Epoch: [452/500] Iter: [176732/195500] Loss: 1.739 Acc: 44.27%

 ** Time 16:1

 ** Train ** Epoch: [453/500] Iter: [177123/195500] Loss: 0.223 Acc: 91.25%

 ** Valid ** Epoch: [453/500] Iter: [177123/195500] Loss: 1.76 Acc: 44.17%

 ** Time 16:1

 ** Train ** Epoch: [454/500] Iter: [177514/195500] Loss: 0.235 Acc: 91.25%

 ** Valid ** Epoch: [454/500] Iter: [177514/195500] Loss: 1.727 Acc: 44.92%

 ** Time 16:1

 ** Train ** Epoch: [455/500] Iter: [177905/195500] Loss: 0.431 Acc: 83.75%

 ** Valid ** Epoch: [455/500] Iter: [177905/195500] Loss: 1.678 Acc: 44.79%

 ** Time 16:1

 ** Train ** Epoch: [456/500] Iter: [178296/195500] Loss: 0.245 Acc: 90.0%

 ** Valid ** Epoch: [456/500] Iter: [178296/195500] Loss: 1.733 Acc: 44.54%

 ** Time 16:1

 ** Train ** Epoch: [457/500] Iter: [178687/195500] Loss: 0.362 Acc: 88.75%

 ** Valid ** Epoch: [457/500] Iter: [178687/195500] Loss: 1.761 Acc: 43.83%

 ** Time 16:1

 ** Train ** Epoch: [458/500] Iter: [179078/195500] Loss: 0.437 Acc: 86.25%

 ** Valid ** Epoch: [458/500] Iter: [179078/195500] Loss: 1.682 Acc: 44.33%

 ** Time 16:2

 ** Train ** Epoch: [459/500] Iter: [179469/195500] Loss: 0.181 Acc: 92.5%

 ** Valid ** Epoch: [459/500] Iter: [179469/195500] Loss: 1.724 Acc: 44.04%

 ** Time 16:2

 ** Train ** Epoch: [460/500] Iter: [179860/195500] Loss: 0.345 Acc: 90.0%

 ** Valid ** Epoch: [460/500] Iter: [179860/195500] Loss: 1.663 Acc: 44.3%

 ** Time 16:2

 ** Train ** Epoch: [461/500] Iter: [180251/195500] Loss: 0.244 Acc: 90.0%

 ** Valid ** Epoch: [461/500] Iter: [180251/195500] Loss: 1.643 Acc: 44.53%

 ** Time 16:2

 ** Train ** Epoch: [462/500] Iter: [180642/195500] Loss: 0.337 Acc: 90.0%

 ** Valid ** Epoch: [462/500] Iter: [180642/195500] Loss: 1.65 Acc: 44.36%

 ** Time 16:2

 ** Train ** Epoch: [463/500] Iter: [181033/195500] Loss: 0.206 Acc: 90.0%

 ** Valid ** Epoch: [463/500] Iter: [181033/195500] Loss: 1.656 Acc: 44.81%

 ** Time 16:2

 ** Train ** Epoch: [464/500] Iter: [181424/195500] Loss: 0.251 Acc: 91.25%

 ** Valid ** Epoch: [464/500] Iter: [181424/195500] Loss: 1.568 Acc: 45.3%

 ** Time 16:2

 ** Train ** Epoch: [465/500] Iter: [181815/195500] Loss: 0.376 Acc: 86.25%

 ** Valid ** Epoch: [465/500] Iter: [181815/195500] Loss: 1.615 Acc: 44.73%

 ** Time 16:3

 ** Train ** Epoch: [466/500] Iter: [182206/195500] Loss: 0.39 Acc: 81.25%

 ** Valid ** Epoch: [466/500] Iter: [182206/195500] Loss: 1.635 Acc: 45.34%

 ** Time 16:3

 ** Train ** Epoch: [467/500] Iter: [182597/195500] Loss: 0.304 Acc: 82.5%

 ** Valid ** Epoch: [467/500] Iter: [182597/195500] Loss: 1.711 Acc: 44.74%

 ** Time 16:3

 ** Train ** Epoch: [468/500] Iter: [182988/195500] Loss: 0.305 Acc: 87.5%

 ** Valid ** Epoch: [468/500] Iter: [182988/195500] Loss: 1.687 Acc: 44.36%

 ** Time 16:3

 ** Train ** Epoch: [469/500] Iter: [183379/195500] Loss: 0.365 Acc: 90.0%

 ** Valid ** Epoch: [469/500] Iter: [183379/195500] Loss: 1.637 Acc: 44.58%

 ** Time 16:3

 ** Train ** Epoch: [470/500] Iter: [183770/195500] Loss: 0.184 Acc: 93.75%

 ** Valid ** Epoch: [470/500] Iter: [183770/195500] Loss: 1.676 Acc: 44.64%

 ** Time 16:3

 ** Train ** Epoch: [471/500] Iter: [184161/195500] Loss: 0.234 Acc: 90.0%

 ** Valid ** Epoch: [471/500] Iter: [184161/195500] Loss: 1.644 Acc: 43.91%

 ** Time 16:3

 ** Train ** Epoch: [472/500] Iter: [184552/195500] Loss: 0.134 Acc: 95.0%

 ** Valid ** Epoch: [472/500] Iter: [184552/195500] Loss: 1.652 Acc: 45.03%

 ** Time 16:3

 ** Train ** Epoch: [473/500] Iter: [184943/195500] Loss: 0.205 Acc: 92.5%

 ** Valid ** Epoch: [473/500] Iter: [184943/195500] Loss: 1.668 Acc: 44.27%

 ** Time 16:4

 ** Train ** Epoch: [474/500] Iter: [185334/195500] Loss: 0.195 Acc: 90.0%

 ** Valid ** Epoch: [474/500] Iter: [185334/195500] Loss: 1.706 Acc: 44.4%

 ** Time 16:4

 ** Train ** Epoch: [475/500] Iter: [185725/195500] Loss: 0.281 Acc: 88.75%

 ** Valid ** Epoch: [475/500] Iter: [185725/195500] Loss: 1.713 Acc: 43.9%

 ** Time 16:4

 ** Train ** Epoch: [476/500] Iter: [186116/195500] Loss: 0.218 Acc: 90.0%

 ** Valid ** Epoch: [476/500] Iter: [186116/195500] Loss: 1.721 Acc: 43.61%

 ** Time 16:4

 ** Train ** Epoch: [477/500] Iter: [186507/195500] Loss: 0.27 Acc: 88.75%

 ** Valid ** Epoch: [477/500] Iter: [186507/195500] Loss: 1.725 Acc: 43.74%

 ** Time 16:4

 ** Train ** Epoch: [478/500] Iter: [186898/195500] Loss: 0.395 Acc: 88.75%

 ** Valid ** Epoch: [478/500] Iter: [186898/195500] Loss: 1.669 Acc: 45.38%

 ** Time 16:4

 ** Train ** Epoch: [479/500] Iter: [187289/195500] Loss: 0.384 Acc: 85.0%

 ** Valid ** Epoch: [479/500] Iter: [187289/195500] Loss: 1.714 Acc: 44.2%

 ** Time 16:4

 ** Train ** Epoch: [480/500] Iter: [187680/195500] Loss: 0.302 Acc: 90.0%

 ** Valid ** Epoch: [480/500] Iter: [187680/195500] Loss: 1.651 Acc: 43.72%

 ** Time 16:4

 ** Train ** Epoch: [481/500] Iter: [188071/195500] Loss: 0.342 Acc: 87.5%

 ** Valid ** Epoch: [481/500] Iter: [188071/195500] Loss: 1.645 Acc: 44.74%

 ** Time 16:5

 ** Train ** Epoch: [482/500] Iter: [188462/195500] Loss: 0.31 Acc: 90.0%

 ** Valid ** Epoch: [482/500] Iter: [188462/195500] Loss: 1.65 Acc: 44.95%

 ** Time 16:5

 ** Train ** Epoch: [483/500] Iter: [188853/195500] Loss: 0.248 Acc: 92.5%

 ** Valid ** Epoch: [483/500] Iter: [188853/195500] Loss: 1.657 Acc: 44.78%

 ** Time 16:5

 ** Train ** Epoch: [484/500] Iter: [189244/195500] Loss: 0.176 Acc: 93.75%

 ** Valid ** Epoch: [484/500] Iter: [189244/195500] Loss: 1.687 Acc: 44.66%

 ** Time 16:5

 ** Train ** Epoch: [485/500] Iter: [189635/195500] Loss: 0.224 Acc: 95.0%

 ** Valid ** Epoch: [485/500] Iter: [189635/195500] Loss: 1.7 Acc: 44.17%

 ** Time 16:5

 ** Train ** Epoch: [486/500] Iter: [190026/195500] Loss: 0.239 Acc: 91.25%

 ** Valid ** Epoch: [486/500] Iter: [190026/195500] Loss: 1.71 Acc: 44.07%

 ** Time 16:5

 ** Train ** Epoch: [487/500] Iter: [190417/195500] Loss: 0.232 Acc: 91.25%

 ** Valid ** Epoch: [487/500] Iter: [190417/195500] Loss: 1.75 Acc: 43.64%

 ** Time 16:5

 ** Train ** Epoch: [488/500] Iter: [190808/195500] Loss: 0.156 Acc: 93.75%

 ** Valid ** Epoch: [488/500] Iter: [190808/195500] Loss: 1.714 Acc: 43.8%

 ** Time 16:6

 ** Train ** Epoch: [489/500] Iter: [191199/195500] Loss: 0.232 Acc: 88.75%

 ** Valid ** Epoch: [489/500] Iter: [191199/195500] Loss: 1.622 Acc: 44.88%

 ** Time 16:6

 ** Train ** Epoch: [490/500] Iter: [191590/195500] Loss: 0.231 Acc: 92.5%

 ** Valid ** Epoch: [490/500] Iter: [191590/195500] Loss: 1.627 Acc: 44.47%

 ** Time 16:6

 ** Train ** Epoch: [491/500] Iter: [191981/195500] Loss: 0.507 Acc: 86.25%

 ** Valid ** Epoch: [491/500] Iter: [191981/195500] Loss: 1.592 Acc: 45.31%

 ** Time 16:6

 ** Train ** Epoch: [492/500] Iter: [192372/195500] Loss: 0.272 Acc: 92.5%

 ** Valid ** Epoch: [492/500] Iter: [192372/195500] Loss: 1.621 Acc: 45.22%

 ** Time 16:6

 ** Train ** Epoch: [493/500] Iter: [192763/195500] Loss: 0.171 Acc: 93.75%

 ** Valid ** Epoch: [493/500] Iter: [192763/195500] Loss: 1.624 Acc: 45.0%

 ** Time 16:6

 ** Train ** Epoch: [494/500] Iter: [193154/195500] Loss: 0.174 Acc: 92.5%

 ** Valid ** Epoch: [494/500] Iter: [193154/195500] Loss: 1.643 Acc: 44.86%

 ** Time 16:6

 ** Train ** Epoch: [495/500] Iter: [193545/195500] Loss: 0.256 Acc: 91.25%

 ** Valid ** Epoch: [495/500] Iter: [193545/195500] Loss: 1.67 Acc: 44.71%

 ** Time 16:6

 ** Train ** Epoch: [496/500] Iter: [193936/195500] Loss: 0.224 Acc: 90.0%

 ** Valid ** Epoch: [496/500] Iter: [193936/195500] Loss: 1.707 Acc: 44.16%

 ** Time 16:7

 ** Train ** Epoch: [497/500] Iter: [194327/195500] Loss: 0.196 Acc: 93.75%

 ** Valid ** Epoch: [497/500] Iter: [194327/195500] Loss: 1.755 Acc: 44.92%

 ** Time 16:7

 ** Train ** Epoch: [498/500] Iter: [194718/195500] Loss: 0.255 Acc: 87.5%

 ** Valid ** Epoch: [498/500] Iter: [194718/195500] Loss: 1.723 Acc: 45.28%

 ** Time 16:7

 ** Train ** Epoch: [499/500] Iter: [195109/195500] Loss: 0.281 Acc: 87.5%

 ** Valid ** Epoch: [499/500] Iter: [195109/195500] Loss: 1.706 Acc: 45.11%

 ** Time 16:7

 ** Train ** Epoch: [500/500] Iter: [195500/195500] Loss: 0.153 Acc: 91.25%

 ** Valid ** Epoch: [500/500] Iter: [195500/195500] Loss: 1.631 Acc: 45.24%

Finished training... Time:  66.27
Lenght of results collected
+-------------+-------------+-------------+------------+
|    Model    | Epoch Train | Epoch Valid | Iter Train |
+-------------+-------------+-------------+------------+
| Single Deep |     500     |     500     |   195500   |
+-------------+-------------+-------------+------------+
Current set up
[ALERT]: Path to results (this may overwrite /home/ec2-user/Single_vs_Ensemble_of_NNs/results
[ALERT]: Path to checkpoint (this may overwrite None
Do you want to continue? [Y/n]: 