

CONFIGURATION
-------------
+-----------------+------------------------+
| Python Version  |         3.6.5          |
+-----------------+------------------------+
| PyTorch Version |         1.0.0          |
+-----------------+------------------------+
|     Device      |  Tesla V100-SXM2-16GB  |
+-----------------+------------------------+
|      Cores      |           8            |
+-----------------+------------------------+
|      GPUs       |           1            |
+-----------------+------------------------+
|  CUDNN Enabled  |          True          |
+-----------------+------------------------+
|   Single Net    |  Single_Non_Recursive  |
+-----------------+------------------------+
|  Ensemble Nets  | Ensemble_Non_Recursive |
+-----------------+------------------------+
|     Dataset     |        CIFAR10         |
+-----------------+------------------------+
|     Epochs      |          500           |
+-----------------+------------------------+
|   Batch Size    |          128           |
+-----------------+------------------------+
|   Initial LR    |          0.01          |
+-----------------+------------------------+


DEFINITION OF PATHS
-------------------

[OK]: Paths Validated Successfully
Root path:  /home/ec2-user/Single_vs_Ensemble_of_NNs
Script path:  /home/ec2-user/Single_vs_Ensemble_of_NNs/scripts
Results path:  /home/ec2-user/Single_vs_Ensemble_of_NNs/results
DataFolder path:  /home/ec2-user/datasets
Models to save path:  /home/ec2-user/Single_vs_Ensemble_of_NNs/results/models/recursives/ensemble_recursives
Models to load path:  /home/ec2-user/Single_vs_Ensemble_of_NNs/results/models/recursives/ensemble_recursives/definitives


IMPORTING DATA
--------------
Files already downloaded and verified


LOADING MODELS
----------------
Regular net
Conv_Net(
  (act): ReLU()
  (d1): Dropout2d(p=0.1)
  (d2): Dropout2d(p=0.5)
  (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (V): Conv2d(3, 32, kernel_size=(8, 8), stride=(1, 1), padding=(3, 3))
  (P): MaxPool2d(kernel_size=4, stride=4, padding=2, dilation=1, ceil_mode=False)
  (W): ModuleList(
    (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (5): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (6): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (7): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (8): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (9): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (10): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (11): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (12): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (13): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (14): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (15): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  )
  (C): Linear(in_features=2048, out_features=10, bias=True)
)


		Parameters: 0.174762M
Non Recursive ConvNet
Conv_Net(
  (act): ReLU()
  (V): Conv2d(3, 32, kernel_size=(8, 8), stride=(1, 1), padding=(3, 3))
  (P): MaxPool2d(kernel_size=4, stride=4, padding=2, dilation=1, ceil_mode=False)
  (W): ModuleList(
    (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (5): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (6): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (7): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (8): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (9): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (10): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (11): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (12): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (13): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (14): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (15): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  )
  (C): Linear(in_features=2048, out_features=10, bias=True)
)


		Parameters: 0.174634M


TRAINING
--------
Current set up
[ALERT]: Path to results (this may overwrite /home/ec2-user/Single_vs_Ensemble_of_NNs/results
[ALERT]: Path to checkpoint (this may overwrite None
Do you want to continue? [Y/n]: [OK]: Starting Training of Recursive Ensemble Model

Starting Single Model Training...

 ** Time 13:11

 ** Train ** Epoch: [1/500] Iter: [391/195500] Loss: 2.138 Acc: 23.75%

 ** Valid ** Epoch: [1/500] Iter: [391/195500] Loss: 2.267 Acc: 10.73%

 ** Time 13:11

 ** Train ** Epoch: [2/500] Iter: [782/195500] Loss: 1.894 Acc: 32.5%

 ** Valid ** Epoch: [2/500] Iter: [782/195500] Loss: 2.273 Acc: 11.06%

 ** Time 13:11

 ** Train ** Epoch: [3/500] Iter: [1173/195500] Loss: 1.758 Acc: 35.0%

 ** Valid ** Epoch: [3/500] Iter: [1173/195500] Loss: 2.243 Acc: 11.79%

 ** Time 13:11

 ** Train ** Epoch: [4/500] Iter: [1564/195500] Loss: 1.58 Acc: 37.5%

 ** Valid ** Epoch: [4/500] Iter: [1564/195500] Loss: 2.185 Acc: 10.37%

 ** Time 13:11

 ** Train ** Epoch: [5/500] Iter: [1955/195500] Loss: 1.803 Acc: 33.75%

 ** Valid ** Epoch: [5/500] Iter: [1955/195500] Loss: 2.188 Acc: 13.81%

 ** Time 13:11

 ** Train ** Epoch: [6/500] Iter: [2346/195500] Loss: 1.542 Acc: 32.5%

 ** Valid ** Epoch: [6/500] Iter: [2346/195500] Loss: 2.179 Acc: 13.69%

 ** Time 13:11

 ** Train ** Epoch: [7/500] Iter: [2737/195500] Loss: 1.549 Acc: 48.75%

 ** Valid ** Epoch: [7/500] Iter: [2737/195500] Loss: 2.207 Acc: 13.22%

 ** Time 13:12

 ** Train ** Epoch: [8/500] Iter: [3128/195500] Loss: 1.385 Acc: 55.0%

 ** Valid ** Epoch: [8/500] Iter: [3128/195500] Loss: 2.167 Acc: 16.74%

 ** Time 13:12

 ** Train ** Epoch: [9/500] Iter: [3519/195500] Loss: 1.47 Acc: 45.0%

 ** Valid ** Epoch: [9/500] Iter: [3519/195500] Loss: 2.166 Acc: 15.66%

 ** Time 13:12

 ** Train ** Epoch: [10/500] Iter: [3910/195500] Loss: 1.452 Acc: 51.25%

 ** Valid ** Epoch: [10/500] Iter: [3910/195500] Loss: 2.133 Acc: 18.2%

 ** Time 13:12

 ** Train ** Epoch: [11/500] Iter: [4301/195500] Loss: 1.461 Acc: 47.5%

 ** Valid ** Epoch: [11/500] Iter: [4301/195500] Loss: 2.067 Acc: 16.88%

 ** Time 13:12

 ** Train ** Epoch: [12/500] Iter: [4692/195500] Loss: 1.663 Acc: 38.75%

 ** Valid ** Epoch: [12/500] Iter: [4692/195500] Loss: 2.111 Acc: 21.91%

 ** Time 13:12

 ** Train ** Epoch: [13/500] Iter: [5083/195500] Loss: 1.426 Acc: 47.5%

 ** Valid ** Epoch: [13/500] Iter: [5083/195500] Loss: 2.049 Acc: 25.84%

 ** Time 13:12

 ** Train ** Epoch: [14/500] Iter: [5474/195500] Loss: 1.464 Acc: 53.75%

 ** Valid ** Epoch: [14/500] Iter: [5474/195500] Loss: 1.985 Acc: 27.8%

 ** Time 13:13

 ** Train ** Epoch: [15/500] Iter: [5865/195500] Loss: 1.1 Acc: 58.75%

 ** Valid ** Epoch: [15/500] Iter: [5865/195500] Loss: 2.046 Acc: 23.44%

 ** Time 13:13

 ** Train ** Epoch: [16/500] Iter: [6256/195500] Loss: 1.392 Acc: 50.0%

 ** Valid ** Epoch: [16/500] Iter: [6256/195500] Loss: 2.022 Acc: 20.99%

 ** Time 13:13

 ** Train ** Epoch: [17/500] Iter: [6647/195500] Loss: 1.072 Acc: 57.5%

 ** Valid ** Epoch: [17/500] Iter: [6647/195500] Loss: 1.997 Acc: 19.96%

 ** Time 13:13

 ** Train ** Epoch: [18/500] Iter: [7038/195500] Loss: 1.408 Acc: 53.75%

 ** Valid ** Epoch: [18/500] Iter: [7038/195500] Loss: 2.04 Acc: 23.03%

 ** Time 13:13

 ** Train ** Epoch: [19/500] Iter: [7429/195500] Loss: 1.153 Acc: 52.5%

 ** Valid ** Epoch: [19/500] Iter: [7429/195500] Loss: 2.057 Acc: 26.56%

 ** Time 13:13

 ** Train ** Epoch: [20/500] Iter: [7820/195500] Loss: 1.284 Acc: 53.75%

 ** Valid ** Epoch: [20/500] Iter: [7820/195500] Loss: 1.99 Acc: 30.41%

 ** Time 13:13

 ** Train ** Epoch: [21/500] Iter: [8211/195500] Loss: 1.353 Acc: 47.5%

 ** Valid ** Epoch: [21/500] Iter: [8211/195500] Loss: 1.962 Acc: 26.32%

 ** Time 13:14

 ** Train ** Epoch: [22/500] Iter: [8602/195500] Loss: 1.125 Acc: 65.0%

 ** Valid ** Epoch: [22/500] Iter: [8602/195500] Loss: 1.97 Acc: 29.66%

 ** Time 13:14

 ** Train ** Epoch: [23/500] Iter: [8993/195500] Loss: 1.141 Acc: 52.5%

 ** Valid ** Epoch: [23/500] Iter: [8993/195500] Loss: 2.016 Acc: 26.97%

 ** Time 13:14

 ** Train ** Epoch: [24/500] Iter: [9384/195500] Loss: 1.235 Acc: 61.25%

 ** Valid ** Epoch: [24/500] Iter: [9384/195500] Loss: 2.118 Acc: 30.66%

 ** Time 13:14

 ** Train ** Epoch: [25/500] Iter: [9775/195500] Loss: 1.276 Acc: 57.5%

 ** Valid ** Epoch: [25/500] Iter: [9775/195500] Loss: 1.979 Acc: 28.93%

 ** Time 13:14

 ** Train ** Epoch: [26/500] Iter: [10166/195500] Loss: 1.542 Acc: 47.5%

 ** Valid ** Epoch: [26/500] Iter: [10166/195500] Loss: 1.991 Acc: 26.67%

 ** Time 13:14

 ** Train ** Epoch: [27/500] Iter: [10557/195500] Loss: 1.427 Acc: 50.0%

 ** Valid ** Epoch: [27/500] Iter: [10557/195500] Loss: 2.024 Acc: 28.97%

 ** Time 13:14

 ** Train ** Epoch: [28/500] Iter: [10948/195500] Loss: 1.071 Acc: 65.0%

 ** Valid ** Epoch: [28/500] Iter: [10948/195500] Loss: 2.091 Acc: 28.94%

 ** Time 13:15

 ** Train ** Epoch: [29/500] Iter: [11339/195500] Loss: 1.413 Acc: 53.75%

 ** Valid ** Epoch: [29/500] Iter: [11339/195500] Loss: 1.984 Acc: 30.08%

 ** Time 13:15

 ** Train ** Epoch: [30/500] Iter: [11730/195500] Loss: 1.039 Acc: 55.0%

 ** Valid ** Epoch: [30/500] Iter: [11730/195500] Loss: 1.925 Acc: 32.62%

 ** Time 13:15

 ** Train ** Epoch: [31/500] Iter: [12121/195500] Loss: 0.971 Acc: 65.0%

 ** Valid ** Epoch: [31/500] Iter: [12121/195500] Loss: 2.034 Acc: 26.94%

 ** Time 13:15

 ** Train ** Epoch: [32/500] Iter: [12512/195500] Loss: 1.178 Acc: 55.0%

 ** Valid ** Epoch: [32/500] Iter: [12512/195500] Loss: 2.053 Acc: 30.16%

 ** Time 13:15

 ** Train ** Epoch: [33/500] Iter: [12903/195500] Loss: 1.088 Acc: 61.25%

 ** Valid ** Epoch: [33/500] Iter: [12903/195500] Loss: 2.071 Acc: 28.39%

 ** Time 13:15

 ** Train ** Epoch: [34/500] Iter: [13294/195500] Loss: 0.938 Acc: 67.5%

 ** Valid ** Epoch: [34/500] Iter: [13294/195500] Loss: 2.007 Acc: 29.96%

 ** Time 13:15

 ** Train ** Epoch: [35/500] Iter: [13685/195500] Loss: 0.953 Acc: 65.0%

 ** Valid ** Epoch: [35/500] Iter: [13685/195500] Loss: 1.923 Acc: 30.22%

 ** Time 13:16

 ** Train ** Epoch: [36/500] Iter: [14076/195500] Loss: 1.141 Acc: 60.0%

 ** Valid ** Epoch: [36/500] Iter: [14076/195500] Loss: 2.004 Acc: 29.41%

 ** Time 13:16

 ** Train ** Epoch: [37/500] Iter: [14467/195500] Loss: 1.171 Acc: 63.75%

 ** Valid ** Epoch: [37/500] Iter: [14467/195500] Loss: 2.01 Acc: 27.37%

 ** Time 13:16

 ** Train ** Epoch: [38/500] Iter: [14858/195500] Loss: 1.075 Acc: 63.75%

 ** Valid ** Epoch: [38/500] Iter: [14858/195500] Loss: 2.056 Acc: 30.4%

 ** Time 13:16

 ** Train ** Epoch: [39/500] Iter: [15249/195500] Loss: 1.176 Acc: 65.0%

 ** Valid ** Epoch: [39/500] Iter: [15249/195500] Loss: 2.063 Acc: 31.06%

 ** Time 13:16

 ** Train ** Epoch: [40/500] Iter: [15640/195500] Loss: 1.342 Acc: 52.5%

 ** Valid ** Epoch: [40/500] Iter: [15640/195500] Loss: 2.048 Acc: 30.59%

 ** Time 13:16

 ** Train ** Epoch: [41/500] Iter: [16031/195500] Loss: 1.241 Acc: 56.25%

 ** Valid ** Epoch: [41/500] Iter: [16031/195500] Loss: 2.024 Acc: 30.66%

 ** Time 13:16

 ** Train ** Epoch: [42/500] Iter: [16422/195500] Loss: 1.014 Acc: 60.0%

 ** Valid ** Epoch: [42/500] Iter: [16422/195500] Loss: 2.02 Acc: 31.35%

 ** Time 13:17

 ** Train ** Epoch: [43/500] Iter: [16813/195500] Loss: 0.782 Acc: 72.5%

 ** Valid ** Epoch: [43/500] Iter: [16813/195500] Loss: 1.992 Acc: 33.74%

 ** Time 13:17

 ** Train ** Epoch: [44/500] Iter: [17204/195500] Loss: 1.233 Acc: 60.0%

 ** Valid ** Epoch: [44/500] Iter: [17204/195500] Loss: 1.986 Acc: 33.93%

 ** Time 13:17

 ** Train ** Epoch: [45/500] Iter: [17595/195500] Loss: 1.071 Acc: 65.0%

 ** Valid ** Epoch: [45/500] Iter: [17595/195500] Loss: 2.023 Acc: 31.13%

 ** Time 13:17

 ** Train ** Epoch: [46/500] Iter: [17986/195500] Loss: 1.087 Acc: 58.75%

 ** Valid ** Epoch: [46/500] Iter: [17986/195500] Loss: 1.97 Acc: 33.32%

 ** Time 13:17

 ** Train ** Epoch: [47/500] Iter: [18377/195500] Loss: 0.973 Acc: 70.0%

 ** Valid ** Epoch: [47/500] Iter: [18377/195500] Loss: 2.017 Acc: 30.84%

 ** Time 13:17

 ** Train ** Epoch: [48/500] Iter: [18768/195500] Loss: 1.139 Acc: 62.5%

 ** Valid ** Epoch: [48/500] Iter: [18768/195500] Loss: 1.933 Acc: 34.77%

 ** Time 13:17

 ** Train ** Epoch: [49/500] Iter: [19159/195500] Loss: 0.947 Acc: 65.0%

 ** Valid ** Epoch: [49/500] Iter: [19159/195500] Loss: 2.056 Acc: 29.29%

 ** Time 13:18

 ** Train ** Epoch: [50/500] Iter: [19550/195500] Loss: 1.047 Acc: 68.75%

 ** Valid ** Epoch: [50/500] Iter: [19550/195500] Loss: 1.968 Acc: 34.05%

 ** Time 13:18

 ** Train ** Epoch: [51/500] Iter: [19941/195500] Loss: 1.058 Acc: 62.5%

 ** Valid ** Epoch: [51/500] Iter: [19941/195500] Loss: 2.0 Acc: 32.28%

 ** Time 13:18

 ** Train ** Epoch: [52/500] Iter: [20332/195500] Loss: 0.903 Acc: 68.75%

 ** Valid ** Epoch: [52/500] Iter: [20332/195500] Loss: 1.97 Acc: 29.52%

 ** Time 13:18

 ** Train ** Epoch: [53/500] Iter: [20723/195500] Loss: 1.056 Acc: 61.25%

 ** Valid ** Epoch: [53/500] Iter: [20723/195500] Loss: 2.007 Acc: 30.73%

 ** Time 13:18

 ** Train ** Epoch: [54/500] Iter: [21114/195500] Loss: 1.13 Acc: 66.25%

 ** Valid ** Epoch: [54/500] Iter: [21114/195500] Loss: 2.077 Acc: 29.47%

 ** Time 13:18

 ** Train ** Epoch: [55/500] Iter: [21505/195500] Loss: 0.901 Acc: 67.5%

 ** Valid ** Epoch: [55/500] Iter: [21505/195500] Loss: 1.933 Acc: 32.41%

 ** Time 13:18

 ** Train ** Epoch: [56/500] Iter: [21896/195500] Loss: 0.807 Acc: 76.25%

 ** Valid ** Epoch: [56/500] Iter: [21896/195500] Loss: 1.934 Acc: 34.49%

 ** Time 13:19

 ** Train ** Epoch: [57/500] Iter: [22287/195500] Loss: 0.983 Acc: 66.25%

 ** Valid ** Epoch: [57/500] Iter: [22287/195500] Loss: 1.866 Acc: 30.81%

 ** Time 13:19

 ** Train ** Epoch: [58/500] Iter: [22678/195500] Loss: 0.921 Acc: 68.75%

 ** Valid ** Epoch: [58/500] Iter: [22678/195500] Loss: 1.913 Acc: 31.73%

 ** Time 13:19

 ** Train ** Epoch: [59/500] Iter: [23069/195500] Loss: 0.86 Acc: 68.75%

 ** Valid ** Epoch: [59/500] Iter: [23069/195500] Loss: 2.019 Acc: 30.11%

 ** Time 13:19

 ** Train ** Epoch: [60/500] Iter: [23460/195500] Loss: 1.036 Acc: 63.75%

 ** Valid ** Epoch: [60/500] Iter: [23460/195500] Loss: 2.013 Acc: 30.71%

 ** Time 13:19

 ** Train ** Epoch: [61/500] Iter: [23851/195500] Loss: 0.821 Acc: 68.75%

 ** Valid ** Epoch: [61/500] Iter: [23851/195500] Loss: 1.915 Acc: 30.91%

 ** Time 13:19

 ** Train ** Epoch: [62/500] Iter: [24242/195500] Loss: 1.041 Acc: 61.25%

 ** Valid ** Epoch: [62/500] Iter: [24242/195500] Loss: 1.941 Acc: 28.93%

 ** Time 13:19

 ** Train ** Epoch: [63/500] Iter: [24633/195500] Loss: 0.996 Acc: 63.75%

 ** Valid ** Epoch: [63/500] Iter: [24633/195500] Loss: 1.902 Acc: 32.43%

 ** Time 13:20

 ** Train ** Epoch: [64/500] Iter: [25024/195500] Loss: 0.999 Acc: 65.0%

 ** Valid ** Epoch: [64/500] Iter: [25024/195500] Loss: 1.997 Acc: 27.98%

 ** Time 13:20

 ** Train ** Epoch: [65/500] Iter: [25415/195500] Loss: 0.943 Acc: 66.25%

 ** Valid ** Epoch: [65/500] Iter: [25415/195500] Loss: 1.998 Acc: 27.92%

 ** Time 13:20

 ** Train ** Epoch: [66/500] Iter: [25806/195500] Loss: 1.167 Acc: 58.75%

 ** Valid ** Epoch: [66/500] Iter: [25806/195500] Loss: 2.015 Acc: 28.55%

 ** Time 13:20

 ** Train ** Epoch: [67/500] Iter: [26197/195500] Loss: 0.716 Acc: 73.75%

 ** Valid ** Epoch: [67/500] Iter: [26197/195500] Loss: 1.96 Acc: 31.92%

 ** Time 13:20

 ** Train ** Epoch: [68/500] Iter: [26588/195500] Loss: 0.788 Acc: 72.5%

 ** Valid ** Epoch: [68/500] Iter: [26588/195500] Loss: 1.988 Acc: 29.41%

 ** Time 13:20

 ** Train ** Epoch: [69/500] Iter: [26979/195500] Loss: 0.988 Acc: 66.25%

 ** Valid ** Epoch: [69/500] Iter: [26979/195500] Loss: 1.941 Acc: 28.24%

 ** Time 13:20

 ** Train ** Epoch: [70/500] Iter: [27370/195500] Loss: 0.793 Acc: 68.75%

 ** Valid ** Epoch: [70/500] Iter: [27370/195500] Loss: 1.985 Acc: 32.27%

 ** Time 13:20

 ** Train ** Epoch: [71/500] Iter: [27761/195500] Loss: 1.019 Acc: 66.25%

 ** Valid ** Epoch: [71/500] Iter: [27761/195500] Loss: 2.046 Acc: 33.62%

 ** Time 13:21

 ** Train ** Epoch: [72/500] Iter: [28152/195500] Loss: 1.108 Acc: 57.5%

 ** Valid ** Epoch: [72/500] Iter: [28152/195500] Loss: 1.962 Acc: 33.25%

 ** Time 13:21

 ** Train ** Epoch: [73/500] Iter: [28543/195500] Loss: 0.946 Acc: 66.25%

 ** Valid ** Epoch: [73/500] Iter: [28543/195500] Loss: 1.948 Acc: 32.32%

 ** Time 13:21

 ** Train ** Epoch: [74/500] Iter: [28934/195500] Loss: 1.032 Acc: 62.5%

 ** Valid ** Epoch: [74/500] Iter: [28934/195500] Loss: 1.954 Acc: 34.42%

 ** Time 13:21

 ** Train ** Epoch: [75/500] Iter: [29325/195500] Loss: 1.012 Acc: 65.0%

 ** Valid ** Epoch: [75/500] Iter: [29325/195500] Loss: 2.037 Acc: 31.94%

 ** Time 13:21

 ** Train ** Epoch: [76/500] Iter: [29716/195500] Loss: 0.841 Acc: 75.0%

 ** Valid ** Epoch: [76/500] Iter: [29716/195500] Loss: 1.896 Acc: 32.36%

 ** Time 13:21

 ** Train ** Epoch: [77/500] Iter: [30107/195500] Loss: 0.882 Acc: 68.75%

 ** Valid ** Epoch: [77/500] Iter: [30107/195500] Loss: 1.984 Acc: 31.39%

 ** Time 13:21

 ** Train ** Epoch: [78/500] Iter: [30498/195500] Loss: 0.783 Acc: 71.25%

 ** Valid ** Epoch: [78/500] Iter: [30498/195500] Loss: 2.015 Acc: 31.29%

 ** Time 13:22

 ** Train ** Epoch: [79/500] Iter: [30889/195500] Loss: 0.858 Acc: 71.25%

 ** Valid ** Epoch: [79/500] Iter: [30889/195500] Loss: 1.989 Acc: 29.56%

 ** Time 13:22

 ** Train ** Epoch: [80/500] Iter: [31280/195500] Loss: 1.246 Acc: 61.25%

 ** Valid ** Epoch: [80/500] Iter: [31280/195500] Loss: 1.94 Acc: 33.41%

 ** Time 13:22

 ** Train ** Epoch: [81/500] Iter: [31671/195500] Loss: 0.772 Acc: 72.5%

 ** Valid ** Epoch: [81/500] Iter: [31671/195500] Loss: 1.875 Acc: 35.88%

 ** Time 13:22

 ** Train ** Epoch: [82/500] Iter: [32062/195500] Loss: 0.888 Acc: 67.5%

 ** Valid ** Epoch: [82/500] Iter: [32062/195500] Loss: 1.888 Acc: 35.12%

 ** Time 13:22

 ** Train ** Epoch: [83/500] Iter: [32453/195500] Loss: 1.08 Acc: 63.75%

 ** Valid ** Epoch: [83/500] Iter: [32453/195500] Loss: 2.001 Acc: 30.46%

 ** Time 13:22

 ** Train ** Epoch: [84/500] Iter: [32844/195500] Loss: 0.948 Acc: 71.25%

 ** Valid ** Epoch: [84/500] Iter: [32844/195500] Loss: 1.893 Acc: 33.57%

 ** Time 13:22

 ** Train ** Epoch: [85/500] Iter: [33235/195500] Loss: 0.835 Acc: 70.0%

 ** Valid ** Epoch: [85/500] Iter: [33235/195500] Loss: 1.979 Acc: 34.59%

 ** Time 13:23

 ** Train ** Epoch: [86/500] Iter: [33626/195500] Loss: 0.833 Acc: 66.25%

 ** Valid ** Epoch: [86/500] Iter: [33626/195500] Loss: 1.938 Acc: 31.54%

 ** Time 13:23

 ** Train ** Epoch: [87/500] Iter: [34017/195500] Loss: 0.775 Acc: 73.75%

 ** Valid ** Epoch: [87/500] Iter: [34017/195500] Loss: 1.906 Acc: 33.59%

 ** Time 13:23

 ** Train ** Epoch: [88/500] Iter: [34408/195500] Loss: 1.018 Acc: 65.0%

 ** Valid ** Epoch: [88/500] Iter: [34408/195500] Loss: 1.967 Acc: 34.88%

 ** Time 13:23

 ** Train ** Epoch: [89/500] Iter: [34799/195500] Loss: 1.042 Acc: 66.25%

 ** Valid ** Epoch: [89/500] Iter: [34799/195500] Loss: 1.938 Acc: 32.32%

 ** Time 13:23

 ** Train ** Epoch: [90/500] Iter: [35190/195500] Loss: 0.838 Acc: 70.0%

 ** Valid ** Epoch: [90/500] Iter: [35190/195500] Loss: 2.023 Acc: 30.83%

 ** Time 13:23

 ** Train ** Epoch: [91/500] Iter: [35581/195500] Loss: 1.08 Acc: 66.25%

 ** Valid ** Epoch: [91/500] Iter: [35581/195500] Loss: 1.979 Acc: 28.52%

 ** Time 13:23

 ** Train ** Epoch: [92/500] Iter: [35972/195500] Loss: 1.041 Acc: 66.25%

 ** Valid ** Epoch: [92/500] Iter: [35972/195500] Loss: 1.911 Acc: 36.01%

 ** Time 13:24

 ** Train ** Epoch: [93/500] Iter: [36363/195500] Loss: 0.774 Acc: 71.25%

 ** Valid ** Epoch: [93/500] Iter: [36363/195500] Loss: 1.965 Acc: 33.05%

 ** Time 13:24

 ** Train ** Epoch: [94/500] Iter: [36754/195500] Loss: 0.876 Acc: 66.25%

 ** Valid ** Epoch: [94/500] Iter: [36754/195500] Loss: 1.866 Acc: 33.96%

 ** Time 13:24

 ** Train ** Epoch: [95/500] Iter: [37145/195500] Loss: 0.685 Acc: 76.25%

 ** Valid ** Epoch: [95/500] Iter: [37145/195500] Loss: 1.916 Acc: 37.04%

 ** Time 13:24

 ** Train ** Epoch: [96/500] Iter: [37536/195500] Loss: 0.873 Acc: 66.25%

 ** Valid ** Epoch: [96/500] Iter: [37536/195500] Loss: 1.914 Acc: 31.11%

 ** Time 13:24

 ** Train ** Epoch: [97/500] Iter: [37927/195500] Loss: 0.781 Acc: 73.75%

 ** Valid ** Epoch: [97/500] Iter: [37927/195500] Loss: 1.899 Acc: 35.03%

 ** Time 13:24

 ** Train ** Epoch: [98/500] Iter: [38318/195500] Loss: 1.073 Acc: 56.25%

 ** Valid ** Epoch: [98/500] Iter: [38318/195500] Loss: 1.885 Acc: 31.64%

 ** Time 13:24

 ** Train ** Epoch: [99/500] Iter: [38709/195500] Loss: 0.911 Acc: 71.25%

 ** Valid ** Epoch: [99/500] Iter: [38709/195500] Loss: 1.891 Acc: 32.02%

 ** Time 13:25

 ** Train ** Epoch: [100/500] Iter: [39100/195500] Loss: 0.951 Acc: 67.5%

 ** Valid ** Epoch: [100/500] Iter: [39100/195500] Loss: 1.882 Acc: 33.87%

 ** Time 13:25

 ** Train ** Epoch: [101/500] Iter: [39491/195500] Loss: 0.878 Acc: 71.25%

 ** Valid ** Epoch: [101/500] Iter: [39491/195500] Loss: 1.971 Acc: 31.35%

 ** Time 13:25

 ** Train ** Epoch: [102/500] Iter: [39882/195500] Loss: 0.963 Acc: 61.25%

 ** Valid ** Epoch: [102/500] Iter: [39882/195500] Loss: 1.891 Acc: 31.95%

 ** Time 13:25

 ** Train ** Epoch: [103/500] Iter: [40273/195500] Loss: 0.956 Acc: 68.75%

 ** Valid ** Epoch: [103/500] Iter: [40273/195500] Loss: 1.885 Acc: 31.84%

 ** Time 13:25

 ** Train ** Epoch: [104/500] Iter: [40664/195500] Loss: 0.847 Acc: 72.5%

 ** Valid ** Epoch: [104/500] Iter: [40664/195500] Loss: 1.957 Acc: 34.62%

 ** Time 13:25

 ** Train ** Epoch: [105/500] Iter: [41055/195500] Loss: 0.792 Acc: 73.75%

 ** Valid ** Epoch: [105/500] Iter: [41055/195500] Loss: 1.911 Acc: 33.64%

 ** Time 13:25

 ** Train ** Epoch: [106/500] Iter: [41446/195500] Loss: 1.003 Acc: 63.75%

 ** Valid ** Epoch: [106/500] Iter: [41446/195500] Loss: 1.969 Acc: 29.86%

 ** Time 13:26

 ** Train ** Epoch: [107/500] Iter: [41837/195500] Loss: 0.869 Acc: 66.25%

 ** Valid ** Epoch: [107/500] Iter: [41837/195500] Loss: 1.943 Acc: 32.78%

 ** Time 13:26

 ** Train ** Epoch: [108/500] Iter: [42228/195500] Loss: 0.779 Acc: 73.75%

 ** Valid ** Epoch: [108/500] Iter: [42228/195500] Loss: 1.9 Acc: 34.31%

 ** Time 13:26

 ** Train ** Epoch: [109/500] Iter: [42619/195500] Loss: 0.889 Acc: 68.75%

 ** Valid ** Epoch: [109/500] Iter: [42619/195500] Loss: 1.88 Acc: 34.75%

 ** Time 13:26

 ** Train ** Epoch: [110/500] Iter: [43010/195500] Loss: 0.865 Acc: 71.25%

 ** Valid ** Epoch: [110/500] Iter: [43010/195500] Loss: 1.803 Acc: 34.36%

 ** Time 13:26

 ** Train ** Epoch: [111/500] Iter: [43401/195500] Loss: 0.935 Acc: 60.0%

 ** Valid ** Epoch: [111/500] Iter: [43401/195500] Loss: 1.855 Acc: 34.79%

 ** Time 13:26

 ** Train ** Epoch: [112/500] Iter: [43792/195500] Loss: 0.952 Acc: 62.5%

 ** Valid ** Epoch: [112/500] Iter: [43792/195500] Loss: 1.822 Acc: 34.07%

 ** Time 13:26

 ** Train ** Epoch: [113/500] Iter: [44183/195500] Loss: 0.841 Acc: 68.75%

 ** Valid ** Epoch: [113/500] Iter: [44183/195500] Loss: 1.898 Acc: 32.9%

 ** Time 13:27

 ** Train ** Epoch: [114/500] Iter: [44574/195500] Loss: 0.886 Acc: 66.25%

 ** Valid ** Epoch: [114/500] Iter: [44574/195500] Loss: 1.851 Acc: 34.6%

 ** Time 13:27

 ** Train ** Epoch: [115/500] Iter: [44965/195500] Loss: 0.67 Acc: 77.5%

 ** Valid ** Epoch: [115/500] Iter: [44965/195500] Loss: 1.861 Acc: 33.16%

 ** Time 13:27

 ** Train ** Epoch: [116/500] Iter: [45356/195500] Loss: 0.976 Acc: 61.25%

 ** Valid ** Epoch: [116/500] Iter: [45356/195500] Loss: 1.909 Acc: 32.14%

 ** Time 13:27

 ** Train ** Epoch: [117/500] Iter: [45747/195500] Loss: 0.93 Acc: 68.75%

 ** Valid ** Epoch: [117/500] Iter: [45747/195500] Loss: 1.887 Acc: 34.24%

 ** Time 13:27

 ** Train ** Epoch: [118/500] Iter: [46138/195500] Loss: 1.139 Acc: 61.25%

 ** Valid ** Epoch: [118/500] Iter: [46138/195500] Loss: 1.934 Acc: 31.36%

 ** Time 13:27

 ** Train ** Epoch: [119/500] Iter: [46529/195500] Loss: 0.898 Acc: 70.0%

 ** Valid ** Epoch: [119/500] Iter: [46529/195500] Loss: 1.851 Acc: 36.3%

 ** Time 13:27

 ** Train ** Epoch: [120/500] Iter: [46920/195500] Loss: 0.744 Acc: 70.0%

 ** Valid ** Epoch: [120/500] Iter: [46920/195500] Loss: 1.919 Acc: 33.59%

 ** Time 13:28

 ** Train ** Epoch: [121/500] Iter: [47311/195500] Loss: 0.867 Acc: 67.5%

 ** Valid ** Epoch: [121/500] Iter: [47311/195500] Loss: 1.813 Acc: 36.93%

 ** Time 13:28

 ** Train ** Epoch: [122/500] Iter: [47702/195500] Loss: 0.881 Acc: 70.0%

 ** Valid ** Epoch: [122/500] Iter: [47702/195500] Loss: 1.882 Acc: 34.88%

 ** Time 13:28

 ** Train ** Epoch: [123/500] Iter: [48093/195500] Loss: 0.937 Acc: 67.5%

 ** Valid ** Epoch: [123/500] Iter: [48093/195500] Loss: 1.915 Acc: 32.38%

 ** Time 13:28

 ** Train ** Epoch: [124/500] Iter: [48484/195500] Loss: 0.756 Acc: 73.75%

 ** Valid ** Epoch: [124/500] Iter: [48484/195500] Loss: 1.911 Acc: 33.53%

 ** Time 13:28

 ** Train ** Epoch: [125/500] Iter: [48875/195500] Loss: 0.851 Acc: 68.75%

 ** Valid ** Epoch: [125/500] Iter: [48875/195500] Loss: 1.906 Acc: 36.74%

 ** Time 13:28

 ** Train ** Epoch: [126/500] Iter: [49266/195500] Loss: 0.982 Acc: 68.75%

 ** Valid ** Epoch: [126/500] Iter: [49266/195500] Loss: 1.875 Acc: 39.22%

 ** Time 13:28

 ** Train ** Epoch: [127/500] Iter: [49657/195500] Loss: 0.776 Acc: 70.0%

 ** Valid ** Epoch: [127/500] Iter: [49657/195500] Loss: 1.877 Acc: 34.33%

 ** Time 13:29

 ** Train ** Epoch: [128/500] Iter: [50048/195500] Loss: 0.978 Acc: 63.75%

 ** Valid ** Epoch: [128/500] Iter: [50048/195500] Loss: 1.972 Acc: 31.38%

 ** Time 13:29

 ** Train ** Epoch: [129/500] Iter: [50439/195500] Loss: 0.897 Acc: 68.75%

 ** Valid ** Epoch: [129/500] Iter: [50439/195500] Loss: 1.909 Acc: 31.37%

 ** Time 13:29

 ** Train ** Epoch: [130/500] Iter: [50830/195500] Loss: 0.776 Acc: 73.75%

 ** Valid ** Epoch: [130/500] Iter: [50830/195500] Loss: 1.881 Acc: 35.78%

 ** Time 13:29

 ** Train ** Epoch: [131/500] Iter: [51221/195500] Loss: 0.803 Acc: 73.75%

 ** Valid ** Epoch: [131/500] Iter: [51221/195500] Loss: 1.905 Acc: 34.31%

 ** Time 13:29

 ** Train ** Epoch: [132/500] Iter: [51612/195500] Loss: 0.919 Acc: 61.25%

 ** Valid ** Epoch: [132/500] Iter: [51612/195500] Loss: 1.937 Acc: 34.06%

 ** Time 13:29

 ** Train ** Epoch: [133/500] Iter: [52003/195500] Loss: 0.903 Acc: 68.75%

 ** Valid ** Epoch: [133/500] Iter: [52003/195500] Loss: 1.918 Acc: 29.87%

 ** Time 13:29

 ** Train ** Epoch: [134/500] Iter: [52394/195500] Loss: 0.637 Acc: 75.0%

 ** Valid ** Epoch: [134/500] Iter: [52394/195500] Loss: 1.987 Acc: 30.44%

 ** Time 13:30

 ** Train ** Epoch: [135/500] Iter: [52785/195500] Loss: 0.791 Acc: 72.5%

 ** Valid ** Epoch: [135/500] Iter: [52785/195500] Loss: 1.954 Acc: 27.05%

 ** Time 13:30

 ** Train ** Epoch: [136/500] Iter: [53176/195500] Loss: 0.792 Acc: 73.75%

 ** Valid ** Epoch: [136/500] Iter: [53176/195500] Loss: 1.883 Acc: 34.72%

 ** Time 13:30

 ** Train ** Epoch: [137/500] Iter: [53567/195500] Loss: 0.911 Acc: 68.75%

 ** Valid ** Epoch: [137/500] Iter: [53567/195500] Loss: 1.855 Acc: 31.08%

 ** Time 13:30

 ** Train ** Epoch: [138/500] Iter: [53958/195500] Loss: 0.765 Acc: 72.5%

 ** Valid ** Epoch: [138/500] Iter: [53958/195500] Loss: 1.998 Acc: 32.52%

 ** Time 13:30

 ** Train ** Epoch: [139/500] Iter: [54349/195500] Loss: 0.758 Acc: 76.25%

 ** Valid ** Epoch: [139/500] Iter: [54349/195500] Loss: 1.899 Acc: 33.32%

 ** Time 13:30

 ** Train ** Epoch: [140/500] Iter: [54740/195500] Loss: 0.867 Acc: 70.0%

 ** Valid ** Epoch: [140/500] Iter: [54740/195500] Loss: 2.003 Acc: 31.91%

 ** Time 13:30

 ** Train ** Epoch: [141/500] Iter: [55131/195500] Loss: 0.962 Acc: 67.5%

 ** Valid ** Epoch: [141/500] Iter: [55131/195500] Loss: 1.908 Acc: 33.24%

 ** Time 13:31

 ** Train ** Epoch: [142/500] Iter: [55522/195500] Loss: 0.91 Acc: 65.0%

 ** Valid ** Epoch: [142/500] Iter: [55522/195500] Loss: 1.879 Acc: 34.23%

 ** Time 13:31

 ** Train ** Epoch: [143/500] Iter: [55913/195500] Loss: 0.806 Acc: 78.75%

 ** Valid ** Epoch: [143/500] Iter: [55913/195500] Loss: 1.958 Acc: 30.78%

 ** Time 13:31

 ** Train ** Epoch: [144/500] Iter: [56304/195500] Loss: 0.9 Acc: 70.0%

 ** Valid ** Epoch: [144/500] Iter: [56304/195500] Loss: 1.857 Acc: 34.13%

 ** Time 13:31

 ** Train ** Epoch: [145/500] Iter: [56695/195500] Loss: 0.833 Acc: 65.0%

 ** Valid ** Epoch: [145/500] Iter: [56695/195500] Loss: 1.936 Acc: 28.97%

 ** Time 13:31

 ** Train ** Epoch: [146/500] Iter: [57086/195500] Loss: 0.792 Acc: 76.25%

 ** Valid ** Epoch: [146/500] Iter: [57086/195500] Loss: 1.91 Acc: 30.75%

 ** Time 13:31

 ** Train ** Epoch: [147/500] Iter: [57477/195500] Loss: 0.801 Acc: 68.75%

 ** Valid ** Epoch: [147/500] Iter: [57477/195500] Loss: 1.856 Acc: 31.56%

 ** Time 13:31

 ** Train ** Epoch: [148/500] Iter: [57868/195500] Loss: 1.082 Acc: 67.5%

 ** Valid ** Epoch: [148/500] Iter: [57868/195500] Loss: 1.917 Acc: 31.87%

 ** Time 13:31

 ** Train ** Epoch: [149/500] Iter: [58259/195500] Loss: 0.841 Acc: 72.5%

 ** Valid ** Epoch: [149/500] Iter: [58259/195500] Loss: 1.927 Acc: 29.1%

 ** Time 13:32

 ** Train ** Epoch: [150/500] Iter: [58650/195500] Loss: 0.802 Acc: 71.25%

 ** Valid ** Epoch: [150/500] Iter: [58650/195500] Loss: 1.898 Acc: 28.38%

 ** Time 13:32

 ** Train ** Epoch: [151/500] Iter: [59041/195500] Loss: 0.94 Acc: 68.75%

 ** Valid ** Epoch: [151/500] Iter: [59041/195500] Loss: 2.022 Acc: 30.2%

 ** Time 13:32

 ** Train ** Epoch: [152/500] Iter: [59432/195500] Loss: 0.931 Acc: 72.5%

 ** Valid ** Epoch: [152/500] Iter: [59432/195500] Loss: 1.928 Acc: 30.31%

 ** Time 13:32

 ** Train ** Epoch: [153/500] Iter: [59823/195500] Loss: 0.846 Acc: 67.5%

 ** Valid ** Epoch: [153/500] Iter: [59823/195500] Loss: 2.041 Acc: 30.41%

 ** Time 13:32

 ** Train ** Epoch: [154/500] Iter: [60214/195500] Loss: 0.789 Acc: 70.0%

 ** Valid ** Epoch: [154/500] Iter: [60214/195500] Loss: 1.933 Acc: 28.52%

 ** Time 13:32

 ** Train ** Epoch: [155/500] Iter: [60605/195500] Loss: 0.831 Acc: 75.0%

 ** Valid ** Epoch: [155/500] Iter: [60605/195500] Loss: 1.953 Acc: 29.63%

 ** Time 13:32

 ** Train ** Epoch: [156/500] Iter: [60996/195500] Loss: 0.762 Acc: 67.5%

 ** Valid ** Epoch: [156/500] Iter: [60996/195500] Loss: 1.934 Acc: 30.29%

 ** Time 13:33

 ** Train ** Epoch: [157/500] Iter: [61387/195500] Loss: 0.85 Acc: 71.25%

 ** Valid ** Epoch: [157/500] Iter: [61387/195500] Loss: 1.939 Acc: 29.26%

 ** Time 13:33

 ** Train ** Epoch: [158/500] Iter: [61778/195500] Loss: 0.927 Acc: 72.5%

 ** Valid ** Epoch: [158/500] Iter: [61778/195500] Loss: 1.941 Acc: 32.37%

 ** Time 13:33

 ** Train ** Epoch: [159/500] Iter: [62169/195500] Loss: 0.72 Acc: 73.75%

 ** Valid ** Epoch: [159/500] Iter: [62169/195500] Loss: 1.879 Acc: 34.59%

 ** Time 13:33

 ** Train ** Epoch: [160/500] Iter: [62560/195500] Loss: 0.826 Acc: 70.0%

 ** Valid ** Epoch: [160/500] Iter: [62560/195500] Loss: 1.871 Acc: 33.58%

 ** Time 13:33

 ** Train ** Epoch: [161/500] Iter: [62951/195500] Loss: 0.706 Acc: 75.0%

 ** Valid ** Epoch: [161/500] Iter: [62951/195500] Loss: 1.919 Acc: 28.39%

 ** Time 13:33

 ** Train ** Epoch: [162/500] Iter: [63342/195500] Loss: 0.833 Acc: 72.5%

 ** Valid ** Epoch: [162/500] Iter: [63342/195500] Loss: 1.888 Acc: 30.77%

 ** Time 13:33

 ** Train ** Epoch: [163/500] Iter: [63733/195500] Loss: 0.838 Acc: 75.0%

 ** Valid ** Epoch: [163/500] Iter: [63733/195500] Loss: 1.878 Acc: 30.39%

 ** Time 13:34

 ** Train ** Epoch: [164/500] Iter: [64124/195500] Loss: 0.96 Acc: 67.5%

 ** Valid ** Epoch: [164/500] Iter: [64124/195500] Loss: 1.891 Acc: 32.33%

 ** Time 13:34

 ** Train ** Epoch: [165/500] Iter: [64515/195500] Loss: 0.964 Acc: 68.75%

 ** Valid ** Epoch: [165/500] Iter: [64515/195500] Loss: 1.969 Acc: 30.57%

 ** Time 13:34

 ** Train ** Epoch: [166/500] Iter: [64906/195500] Loss: 1.218 Acc: 63.75%

 ** Valid ** Epoch: [166/500] Iter: [64906/195500] Loss: 1.922 Acc: 30.03%

 ** Time 13:34

 ** Train ** Epoch: [167/500] Iter: [65297/195500] Loss: 0.687 Acc: 78.75%

 ** Valid ** Epoch: [167/500] Iter: [65297/195500] Loss: 1.938 Acc: 34.53%

 ** Time 13:34

 ** Train ** Epoch: [168/500] Iter: [65688/195500] Loss: 0.915 Acc: 76.25%

 ** Valid ** Epoch: [168/500] Iter: [65688/195500] Loss: 1.909 Acc: 34.65%

 ** Time 13:34

 ** Train ** Epoch: [169/500] Iter: [66079/195500] Loss: 0.807 Acc: 78.75%

 ** Valid ** Epoch: [169/500] Iter: [66079/195500] Loss: 1.975 Acc: 32.06%

 ** Time 13:34

 ** Train ** Epoch: [170/500] Iter: [66470/195500] Loss: 0.795 Acc: 65.0%

 ** Valid ** Epoch: [170/500] Iter: [66470/195500] Loss: 1.856 Acc: 34.46%

 ** Time 13:35

 ** Train ** Epoch: [171/500] Iter: [66861/195500] Loss: 1.044 Acc: 63.75%

 ** Valid ** Epoch: [171/500] Iter: [66861/195500] Loss: 1.925 Acc: 33.47%

 ** Time 13:35

 ** Train ** Epoch: [172/500] Iter: [67252/195500] Loss: 0.671 Acc: 76.25%

 ** Valid ** Epoch: [172/500] Iter: [67252/195500] Loss: 1.885 Acc: 36.23%

 ** Time 13:35

 ** Train ** Epoch: [173/500] Iter: [67643/195500] Loss: 0.695 Acc: 73.75%

 ** Valid ** Epoch: [173/500] Iter: [67643/195500] Loss: 1.926 Acc: 29.68%

 ** Time 13:35

 ** Train ** Epoch: [174/500] Iter: [68034/195500] Loss: 0.676 Acc: 77.5%

 ** Valid ** Epoch: [174/500] Iter: [68034/195500] Loss: 1.886 Acc: 35.97%

 ** Time 13:35

 ** Train ** Epoch: [175/500] Iter: [68425/195500] Loss: 0.88 Acc: 72.5%

 ** Valid ** Epoch: [175/500] Iter: [68425/195500] Loss: 1.891 Acc: 36.91%

 ** Time 13:35

 ** Train ** Epoch: [176/500] Iter: [68816/195500] Loss: 0.926 Acc: 67.5%

 ** Valid ** Epoch: [176/500] Iter: [68816/195500] Loss: 1.952 Acc: 35.8%

 ** Time 13:35

 ** Train ** Epoch: [177/500] Iter: [69207/195500] Loss: 0.825 Acc: 66.25%

 ** Valid ** Epoch: [177/500] Iter: [69207/195500] Loss: 1.868 Acc: 32.28%

 ** Time 13:36

 ** Train ** Epoch: [178/500] Iter: [69598/195500] Loss: 0.889 Acc: 71.25%

 ** Valid ** Epoch: [178/500] Iter: [69598/195500] Loss: 1.903 Acc: 35.16%

 ** Time 13:36

 ** Train ** Epoch: [179/500] Iter: [69989/195500] Loss: 0.893 Acc: 72.5%

 ** Valid ** Epoch: [179/500] Iter: [69989/195500] Loss: 1.894 Acc: 31.77%

 ** Time 13:36

 ** Train ** Epoch: [180/500] Iter: [70380/195500] Loss: 1.021 Acc: 67.5%

 ** Valid ** Epoch: [180/500] Iter: [70380/195500] Loss: 1.799 Acc: 34.51%

 ** Time 13:36

 ** Train ** Epoch: [181/500] Iter: [70771/195500] Loss: 0.82 Acc: 66.25%

 ** Valid ** Epoch: [181/500] Iter: [70771/195500] Loss: 1.882 Acc: 33.1%

 ** Time 13:36

 ** Train ** Epoch: [182/500] Iter: [71162/195500] Loss: 0.852 Acc: 71.25%

 ** Valid ** Epoch: [182/500] Iter: [71162/195500] Loss: 1.83 Acc: 34.61%

 ** Time 13:36

 ** Train ** Epoch: [183/500] Iter: [71553/195500] Loss: 1.068 Acc: 66.25%

 ** Valid ** Epoch: [183/500] Iter: [71553/195500] Loss: 1.885 Acc: 34.32%

 ** Time 13:36

 ** Train ** Epoch: [184/500] Iter: [71944/195500] Loss: 0.982 Acc: 71.25%

 ** Valid ** Epoch: [184/500] Iter: [71944/195500] Loss: 1.964 Acc: 31.13%

 ** Time 13:37

 ** Train ** Epoch: [185/500] Iter: [72335/195500] Loss: 0.822 Acc: 66.25%

 ** Valid ** Epoch: [185/500] Iter: [72335/195500] Loss: 1.907 Acc: 35.86%

 ** Time 13:37

 ** Train ** Epoch: [186/500] Iter: [72726/195500] Loss: 0.842 Acc: 73.75%

 ** Valid ** Epoch: [186/500] Iter: [72726/195500] Loss: 1.932 Acc: 34.96%

 ** Time 13:37

 ** Train ** Epoch: [187/500] Iter: [73117/195500] Loss: 0.981 Acc: 63.75%

 ** Valid ** Epoch: [187/500] Iter: [73117/195500] Loss: 1.971 Acc: 33.51%

 ** Time 13:37

 ** Train ** Epoch: [188/500] Iter: [73508/195500] Loss: 0.825 Acc: 67.5%

 ** Valid ** Epoch: [188/500] Iter: [73508/195500] Loss: 1.943 Acc: 33.79%

 ** Time 13:37

 ** Train ** Epoch: [189/500] Iter: [73899/195500] Loss: 0.728 Acc: 73.75%

 ** Valid ** Epoch: [189/500] Iter: [73899/195500] Loss: 1.938 Acc: 33.67%

 ** Time 13:37

 ** Train ** Epoch: [190/500] Iter: [74290/195500] Loss: 0.803 Acc: 70.0%

 ** Valid ** Epoch: [190/500] Iter: [74290/195500] Loss: 1.908 Acc: 34.33%

 ** Time 13:37

 ** Train ** Epoch: [191/500] Iter: [74681/195500] Loss: 0.92 Acc: 70.0%

 ** Valid ** Epoch: [191/500] Iter: [74681/195500] Loss: 1.947 Acc: 33.72%

 ** Time 13:38

 ** Train ** Epoch: [192/500] Iter: [75072/195500] Loss: 0.784 Acc: 71.25%

 ** Valid ** Epoch: [192/500] Iter: [75072/195500] Loss: 1.947 Acc: 32.17%

 ** Time 13:38

 ** Train ** Epoch: [193/500] Iter: [75463/195500] Loss: 0.818 Acc: 76.25%

 ** Valid ** Epoch: [193/500] Iter: [75463/195500] Loss: 1.888 Acc: 31.57%

 ** Time 13:38

 ** Train ** Epoch: [194/500] Iter: [75854/195500] Loss: 0.748 Acc: 71.25%

 ** Valid ** Epoch: [194/500] Iter: [75854/195500] Loss: 1.857 Acc: 34.42%

 ** Time 13:38

 ** Train ** Epoch: [195/500] Iter: [76245/195500] Loss: 0.805 Acc: 76.25%

 ** Valid ** Epoch: [195/500] Iter: [76245/195500] Loss: 1.947 Acc: 29.8%

 ** Time 13:38

 ** Train ** Epoch: [196/500] Iter: [76636/195500] Loss: 0.64 Acc: 82.5%

 ** Valid ** Epoch: [196/500] Iter: [76636/195500] Loss: 1.907 Acc: 27.78%

 ** Time 13:38

 ** Train ** Epoch: [197/500] Iter: [77027/195500] Loss: 0.834 Acc: 73.75%

 ** Valid ** Epoch: [197/500] Iter: [77027/195500] Loss: 1.933 Acc: 31.71%

 ** Time 13:38

 ** Train ** Epoch: [198/500] Iter: [77418/195500] Loss: 0.92 Acc: 66.25%

 ** Valid ** Epoch: [198/500] Iter: [77418/195500] Loss: 1.927 Acc: 31.02%

 ** Time 13:39

 ** Train ** Epoch: [199/500] Iter: [77809/195500] Loss: 0.927 Acc: 62.5%

 ** Valid ** Epoch: [199/500] Iter: [77809/195500] Loss: 1.871 Acc: 31.41%

 ** Time 13:39

 ** Train ** Epoch: [200/500] Iter: [78200/195500] Loss: 0.66 Acc: 77.5%

 ** Valid ** Epoch: [200/500] Iter: [78200/195500] Loss: 1.885 Acc: 30.93%

 ** Time 13:39

 ** Train ** Epoch: [201/500] Iter: [78591/195500] Loss: 0.87 Acc: 71.25%

 ** Valid ** Epoch: [201/500] Iter: [78591/195500] Loss: 1.794 Acc: 34.42%

 ** Time 13:39

 ** Train ** Epoch: [202/500] Iter: [78982/195500] Loss: 0.873 Acc: 67.5%

 ** Valid ** Epoch: [202/500] Iter: [78982/195500] Loss: 1.92 Acc: 28.95%

 ** Time 13:39

 ** Train ** Epoch: [203/500] Iter: [79373/195500] Loss: 0.756 Acc: 72.5%

 ** Valid ** Epoch: [203/500] Iter: [79373/195500] Loss: 2.031 Acc: 30.89%

 ** Time 13:39

 ** Train ** Epoch: [204/500] Iter: [79764/195500] Loss: 0.881 Acc: 71.25%

 ** Valid ** Epoch: [204/500] Iter: [79764/195500] Loss: 1.949 Acc: 32.14%

 ** Time 13:39

 ** Train ** Epoch: [205/500] Iter: [80155/195500] Loss: 0.802 Acc: 70.0%

 ** Valid ** Epoch: [205/500] Iter: [80155/195500] Loss: 1.952 Acc: 30.86%

 ** Time 13:40

 ** Train ** Epoch: [206/500] Iter: [80546/195500] Loss: 0.854 Acc: 67.5%

 ** Valid ** Epoch: [206/500] Iter: [80546/195500] Loss: 1.925 Acc: 31.07%

 ** Time 13:40

 ** Train ** Epoch: [207/500] Iter: [80937/195500] Loss: 0.793 Acc: 68.75%

 ** Valid ** Epoch: [207/500] Iter: [80937/195500] Loss: 1.941 Acc: 32.16%

 ** Time 13:40

 ** Train ** Epoch: [208/500] Iter: [81328/195500] Loss: 0.874 Acc: 68.75%

 ** Valid ** Epoch: [208/500] Iter: [81328/195500] Loss: 1.984 Acc: 25.66%

 ** Time 13:40

 ** Train ** Epoch: [209/500] Iter: [81719/195500] Loss: 0.948 Acc: 67.5%

 ** Valid ** Epoch: [209/500] Iter: [81719/195500] Loss: 1.918 Acc: 30.62%

 ** Time 13:40

 ** Train ** Epoch: [210/500] Iter: [82110/195500] Loss: 0.751 Acc: 70.0%

 ** Valid ** Epoch: [210/500] Iter: [82110/195500] Loss: 1.963 Acc: 27.4%

 ** Time 13:40

 ** Train ** Epoch: [211/500] Iter: [82501/195500] Loss: 0.889 Acc: 68.75%

 ** Valid ** Epoch: [211/500] Iter: [82501/195500] Loss: 1.919 Acc: 29.42%

 ** Time 13:40

 ** Train ** Epoch: [212/500] Iter: [82892/195500] Loss: 0.876 Acc: 66.25%

 ** Valid ** Epoch: [212/500] Iter: [82892/195500] Loss: 1.903 Acc: 32.22%

 ** Time 13:41

 ** Train ** Epoch: [213/500] Iter: [83283/195500] Loss: 0.669 Acc: 75.0%

 ** Valid ** Epoch: [213/500] Iter: [83283/195500] Loss: 1.876 Acc: 33.39%

 ** Time 13:41

 ** Train ** Epoch: [214/500] Iter: [83674/195500] Loss: 0.712 Acc: 78.75%

 ** Valid ** Epoch: [214/500] Iter: [83674/195500] Loss: 1.924 Acc: 33.89%

 ** Time 13:41

 ** Train ** Epoch: [215/500] Iter: [84065/195500] Loss: 0.79 Acc: 70.0%

 ** Valid ** Epoch: [215/500] Iter: [84065/195500] Loss: 1.899 Acc: 30.25%

 ** Time 13:41

 ** Train ** Epoch: [216/500] Iter: [84456/195500] Loss: 0.645 Acc: 81.25%

 ** Valid ** Epoch: [216/500] Iter: [84456/195500] Loss: 1.917 Acc: 32.2%

 ** Time 13:41

 ** Train ** Epoch: [217/500] Iter: [84847/195500] Loss: 0.428 Acc: 83.75%

 ** Valid ** Epoch: [217/500] Iter: [84847/195500] Loss: 1.957 Acc: 30.9%

 ** Time 13:41

 ** Train ** Epoch: [218/500] Iter: [85238/195500] Loss: 0.717 Acc: 73.75%

 ** Valid ** Epoch: [218/500] Iter: [85238/195500] Loss: 1.919 Acc: 34.08%

 ** Time 13:41

 ** Train ** Epoch: [219/500] Iter: [85629/195500] Loss: 0.86 Acc: 71.25%

 ** Valid ** Epoch: [219/500] Iter: [85629/195500] Loss: 1.941 Acc: 31.6%

 ** Time 13:42

 ** Train ** Epoch: [220/500] Iter: [86020/195500] Loss: 0.828 Acc: 70.0%

 ** Valid ** Epoch: [220/500] Iter: [86020/195500] Loss: 2.002 Acc: 32.35%

 ** Time 13:42

 ** Train ** Epoch: [221/500] Iter: [86411/195500] Loss: 1.01 Acc: 67.5%

 ** Valid ** Epoch: [221/500] Iter: [86411/195500] Loss: 1.94 Acc: 32.5%

 ** Time 13:42

 ** Train ** Epoch: [222/500] Iter: [86802/195500] Loss: 0.776 Acc: 71.25%

 ** Valid ** Epoch: [222/500] Iter: [86802/195500] Loss: 1.988 Acc: 28.43%

 ** Time 13:42

 ** Train ** Epoch: [223/500] Iter: [87193/195500] Loss: 1.034 Acc: 67.5%

 ** Valid ** Epoch: [223/500] Iter: [87193/195500] Loss: 1.901 Acc: 33.36%

 ** Time 13:42

 ** Train ** Epoch: [224/500] Iter: [87584/195500] Loss: 0.856 Acc: 71.25%

 ** Valid ** Epoch: [224/500] Iter: [87584/195500] Loss: 1.973 Acc: 27.46%

 ** Time 13:42

 ** Train ** Epoch: [225/500] Iter: [87975/195500] Loss: 0.737 Acc: 75.0%

 ** Valid ** Epoch: [225/500] Iter: [87975/195500] Loss: 1.932 Acc: 28.38%

 ** Time 13:42

 ** Train ** Epoch: [226/500] Iter: [88366/195500] Loss: 0.854 Acc: 65.0%

 ** Valid ** Epoch: [226/500] Iter: [88366/195500] Loss: 1.964 Acc: 33.08%

 ** Time 13:42

 ** Train ** Epoch: [227/500] Iter: [88757/195500] Loss: 0.872 Acc: 73.75%

 ** Valid ** Epoch: [227/500] Iter: [88757/195500] Loss: 1.928 Acc: 29.51%

 ** Time 13:43

 ** Train ** Epoch: [228/500] Iter: [89148/195500] Loss: 0.896 Acc: 71.25%

 ** Valid ** Epoch: [228/500] Iter: [89148/195500] Loss: 1.942 Acc: 31.41%

 ** Time 13:43

 ** Train ** Epoch: [229/500] Iter: [89539/195500] Loss: 0.943 Acc: 62.5%

 ** Valid ** Epoch: [229/500] Iter: [89539/195500] Loss: 1.971 Acc: 31.04%

 ** Time 13:43

 ** Train ** Epoch: [230/500] Iter: [89930/195500] Loss: 0.647 Acc: 81.25%

 ** Valid ** Epoch: [230/500] Iter: [89930/195500] Loss: 1.891 Acc: 32.84%

 ** Time 13:43

 ** Train ** Epoch: [231/500] Iter: [90321/195500] Loss: 0.916 Acc: 68.75%

 ** Valid ** Epoch: [231/500] Iter: [90321/195500] Loss: 1.927 Acc: 32.65%

 ** Time 13:43

 ** Train ** Epoch: [232/500] Iter: [90712/195500] Loss: 0.986 Acc: 61.25%

 ** Valid ** Epoch: [232/500] Iter: [90712/195500] Loss: 1.836 Acc: 36.07%

 ** Time 13:43

 ** Train ** Epoch: [233/500] Iter: [91103/195500] Loss: 0.81 Acc: 70.0%

 ** Valid ** Epoch: [233/500] Iter: [91103/195500] Loss: 1.942 Acc: 34.36%

 ** Time 13:43

 ** Train ** Epoch: [234/500] Iter: [91494/195500] Loss: 0.791 Acc: 70.0%

 ** Valid ** Epoch: [234/500] Iter: [91494/195500] Loss: 1.995 Acc: 30.43%

 ** Time 13:44

 ** Train ** Epoch: [235/500] Iter: [91885/195500] Loss: 0.975 Acc: 61.25%

 ** Valid ** Epoch: [235/500] Iter: [91885/195500] Loss: 2.001 Acc: 26.28%

 ** Time 13:44

 ** Train ** Epoch: [236/500] Iter: [92276/195500] Loss: 1.168 Acc: 62.5%

 ** Valid ** Epoch: [236/500] Iter: [92276/195500] Loss: 1.862 Acc: 31.07%

 ** Time 13:44

 ** Train ** Epoch: [237/500] Iter: [92667/195500] Loss: 1.062 Acc: 65.0%

 ** Valid ** Epoch: [237/500] Iter: [92667/195500] Loss: 2.06 Acc: 32.38%

 ** Time 13:44

 ** Train ** Epoch: [238/500] Iter: [93058/195500] Loss: 0.888 Acc: 66.25%

 ** Valid ** Epoch: [238/500] Iter: [93058/195500] Loss: 1.92 Acc: 31.54%

 ** Time 13:44

 ** Train ** Epoch: [239/500] Iter: [93449/195500] Loss: 0.88 Acc: 72.5%

 ** Valid ** Epoch: [239/500] Iter: [93449/195500] Loss: 1.92 Acc: 31.95%

 ** Time 13:44

 ** Train ** Epoch: [240/500] Iter: [93840/195500] Loss: 1.051 Acc: 61.25%

 ** Valid ** Epoch: [240/500] Iter: [93840/195500] Loss: 1.958 Acc: 31.32%

 ** Time 13:44

 ** Train ** Epoch: [241/500] Iter: [94231/195500] Loss: 1.063 Acc: 63.75%

 ** Valid ** Epoch: [241/500] Iter: [94231/195500] Loss: 1.931 Acc: 34.36%

 ** Time 13:45

 ** Train ** Epoch: [242/500] Iter: [94622/195500] Loss: 0.886 Acc: 73.75%

 ** Valid ** Epoch: [242/500] Iter: [94622/195500] Loss: 1.96 Acc: 29.96%

 ** Time 13:45

 ** Train ** Epoch: [243/500] Iter: [95013/195500] Loss: 0.665 Acc: 77.5%

 ** Valid ** Epoch: [243/500] Iter: [95013/195500] Loss: 1.963 Acc: 30.1%

 ** Time 13:45

 ** Train ** Epoch: [244/500] Iter: [95404/195500] Loss: 0.918 Acc: 71.25%

 ** Valid ** Epoch: [244/500] Iter: [95404/195500] Loss: 1.961 Acc: 29.47%

 ** Time 13:45

 ** Train ** Epoch: [245/500] Iter: [95795/195500] Loss: 0.945 Acc: 71.25%

 ** Valid ** Epoch: [245/500] Iter: [95795/195500] Loss: 1.922 Acc: 34.16%

 ** Time 13:45

 ** Train ** Epoch: [246/500] Iter: [96186/195500] Loss: 0.823 Acc: 71.25%

 ** Valid ** Epoch: [246/500] Iter: [96186/195500] Loss: 1.906 Acc: 28.25%

 ** Time 13:45

 ** Train ** Epoch: [247/500] Iter: [96577/195500] Loss: 0.955 Acc: 67.5%

 ** Valid ** Epoch: [247/500] Iter: [96577/195500] Loss: 1.968 Acc: 33.47%

 ** Time 13:45

 ** Train ** Epoch: [248/500] Iter: [96968/195500] Loss: 0.7 Acc: 76.25%

 ** Valid ** Epoch: [248/500] Iter: [96968/195500] Loss: 1.882 Acc: 30.77%

 ** Time 13:46

 ** Train ** Epoch: [249/500] Iter: [97359/195500] Loss: 0.685 Acc: 72.5%

 ** Valid ** Epoch: [249/500] Iter: [97359/195500] Loss: 1.923 Acc: 33.33%

** Changing LR to 0.001 


 ** Time 13:46

 ** Train ** Epoch: [250/500] Iter: [97750/195500] Loss: 0.736 Acc: 75.0%

 ** Valid ** Epoch: [250/500] Iter: [97750/195500] Loss: 1.944 Acc: 30.29%

 ** Time 13:46

 ** Train ** Epoch: [251/500] Iter: [98141/195500] Loss: 0.671 Acc: 77.5%

 ** Valid ** Epoch: [251/500] Iter: [98141/195500] Loss: 1.97 Acc: 30.48%

 ** Time 13:46

 ** Train ** Epoch: [252/500] Iter: [98532/195500] Loss: 0.627 Acc: 81.25%

 ** Valid ** Epoch: [252/500] Iter: [98532/195500] Loss: 1.938 Acc: 30.33%

 ** Time 13:46

 ** Train ** Epoch: [253/500] Iter: [98923/195500] Loss: 0.662 Acc: 75.0%

 ** Valid ** Epoch: [253/500] Iter: [98923/195500] Loss: 1.973 Acc: 29.49%

 ** Time 13:46

 ** Train ** Epoch: [254/500] Iter: [99314/195500] Loss: 0.714 Acc: 76.25%

 ** Valid ** Epoch: [254/500] Iter: [99314/195500] Loss: 1.93 Acc: 29.91%

 ** Time 13:46

 ** Train ** Epoch: [255/500] Iter: [99705/195500] Loss: 0.567 Acc: 82.5%

 ** Valid ** Epoch: [255/500] Iter: [99705/195500] Loss: 1.973 Acc: 28.85%

 ** Time 13:47

 ** Train ** Epoch: [256/500] Iter: [100096/195500] Loss: 0.788 Acc: 73.75%

 ** Valid ** Epoch: [256/500] Iter: [100096/195500] Loss: 1.959 Acc: 28.98%

 ** Time 13:47

 ** Train ** Epoch: [257/500] Iter: [100487/195500] Loss: 0.815 Acc: 71.25%

 ** Valid ** Epoch: [257/500] Iter: [100487/195500] Loss: 1.968 Acc: 29.07%

 ** Time 13:47

 ** Train ** Epoch: [258/500] Iter: [100878/195500] Loss: 0.538 Acc: 78.75%

 ** Valid ** Epoch: [258/500] Iter: [100878/195500] Loss: 1.946 Acc: 28.36%

 ** Time 13:47

 ** Train ** Epoch: [259/500] Iter: [101269/195500] Loss: 0.704 Acc: 80.0%

 ** Valid ** Epoch: [259/500] Iter: [101269/195500] Loss: 1.951 Acc: 27.78%

 ** Time 13:47

 ** Train ** Epoch: [260/500] Iter: [101660/195500] Loss: 0.763 Acc: 73.75%

 ** Valid ** Epoch: [260/500] Iter: [101660/195500] Loss: 1.978 Acc: 28.4%

 ** Time 13:47

 ** Train ** Epoch: [261/500] Iter: [102051/195500] Loss: 0.968 Acc: 73.75%

 ** Valid ** Epoch: [261/500] Iter: [102051/195500] Loss: 1.898 Acc: 30.0%

 ** Time 13:47

 ** Train ** Epoch: [262/500] Iter: [102442/195500] Loss: 0.732 Acc: 73.75%

 ** Valid ** Epoch: [262/500] Iter: [102442/195500] Loss: 1.984 Acc: 27.87%

 ** Time 13:48

 ** Train ** Epoch: [263/500] Iter: [102833/195500] Loss: 0.676 Acc: 77.5%

 ** Valid ** Epoch: [263/500] Iter: [102833/195500] Loss: 1.94 Acc: 29.38%

 ** Time 13:48

 ** Train ** Epoch: [264/500] Iter: [103224/195500] Loss: 0.938 Acc: 67.5%

 ** Valid ** Epoch: [264/500] Iter: [103224/195500] Loss: 1.976 Acc: 29.47%

 ** Time 13:48

 ** Train ** Epoch: [265/500] Iter: [103615/195500] Loss: 0.988 Acc: 70.0%

 ** Valid ** Epoch: [265/500] Iter: [103615/195500] Loss: 1.943 Acc: 29.49%

 ** Time 13:48

 ** Train ** Epoch: [266/500] Iter: [104006/195500] Loss: 0.708 Acc: 75.0%

 ** Valid ** Epoch: [266/500] Iter: [104006/195500] Loss: 1.959 Acc: 29.58%

 ** Time 13:48

 ** Train ** Epoch: [267/500] Iter: [104397/195500] Loss: 0.629 Acc: 75.0%

 ** Valid ** Epoch: [267/500] Iter: [104397/195500] Loss: 1.89 Acc: 30.88%

 ** Time 13:48

 ** Train ** Epoch: [268/500] Iter: [104788/195500] Loss: 0.706 Acc: 73.75%

 ** Valid ** Epoch: [268/500] Iter: [104788/195500] Loss: 1.934 Acc: 30.04%

 ** Time 13:48

 ** Train ** Epoch: [269/500] Iter: [105179/195500] Loss: 0.91 Acc: 71.25%

 ** Valid ** Epoch: [269/500] Iter: [105179/195500] Loss: 1.908 Acc: 30.94%

 ** Time 13:49

 ** Train ** Epoch: [270/500] Iter: [105570/195500] Loss: 0.838 Acc: 77.5%

 ** Valid ** Epoch: [270/500] Iter: [105570/195500] Loss: 1.925 Acc: 29.82%

 ** Time 13:49

 ** Train ** Epoch: [271/500] Iter: [105961/195500] Loss: 0.71 Acc: 72.5%

 ** Valid ** Epoch: [271/500] Iter: [105961/195500] Loss: 1.96 Acc: 28.87%

 ** Time 13:49

 ** Train ** Epoch: [272/500] Iter: [106352/195500] Loss: 0.715 Acc: 76.25%

 ** Valid ** Epoch: [272/500] Iter: [106352/195500] Loss: 1.989 Acc: 27.67%

 ** Time 13:49

 ** Train ** Epoch: [273/500] Iter: [106743/195500] Loss: 0.436 Acc: 83.75%

 ** Valid ** Epoch: [273/500] Iter: [106743/195500] Loss: 1.997 Acc: 28.2%

 ** Time 13:49

 ** Train ** Epoch: [274/500] Iter: [107134/195500] Loss: 0.774 Acc: 75.0%

 ** Valid ** Epoch: [274/500] Iter: [107134/195500] Loss: 1.936 Acc: 29.04%

 ** Time 13:49

 ** Train ** Epoch: [275/500] Iter: [107525/195500] Loss: 0.875 Acc: 73.75%

 ** Valid ** Epoch: [275/500] Iter: [107525/195500] Loss: 1.938 Acc: 29.81%

 ** Time 13:49

 ** Train ** Epoch: [276/500] Iter: [107916/195500] Loss: 0.831 Acc: 68.75%

 ** Valid ** Epoch: [276/500] Iter: [107916/195500] Loss: 1.952 Acc: 29.24%

 ** Time 13:50

 ** Train ** Epoch: [277/500] Iter: [108307/195500] Loss: 0.543 Acc: 81.25%

 ** Valid ** Epoch: [277/500] Iter: [108307/195500] Loss: 1.941 Acc: 30.27%

 ** Time 13:50

 ** Train ** Epoch: [278/500] Iter: [108698/195500] Loss: 0.622 Acc: 77.5%

 ** Valid ** Epoch: [278/500] Iter: [108698/195500] Loss: 1.938 Acc: 29.52%

 ** Time 13:50

 ** Train ** Epoch: [279/500] Iter: [109089/195500] Loss: 0.563 Acc: 81.25%

 ** Valid ** Epoch: [279/500] Iter: [109089/195500] Loss: 1.905 Acc: 31.11%

 ** Time 13:50

 ** Train ** Epoch: [280/500] Iter: [109480/195500] Loss: 0.565 Acc: 80.0%

 ** Valid ** Epoch: [280/500] Iter: [109480/195500] Loss: 1.904 Acc: 29.95%

 ** Time 13:50

 ** Train ** Epoch: [281/500] Iter: [109871/195500] Loss: 0.608 Acc: 81.25%

 ** Valid ** Epoch: [281/500] Iter: [109871/195500] Loss: 1.971 Acc: 29.47%

 ** Time 13:50

 ** Train ** Epoch: [282/500] Iter: [110262/195500] Loss: 0.762 Acc: 72.5%

 ** Valid ** Epoch: [282/500] Iter: [110262/195500] Loss: 1.93 Acc: 30.47%

 ** Time 13:50

 ** Train ** Epoch: [283/500] Iter: [110653/195500] Loss: 0.775 Acc: 68.75%

 ** Valid ** Epoch: [283/500] Iter: [110653/195500] Loss: 1.938 Acc: 30.15%

 ** Time 13:51

 ** Train ** Epoch: [284/500] Iter: [111044/195500] Loss: 0.738 Acc: 73.75%

 ** Valid ** Epoch: [284/500] Iter: [111044/195500] Loss: 1.921 Acc: 29.75%

 ** Time 13:51

 ** Train ** Epoch: [285/500] Iter: [111435/195500] Loss: 0.813 Acc: 72.5%

 ** Valid ** Epoch: [285/500] Iter: [111435/195500] Loss: 1.932 Acc: 29.24%

 ** Time 13:51

 ** Train ** Epoch: [286/500] Iter: [111826/195500] Loss: 0.748 Acc: 75.0%

 ** Valid ** Epoch: [286/500] Iter: [111826/195500] Loss: 1.953 Acc: 28.44%

 ** Time 13:51

 ** Train ** Epoch: [287/500] Iter: [112217/195500] Loss: 0.704 Acc: 72.5%

 ** Valid ** Epoch: [287/500] Iter: [112217/195500] Loss: 1.927 Acc: 28.73%

 ** Time 13:51

 ** Train ** Epoch: [288/500] Iter: [112608/195500] Loss: 0.999 Acc: 68.75%

 ** Valid ** Epoch: [288/500] Iter: [112608/195500] Loss: 1.934 Acc: 28.74%

 ** Time 13:51

 ** Train ** Epoch: [289/500] Iter: [112999/195500] Loss: 0.673 Acc: 71.25%

 ** Valid ** Epoch: [289/500] Iter: [112999/195500] Loss: 1.916 Acc: 29.38%

 ** Time 13:51

 ** Train ** Epoch: [290/500] Iter: [113390/195500] Loss: 0.75 Acc: 71.25%

 ** Valid ** Epoch: [290/500] Iter: [113390/195500] Loss: 1.973 Acc: 29.76%

 ** Time 13:52

 ** Train ** Epoch: [291/500] Iter: [113781/195500] Loss: 0.93 Acc: 65.0%

 ** Valid ** Epoch: [291/500] Iter: [113781/195500] Loss: 1.93 Acc: 29.45%

 ** Time 13:52

 ** Train ** Epoch: [292/500] Iter: [114172/195500] Loss: 0.769 Acc: 75.0%

 ** Valid ** Epoch: [292/500] Iter: [114172/195500] Loss: 2.01 Acc: 28.98%

 ** Time 13:52

 ** Train ** Epoch: [293/500] Iter: [114563/195500] Loss: 0.682 Acc: 78.75%

 ** Valid ** Epoch: [293/500] Iter: [114563/195500] Loss: 1.904 Acc: 29.53%

 ** Time 13:52

 ** Train ** Epoch: [294/500] Iter: [114954/195500] Loss: 0.805 Acc: 77.5%

 ** Valid ** Epoch: [294/500] Iter: [114954/195500] Loss: 1.916 Acc: 30.23%

 ** Time 13:52

 ** Train ** Epoch: [295/500] Iter: [115345/195500] Loss: 0.74 Acc: 70.0%

 ** Valid ** Epoch: [295/500] Iter: [115345/195500] Loss: 1.947 Acc: 29.87%

 ** Time 13:52

 ** Train ** Epoch: [296/500] Iter: [115736/195500] Loss: 0.829 Acc: 68.75%

 ** Valid ** Epoch: [296/500] Iter: [115736/195500] Loss: 1.909 Acc: 30.96%

 ** Time 13:52

 ** Train ** Epoch: [297/500] Iter: [116127/195500] Loss: 0.796 Acc: 68.75%

 ** Valid ** Epoch: [297/500] Iter: [116127/195500] Loss: 1.922 Acc: 29.75%

 ** Time 13:53

 ** Train ** Epoch: [298/500] Iter: [116518/195500] Loss: 0.737 Acc: 71.25%

 ** Valid ** Epoch: [298/500] Iter: [116518/195500] Loss: 1.962 Acc: 29.16%

 ** Time 13:53

 ** Train ** Epoch: [299/500] Iter: [116909/195500] Loss: 1.004 Acc: 65.0%

 ** Valid ** Epoch: [299/500] Iter: [116909/195500] Loss: 1.943 Acc: 28.69%

 ** Time 13:53

 ** Train ** Epoch: [300/500] Iter: [117300/195500] Loss: 0.909 Acc: 70.0%

 ** Valid ** Epoch: [300/500] Iter: [117300/195500] Loss: 1.946 Acc: 28.16%

 ** Time 13:53

 ** Train ** Epoch: [301/500] Iter: [117691/195500] Loss: 0.853 Acc: 73.75%

 ** Valid ** Epoch: [301/500] Iter: [117691/195500] Loss: 1.968 Acc: 29.24%

 ** Time 13:53

 ** Train ** Epoch: [302/500] Iter: [118082/195500] Loss: 0.825 Acc: 72.5%

 ** Valid ** Epoch: [302/500] Iter: [118082/195500] Loss: 1.948 Acc: 30.93%

 ** Time 13:53

 ** Train ** Epoch: [303/500] Iter: [118473/195500] Loss: 0.63 Acc: 82.5%

 ** Valid ** Epoch: [303/500] Iter: [118473/195500] Loss: 1.938 Acc: 29.79%

 ** Time 13:53

 ** Train ** Epoch: [304/500] Iter: [118864/195500] Loss: 0.921 Acc: 68.75%

 ** Valid ** Epoch: [304/500] Iter: [118864/195500] Loss: 1.898 Acc: 29.93%

 ** Time 13:53

 ** Train ** Epoch: [305/500] Iter: [119255/195500] Loss: 0.658 Acc: 75.0%

 ** Valid ** Epoch: [305/500] Iter: [119255/195500] Loss: 1.935 Acc: 28.23%

 ** Time 13:54

 ** Train ** Epoch: [306/500] Iter: [119646/195500] Loss: 0.72 Acc: 71.25%

 ** Valid ** Epoch: [306/500] Iter: [119646/195500] Loss: 1.923 Acc: 29.95%

 ** Time 13:54

 ** Train ** Epoch: [307/500] Iter: [120037/195500] Loss: 0.684 Acc: 73.75%

 ** Valid ** Epoch: [307/500] Iter: [120037/195500] Loss: 1.94 Acc: 29.38%

 ** Time 13:54

 ** Train ** Epoch: [308/500] Iter: [120428/195500] Loss: 0.861 Acc: 80.0%

 ** Valid ** Epoch: [308/500] Iter: [120428/195500] Loss: 1.963 Acc: 29.02%

 ** Time 13:54

 ** Train ** Epoch: [309/500] Iter: [120819/195500] Loss: 0.822 Acc: 72.5%

 ** Valid ** Epoch: [309/500] Iter: [120819/195500] Loss: 1.9 Acc: 30.48%

 ** Time 13:54

 ** Train ** Epoch: [310/500] Iter: [121210/195500] Loss: 0.88 Acc: 72.5%

 ** Valid ** Epoch: [310/500] Iter: [121210/195500] Loss: 1.972 Acc: 29.1%

 ** Time 13:54

 ** Train ** Epoch: [311/500] Iter: [121601/195500] Loss: 0.667 Acc: 78.75%

 ** Valid ** Epoch: [311/500] Iter: [121601/195500] Loss: 1.946 Acc: 29.35%

 ** Time 13:54

 ** Train ** Epoch: [312/500] Iter: [121992/195500] Loss: 0.944 Acc: 66.25%

 ** Valid ** Epoch: [312/500] Iter: [121992/195500] Loss: 1.966 Acc: 27.98%

 ** Time 13:55

 ** Train ** Epoch: [313/500] Iter: [122383/195500] Loss: 0.873 Acc: 68.75%

 ** Valid ** Epoch: [313/500] Iter: [122383/195500] Loss: 1.948 Acc: 28.56%

 ** Time 13:55

 ** Train ** Epoch: [314/500] Iter: [122774/195500] Loss: 0.784 Acc: 72.5%

 ** Valid ** Epoch: [314/500] Iter: [122774/195500] Loss: 1.953 Acc: 28.99%

 ** Time 13:55

 ** Train ** Epoch: [315/500] Iter: [123165/195500] Loss: 1.137 Acc: 62.5%

 ** Valid ** Epoch: [315/500] Iter: [123165/195500] Loss: 1.901 Acc: 30.86%

 ** Time 13:55

 ** Train ** Epoch: [316/500] Iter: [123556/195500] Loss: 0.714 Acc: 66.25%

 ** Valid ** Epoch: [316/500] Iter: [123556/195500] Loss: 1.897 Acc: 29.91%

 ** Time 13:55

 ** Train ** Epoch: [317/500] Iter: [123947/195500] Loss: 0.668 Acc: 75.0%

 ** Valid ** Epoch: [317/500] Iter: [123947/195500] Loss: 1.889 Acc: 31.84%

 ** Time 13:55

 ** Train ** Epoch: [318/500] Iter: [124338/195500] Loss: 0.648 Acc: 83.75%

 ** Valid ** Epoch: [318/500] Iter: [124338/195500] Loss: 1.918 Acc: 30.84%

 ** Time 13:55

 ** Train ** Epoch: [319/500] Iter: [124729/195500] Loss: 0.857 Acc: 67.5%

 ** Valid ** Epoch: [319/500] Iter: [124729/195500] Loss: 1.962 Acc: 31.01%

 ** Time 13:56

 ** Train ** Epoch: [320/500] Iter: [125120/195500] Loss: 0.634 Acc: 78.75%

 ** Valid ** Epoch: [320/500] Iter: [125120/195500] Loss: 1.929 Acc: 30.42%

 ** Time 13:56

 ** Train ** Epoch: [321/500] Iter: [125511/195500] Loss: 0.998 Acc: 63.75%

 ** Valid ** Epoch: [321/500] Iter: [125511/195500] Loss: 1.896 Acc: 30.96%

 ** Time 13:56

 ** Train ** Epoch: [322/500] Iter: [125902/195500] Loss: 0.734 Acc: 71.25%

 ** Valid ** Epoch: [322/500] Iter: [125902/195500] Loss: 1.897 Acc: 29.69%

 ** Time 13:56

 ** Train ** Epoch: [323/500] Iter: [126293/195500] Loss: 0.675 Acc: 80.0%

 ** Valid ** Epoch: [323/500] Iter: [126293/195500] Loss: 1.904 Acc: 29.72%

 ** Time 13:56

 ** Train ** Epoch: [324/500] Iter: [126684/195500] Loss: 0.638 Acc: 78.75%

 ** Valid ** Epoch: [324/500] Iter: [126684/195500] Loss: 1.945 Acc: 29.41%

 ** Time 13:56

 ** Train ** Epoch: [325/500] Iter: [127075/195500] Loss: 0.631 Acc: 78.75%

 ** Valid ** Epoch: [325/500] Iter: [127075/195500] Loss: 1.921 Acc: 28.98%

 ** Time 13:56

 ** Train ** Epoch: [326/500] Iter: [127466/195500] Loss: 0.688 Acc: 76.25%

 ** Valid ** Epoch: [326/500] Iter: [127466/195500] Loss: 1.954 Acc: 27.93%

 ** Time 13:57

 ** Train ** Epoch: [327/500] Iter: [127857/195500] Loss: 0.737 Acc: 75.0%

 ** Valid ** Epoch: [327/500] Iter: [127857/195500] Loss: 1.934 Acc: 28.78%

 ** Time 13:57

 ** Train ** Epoch: [328/500] Iter: [128248/195500] Loss: 0.661 Acc: 80.0%

 ** Valid ** Epoch: [328/500] Iter: [128248/195500] Loss: 1.937 Acc: 29.27%

 ** Time 13:57

 ** Train ** Epoch: [329/500] Iter: [128639/195500] Loss: 0.869 Acc: 63.75%

 ** Valid ** Epoch: [329/500] Iter: [128639/195500] Loss: 1.954 Acc: 30.16%

 ** Time 13:57

 ** Train ** Epoch: [330/500] Iter: [129030/195500] Loss: 0.717 Acc: 81.25%

 ** Valid ** Epoch: [330/500] Iter: [129030/195500] Loss: 1.943 Acc: 29.06%

 ** Time 13:57

 ** Train ** Epoch: [331/500] Iter: [129421/195500] Loss: 0.733 Acc: 78.75%

 ** Valid ** Epoch: [331/500] Iter: [129421/195500] Loss: 1.894 Acc: 30.09%

 ** Time 13:57

 ** Train ** Epoch: [332/500] Iter: [129812/195500] Loss: 0.764 Acc: 71.25%

 ** Valid ** Epoch: [332/500] Iter: [129812/195500] Loss: 1.867 Acc: 30.65%

 ** Time 13:57

 ** Train ** Epoch: [333/500] Iter: [130203/195500] Loss: 0.748 Acc: 75.0%

 ** Valid ** Epoch: [333/500] Iter: [130203/195500] Loss: 1.921 Acc: 30.02%

 ** Time 13:58

 ** Train ** Epoch: [334/500] Iter: [130594/195500] Loss: 0.756 Acc: 77.5%

 ** Valid ** Epoch: [334/500] Iter: [130594/195500] Loss: 1.857 Acc: 29.89%

 ** Time 13:58

 ** Train ** Epoch: [335/500] Iter: [130985/195500] Loss: 0.608 Acc: 80.0%

 ** Valid ** Epoch: [335/500] Iter: [130985/195500] Loss: 1.915 Acc: 29.4%

 ** Time 13:58

 ** Train ** Epoch: [336/500] Iter: [131376/195500] Loss: 0.774 Acc: 72.5%

 ** Valid ** Epoch: [336/500] Iter: [131376/195500] Loss: 1.897 Acc: 28.98%

 ** Time 13:58

 ** Train ** Epoch: [337/500] Iter: [131767/195500] Loss: 0.72 Acc: 72.5%

 ** Valid ** Epoch: [337/500] Iter: [131767/195500] Loss: 1.93 Acc: 30.47%

 ** Time 13:58

 ** Train ** Epoch: [338/500] Iter: [132158/195500] Loss: 0.521 Acc: 83.75%

 ** Valid ** Epoch: [338/500] Iter: [132158/195500] Loss: 1.913 Acc: 29.39%

 ** Time 13:58

 ** Train ** Epoch: [339/500] Iter: [132549/195500] Loss: 0.754 Acc: 75.0%

 ** Valid ** Epoch: [339/500] Iter: [132549/195500] Loss: 1.915 Acc: 29.34%

 ** Time 13:58

 ** Train ** Epoch: [340/500] Iter: [132940/195500] Loss: 0.757 Acc: 72.5%

 ** Valid ** Epoch: [340/500] Iter: [132940/195500] Loss: 1.938 Acc: 28.66%

 ** Time 13:59

 ** Train ** Epoch: [341/500] Iter: [133331/195500] Loss: 0.699 Acc: 72.5%

 ** Valid ** Epoch: [341/500] Iter: [133331/195500] Loss: 1.885 Acc: 29.75%

 ** Time 13:59

 ** Train ** Epoch: [342/500] Iter: [133722/195500] Loss: 0.816 Acc: 71.25%

 ** Valid ** Epoch: [342/500] Iter: [133722/195500] Loss: 1.877 Acc: 30.34%

 ** Time 13:59

 ** Train ** Epoch: [343/500] Iter: [134113/195500] Loss: 0.749 Acc: 75.0%

 ** Valid ** Epoch: [343/500] Iter: [134113/195500] Loss: 1.951 Acc: 29.57%

 ** Time 13:59

 ** Train ** Epoch: [344/500] Iter: [134504/195500] Loss: 0.77 Acc: 75.0%

 ** Valid ** Epoch: [344/500] Iter: [134504/195500] Loss: 1.947 Acc: 28.87%

 ** Time 13:59

 ** Train ** Epoch: [345/500] Iter: [134895/195500] Loss: 0.815 Acc: 70.0%

 ** Valid ** Epoch: [345/500] Iter: [134895/195500] Loss: 1.921 Acc: 28.62%

 ** Time 13:59

 ** Train ** Epoch: [346/500] Iter: [135286/195500] Loss: 0.929 Acc: 63.75%

 ** Valid ** Epoch: [346/500] Iter: [135286/195500] Loss: 1.919 Acc: 30.31%

 ** Time 13:59

 ** Train ** Epoch: [347/500] Iter: [135677/195500] Loss: 0.626 Acc: 82.5%

 ** Valid ** Epoch: [347/500] Iter: [135677/195500] Loss: 1.93 Acc: 27.92%

 ** Time 14:0

 ** Train ** Epoch: [348/500] Iter: [136068/195500] Loss: 0.63 Acc: 77.5%

 ** Valid ** Epoch: [348/500] Iter: [136068/195500] Loss: 1.915 Acc: 29.55%

 ** Time 14:0

 ** Train ** Epoch: [349/500] Iter: [136459/195500] Loss: 0.736 Acc: 70.0%

 ** Valid ** Epoch: [349/500] Iter: [136459/195500] Loss: 1.936 Acc: 28.43%

** Changing LR to 0.0001 


 ** Time 14:0

 ** Train ** Epoch: [350/500] Iter: [136850/195500] Loss: 0.819 Acc: 72.5%

 ** Valid ** Epoch: [350/500] Iter: [136850/195500] Loss: 1.907 Acc: 28.85%

 ** Time 14:0

 ** Train ** Epoch: [351/500] Iter: [137241/195500] Loss: 0.922 Acc: 66.25%

 ** Valid ** Epoch: [351/500] Iter: [137241/195500] Loss: 1.938 Acc: 29.66%

 ** Time 14:0

 ** Train ** Epoch: [352/500] Iter: [137632/195500] Loss: 0.751 Acc: 68.75%

 ** Valid ** Epoch: [352/500] Iter: [137632/195500] Loss: 1.873 Acc: 29.98%

 ** Time 14:0

 ** Train ** Epoch: [353/500] Iter: [138023/195500] Loss: 0.513 Acc: 80.0%

 ** Valid ** Epoch: [353/500] Iter: [138023/195500] Loss: 1.892 Acc: 29.89%

 ** Time 14:0

 ** Train ** Epoch: [354/500] Iter: [138414/195500] Loss: 0.685 Acc: 78.75%

 ** Valid ** Epoch: [354/500] Iter: [138414/195500] Loss: 1.921 Acc: 29.48%

 ** Time 14:1

 ** Train ** Epoch: [355/500] Iter: [138805/195500] Loss: 0.713 Acc: 78.75%

 ** Valid ** Epoch: [355/500] Iter: [138805/195500] Loss: 1.929 Acc: 29.14%

 ** Time 14:1

 ** Train ** Epoch: [356/500] Iter: [139196/195500] Loss: 0.836 Acc: 67.5%

 ** Valid ** Epoch: [356/500] Iter: [139196/195500] Loss: 1.932 Acc: 30.08%

 ** Time 14:1

 ** Train ** Epoch: [357/500] Iter: [139587/195500] Loss: 0.697 Acc: 76.25%

 ** Valid ** Epoch: [357/500] Iter: [139587/195500] Loss: 1.909 Acc: 29.61%

 ** Time 14:1

 ** Train ** Epoch: [358/500] Iter: [139978/195500] Loss: 0.879 Acc: 65.0%

 ** Valid ** Epoch: [358/500] Iter: [139978/195500] Loss: 1.96 Acc: 30.58%

 ** Time 14:1

 ** Train ** Epoch: [359/500] Iter: [140369/195500] Loss: 0.912 Acc: 72.5%

 ** Valid ** Epoch: [359/500] Iter: [140369/195500] Loss: 1.991 Acc: 30.16%

 ** Time 14:1

 ** Train ** Epoch: [360/500] Iter: [140760/195500] Loss: 1.03 Acc: 68.75%

 ** Valid ** Epoch: [360/500] Iter: [140760/195500] Loss: 1.866 Acc: 30.89%

 ** Time 14:1

 ** Train ** Epoch: [361/500] Iter: [141151/195500] Loss: 0.793 Acc: 77.5%

 ** Valid ** Epoch: [361/500] Iter: [141151/195500] Loss: 1.897 Acc: 29.89%

 ** Time 14:2

 ** Train ** Epoch: [362/500] Iter: [141542/195500] Loss: 0.677 Acc: 76.25%

 ** Valid ** Epoch: [362/500] Iter: [141542/195500] Loss: 1.912 Acc: 29.42%

 ** Time 14:2

 ** Train ** Epoch: [363/500] Iter: [141933/195500] Loss: 0.978 Acc: 62.5%

 ** Valid ** Epoch: [363/500] Iter: [141933/195500] Loss: 1.919 Acc: 29.09%

 ** Time 14:2

 ** Train ** Epoch: [364/500] Iter: [142324/195500] Loss: 0.852 Acc: 65.0%

 ** Valid ** Epoch: [364/500] Iter: [142324/195500] Loss: 1.913 Acc: 29.31%

 ** Time 14:2

 ** Train ** Epoch: [365/500] Iter: [142715/195500] Loss: 0.882 Acc: 70.0%

 ** Valid ** Epoch: [365/500] Iter: [142715/195500] Loss: 1.913 Acc: 30.06%

 ** Time 14:2

 ** Train ** Epoch: [366/500] Iter: [143106/195500] Loss: 0.821 Acc: 71.25%

 ** Valid ** Epoch: [366/500] Iter: [143106/195500] Loss: 1.891 Acc: 30.25%

 ** Time 14:2

 ** Train ** Epoch: [367/500] Iter: [143497/195500] Loss: 0.748 Acc: 78.75%

 ** Valid ** Epoch: [367/500] Iter: [143497/195500] Loss: 1.972 Acc: 29.14%

 ** Time 14:2

 ** Train ** Epoch: [368/500] Iter: [143888/195500] Loss: 0.69 Acc: 78.75%

 ** Valid ** Epoch: [368/500] Iter: [143888/195500] Loss: 1.849 Acc: 31.24%

 ** Time 14:3

 ** Train ** Epoch: [369/500] Iter: [144279/195500] Loss: 0.603 Acc: 82.5%

 ** Valid ** Epoch: [369/500] Iter: [144279/195500] Loss: 1.901 Acc: 29.52%

 ** Time 14:3

 ** Train ** Epoch: [370/500] Iter: [144670/195500] Loss: 0.661 Acc: 78.75%

 ** Valid ** Epoch: [370/500] Iter: [144670/195500] Loss: 1.928 Acc: 28.85%

 ** Time 14:3

 ** Train ** Epoch: [371/500] Iter: [145061/195500] Loss: 0.668 Acc: 73.75%

 ** Valid ** Epoch: [371/500] Iter: [145061/195500] Loss: 1.904 Acc: 29.87%

 ** Time 14:3

 ** Train ** Epoch: [372/500] Iter: [145452/195500] Loss: 0.8 Acc: 73.75%

 ** Valid ** Epoch: [372/500] Iter: [145452/195500] Loss: 1.938 Acc: 29.62%

 ** Time 14:3

 ** Train ** Epoch: [373/500] Iter: [145843/195500] Loss: 0.575 Acc: 78.75%

 ** Valid ** Epoch: [373/500] Iter: [145843/195500] Loss: 1.877 Acc: 30.33%

 ** Time 14:3

 ** Train ** Epoch: [374/500] Iter: [146234/195500] Loss: 0.758 Acc: 70.0%

 ** Valid ** Epoch: [374/500] Iter: [146234/195500] Loss: 1.896 Acc: 31.49%

 ** Time 14:3

 ** Train ** Epoch: [375/500] Iter: [146625/195500] Loss: 0.646 Acc: 73.75%

 ** Valid ** Epoch: [375/500] Iter: [146625/195500] Loss: 1.874 Acc: 30.42%

 ** Time 14:4

 ** Train ** Epoch: [376/500] Iter: [147016/195500] Loss: 0.737 Acc: 78.75%

 ** Valid ** Epoch: [376/500] Iter: [147016/195500] Loss: 1.914 Acc: 30.22%

 ** Time 14:4

 ** Train ** Epoch: [377/500] Iter: [147407/195500] Loss: 0.683 Acc: 77.5%

 ** Valid ** Epoch: [377/500] Iter: [147407/195500] Loss: 1.902 Acc: 29.99%

 ** Time 14:4

 ** Train ** Epoch: [378/500] Iter: [147798/195500] Loss: 0.535 Acc: 83.75%

 ** Valid ** Epoch: [378/500] Iter: [147798/195500] Loss: 1.915 Acc: 29.7%

 ** Time 14:4

 ** Train ** Epoch: [379/500] Iter: [148189/195500] Loss: 0.698 Acc: 77.5%

 ** Valid ** Epoch: [379/500] Iter: [148189/195500] Loss: 1.866 Acc: 30.82%

 ** Time 14:4

 ** Train ** Epoch: [380/500] Iter: [148580/195500] Loss: 0.655 Acc: 78.75%

 ** Valid ** Epoch: [380/500] Iter: [148580/195500] Loss: 1.906 Acc: 30.17%

 ** Time 14:4

 ** Train ** Epoch: [381/500] Iter: [148971/195500] Loss: 0.766 Acc: 76.25%

 ** Valid ** Epoch: [381/500] Iter: [148971/195500] Loss: 1.906 Acc: 28.98%

 ** Time 14:4

 ** Train ** Epoch: [382/500] Iter: [149362/195500] Loss: 0.753 Acc: 73.75%

 ** Valid ** Epoch: [382/500] Iter: [149362/195500] Loss: 1.903 Acc: 30.36%

 ** Time 14:4

 ** Train ** Epoch: [383/500] Iter: [149753/195500] Loss: 1.034 Acc: 65.0%

 ** Valid ** Epoch: [383/500] Iter: [149753/195500] Loss: 1.895 Acc: 30.43%

 ** Time 14:5

 ** Train ** Epoch: [384/500] Iter: [150144/195500] Loss: 0.705 Acc: 77.5%

 ** Valid ** Epoch: [384/500] Iter: [150144/195500] Loss: 1.879 Acc: 30.56%

 ** Time 14:5

 ** Train ** Epoch: [385/500] Iter: [150535/195500] Loss: 0.864 Acc: 72.5%

 ** Valid ** Epoch: [385/500] Iter: [150535/195500] Loss: 1.888 Acc: 31.32%

 ** Time 14:5

 ** Train ** Epoch: [386/500] Iter: [150926/195500] Loss: 0.864 Acc: 72.5%

 ** Valid ** Epoch: [386/500] Iter: [150926/195500] Loss: 1.876 Acc: 30.66%

 ** Time 14:5

 ** Train ** Epoch: [387/500] Iter: [151317/195500] Loss: 0.757 Acc: 73.75%

 ** Valid ** Epoch: [387/500] Iter: [151317/195500] Loss: 1.882 Acc: 30.52%

 ** Time 14:5

 ** Train ** Epoch: [388/500] Iter: [151708/195500] Loss: 0.881 Acc: 73.75%

 ** Valid ** Epoch: [388/500] Iter: [151708/195500] Loss: 1.904 Acc: 29.29%

 ** Time 14:5

 ** Train ** Epoch: [389/500] Iter: [152099/195500] Loss: 0.627 Acc: 75.0%

 ** Valid ** Epoch: [389/500] Iter: [152099/195500] Loss: 1.942 Acc: 29.47%

 ** Time 14:5

 ** Train ** Epoch: [390/500] Iter: [152490/195500] Loss: 0.812 Acc: 70.0%

 ** Valid ** Epoch: [390/500] Iter: [152490/195500] Loss: 1.915 Acc: 29.22%

 ** Time 14:6

 ** Train ** Epoch: [391/500] Iter: [152881/195500] Loss: 0.804 Acc: 68.75%

 ** Valid ** Epoch: [391/500] Iter: [152881/195500] Loss: 1.905 Acc: 29.69%

 ** Time 14:6

 ** Train ** Epoch: [392/500] Iter: [153272/195500] Loss: 0.826 Acc: 73.75%

 ** Valid ** Epoch: [392/500] Iter: [153272/195500] Loss: 1.996 Acc: 29.05%

 ** Time 14:6

 ** Train ** Epoch: [393/500] Iter: [153663/195500] Loss: 0.628 Acc: 77.5%

 ** Valid ** Epoch: [393/500] Iter: [153663/195500] Loss: 1.922 Acc: 29.43%

 ** Time 14:6

 ** Train ** Epoch: [394/500] Iter: [154054/195500] Loss: 0.707 Acc: 75.0%

 ** Valid ** Epoch: [394/500] Iter: [154054/195500] Loss: 1.94 Acc: 29.36%

 ** Time 14:6

 ** Train ** Epoch: [395/500] Iter: [154445/195500] Loss: 0.782 Acc: 72.5%

 ** Valid ** Epoch: [395/500] Iter: [154445/195500] Loss: 1.888 Acc: 29.95%

 ** Time 14:6

 ** Train ** Epoch: [396/500] Iter: [154836/195500] Loss: 0.844 Acc: 68.75%

 ** Valid ** Epoch: [396/500] Iter: [154836/195500] Loss: 1.925 Acc: 29.41%

 ** Time 14:6

 ** Train ** Epoch: [397/500] Iter: [155227/195500] Loss: 0.723 Acc: 75.0%

 ** Valid ** Epoch: [397/500] Iter: [155227/195500] Loss: 1.924 Acc: 28.7%

 ** Time 14:7

 ** Train ** Epoch: [398/500] Iter: [155618/195500] Loss: 1.208 Acc: 57.5%

 ** Valid ** Epoch: [398/500] Iter: [155618/195500] Loss: 1.852 Acc: 31.25%

 ** Time 14:7

 ** Train ** Epoch: [399/500] Iter: [156009/195500] Loss: 1.02 Acc: 65.0%

 ** Valid ** Epoch: [399/500] Iter: [156009/195500] Loss: 1.903 Acc: 30.07%

 ** Time 14:7

 ** Train ** Epoch: [400/500] Iter: [156400/195500] Loss: 0.777 Acc: 72.5%

 ** Valid ** Epoch: [400/500] Iter: [156400/195500] Loss: 1.923 Acc: 29.13%

 ** Time 14:7

 ** Train ** Epoch: [401/500] Iter: [156791/195500] Loss: 0.68 Acc: 75.0%

 ** Valid ** Epoch: [401/500] Iter: [156791/195500] Loss: 1.896 Acc: 29.5%

 ** Time 14:7

 ** Train ** Epoch: [402/500] Iter: [157182/195500] Loss: 1.072 Acc: 60.0%

 ** Valid ** Epoch: [402/500] Iter: [157182/195500] Loss: 1.886 Acc: 30.03%

 ** Time 14:7

 ** Train ** Epoch: [403/500] Iter: [157573/195500] Loss: 0.839 Acc: 72.5%

 ** Valid ** Epoch: [403/500] Iter: [157573/195500] Loss: 1.911 Acc: 29.56%

 ** Time 14:7

 ** Train ** Epoch: [404/500] Iter: [157964/195500] Loss: 0.785 Acc: 72.5%

 ** Valid ** Epoch: [404/500] Iter: [157964/195500] Loss: 1.905 Acc: 28.98%

 ** Time 14:8

 ** Train ** Epoch: [405/500] Iter: [158355/195500] Loss: 0.664 Acc: 72.5%

 ** Valid ** Epoch: [405/500] Iter: [158355/195500] Loss: 1.897 Acc: 29.99%

 ** Time 14:8

 ** Train ** Epoch: [406/500] Iter: [158746/195500] Loss: 0.831 Acc: 72.5%

 ** Valid ** Epoch: [406/500] Iter: [158746/195500] Loss: 1.933 Acc: 29.26%

 ** Time 14:8

 ** Train ** Epoch: [407/500] Iter: [159137/195500] Loss: 0.622 Acc: 81.25%

 ** Valid ** Epoch: [407/500] Iter: [159137/195500] Loss: 1.93 Acc: 28.51%

 ** Time 14:8

 ** Train ** Epoch: [408/500] Iter: [159528/195500] Loss: 0.703 Acc: 77.5%

 ** Valid ** Epoch: [408/500] Iter: [159528/195500] Loss: 1.954 Acc: 28.17%

 ** Time 14:8

 ** Train ** Epoch: [409/500] Iter: [159919/195500] Loss: 0.539 Acc: 80.0%

 ** Valid ** Epoch: [409/500] Iter: [159919/195500] Loss: 1.908 Acc: 29.99%

 ** Time 14:8

 ** Train ** Epoch: [410/500] Iter: [160310/195500] Loss: 0.719 Acc: 76.25%

 ** Valid ** Epoch: [410/500] Iter: [160310/195500] Loss: 1.874 Acc: 30.01%

 ** Time 14:8

 ** Train ** Epoch: [411/500] Iter: [160701/195500] Loss: 0.728 Acc: 72.5%

 ** Valid ** Epoch: [411/500] Iter: [160701/195500] Loss: 1.922 Acc: 29.07%

 ** Time 14:9

 ** Train ** Epoch: [412/500] Iter: [161092/195500] Loss: 0.761 Acc: 73.75%

 ** Valid ** Epoch: [412/500] Iter: [161092/195500] Loss: 1.932 Acc: 29.19%

 ** Time 14:9

 ** Train ** Epoch: [413/500] Iter: [161483/195500] Loss: 0.726 Acc: 70.0%

 ** Valid ** Epoch: [413/500] Iter: [161483/195500] Loss: 1.912 Acc: 29.1%

 ** Time 14:9

 ** Train ** Epoch: [414/500] Iter: [161874/195500] Loss: 0.803 Acc: 76.25%

 ** Valid ** Epoch: [414/500] Iter: [161874/195500] Loss: 1.899 Acc: 29.52%

 ** Time 14:9

 ** Train ** Epoch: [415/500] Iter: [162265/195500] Loss: 0.608 Acc: 78.75%

 ** Valid ** Epoch: [415/500] Iter: [162265/195500] Loss: 1.906 Acc: 30.35%

 ** Time 14:9

 ** Train ** Epoch: [416/500] Iter: [162656/195500] Loss: 0.727 Acc: 75.0%

 ** Valid ** Epoch: [416/500] Iter: [162656/195500] Loss: 1.941 Acc: 29.22%

 ** Time 14:9

 ** Train ** Epoch: [417/500] Iter: [163047/195500] Loss: 0.757 Acc: 72.5%

 ** Valid ** Epoch: [417/500] Iter: [163047/195500] Loss: 1.913 Acc: 29.71%

 ** Time 14:9

 ** Train ** Epoch: [418/500] Iter: [163438/195500] Loss: 0.72 Acc: 77.5%

 ** Valid ** Epoch: [418/500] Iter: [163438/195500] Loss: 1.919 Acc: 28.98%

 ** Time 14:10

 ** Train ** Epoch: [419/500] Iter: [163829/195500] Loss: 0.782 Acc: 70.0%

 ** Valid ** Epoch: [419/500] Iter: [163829/195500] Loss: 1.907 Acc: 29.38%

 ** Time 14:10

 ** Train ** Epoch: [420/500] Iter: [164220/195500] Loss: 0.829 Acc: 67.5%

 ** Valid ** Epoch: [420/500] Iter: [164220/195500] Loss: 1.914 Acc: 30.96%

 ** Time 14:10

 ** Train ** Epoch: [421/500] Iter: [164611/195500] Loss: 0.822 Acc: 68.75%

 ** Valid ** Epoch: [421/500] Iter: [164611/195500] Loss: 1.938 Acc: 29.44%

 ** Time 14:10

 ** Train ** Epoch: [422/500] Iter: [165002/195500] Loss: 0.653 Acc: 78.75%

 ** Valid ** Epoch: [422/500] Iter: [165002/195500] Loss: 1.94 Acc: 29.47%

 ** Time 14:10

 ** Train ** Epoch: [423/500] Iter: [165393/195500] Loss: 0.927 Acc: 66.25%

 ** Valid ** Epoch: [423/500] Iter: [165393/195500] Loss: 1.887 Acc: 30.03%

 ** Time 14:10

 ** Train ** Epoch: [424/500] Iter: [165784/195500] Loss: 0.84 Acc: 68.75%

 ** Valid ** Epoch: [424/500] Iter: [165784/195500] Loss: 1.959 Acc: 28.93%

 ** Time 14:10

 ** Train ** Epoch: [425/500] Iter: [166175/195500] Loss: 0.814 Acc: 71.25%

 ** Valid ** Epoch: [425/500] Iter: [166175/195500] Loss: 1.887 Acc: 30.0%

 ** Time 14:11

 ** Train ** Epoch: [426/500] Iter: [166566/195500] Loss: 0.821 Acc: 73.75%

 ** Valid ** Epoch: [426/500] Iter: [166566/195500] Loss: 1.936 Acc: 29.7%

 ** Time 14:11

 ** Train ** Epoch: [427/500] Iter: [166957/195500] Loss: 0.508 Acc: 77.5%

 ** Valid ** Epoch: [427/500] Iter: [166957/195500] Loss: 1.919 Acc: 29.53%

 ** Time 14:11

 ** Train ** Epoch: [428/500] Iter: [167348/195500] Loss: 0.778 Acc: 72.5%

 ** Valid ** Epoch: [428/500] Iter: [167348/195500] Loss: 1.927 Acc: 28.75%

 ** Time 14:11

 ** Train ** Epoch: [429/500] Iter: [167739/195500] Loss: 0.677 Acc: 77.5%

 ** Valid ** Epoch: [429/500] Iter: [167739/195500] Loss: 1.895 Acc: 29.2%

 ** Time 14:11

 ** Train ** Epoch: [430/500] Iter: [168130/195500] Loss: 0.626 Acc: 80.0%

 ** Valid ** Epoch: [430/500] Iter: [168130/195500] Loss: 1.895 Acc: 30.78%

 ** Time 14:11

 ** Train ** Epoch: [431/500] Iter: [168521/195500] Loss: 0.905 Acc: 61.25%

 ** Valid ** Epoch: [431/500] Iter: [168521/195500] Loss: 1.894 Acc: 30.39%

 ** Time 14:11

 ** Train ** Epoch: [432/500] Iter: [168912/195500] Loss: 0.812 Acc: 73.75%

 ** Valid ** Epoch: [432/500] Iter: [168912/195500] Loss: 1.917 Acc: 29.75%

 ** Time 14:12

 ** Train ** Epoch: [433/500] Iter: [169303/195500] Loss: 0.787 Acc: 71.25%

 ** Valid ** Epoch: [433/500] Iter: [169303/195500] Loss: 1.904 Acc: 29.31%

 ** Time 14:12

 ** Train ** Epoch: [434/500] Iter: [169694/195500] Loss: 0.832 Acc: 70.0%

 ** Valid ** Epoch: [434/500] Iter: [169694/195500] Loss: 1.901 Acc: 29.36%

 ** Time 14:12

 ** Train ** Epoch: [435/500] Iter: [170085/195500] Loss: 0.663 Acc: 78.75%

 ** Valid ** Epoch: [435/500] Iter: [170085/195500] Loss: 1.921 Acc: 29.65%

 ** Time 14:12

 ** Train ** Epoch: [436/500] Iter: [170476/195500] Loss: 0.798 Acc: 71.25%

 ** Valid ** Epoch: [436/500] Iter: [170476/195500] Loss: 1.938 Acc: 30.0%

 ** Time 14:12

 ** Train ** Epoch: [437/500] Iter: [170867/195500] Loss: 0.768 Acc: 72.5%

 ** Valid ** Epoch: [437/500] Iter: [170867/195500] Loss: 1.907 Acc: 29.4%

 ** Time 14:12

 ** Train ** Epoch: [438/500] Iter: [171258/195500] Loss: 0.635 Acc: 76.25%

 ** Valid ** Epoch: [438/500] Iter: [171258/195500] Loss: 1.89 Acc: 29.44%

 ** Time 14:12

 ** Train ** Epoch: [439/500] Iter: [171649/195500] Loss: 0.758 Acc: 72.5%

 ** Valid ** Epoch: [439/500] Iter: [171649/195500] Loss: 1.908 Acc: 29.35%

 ** Time 14:13

 ** Train ** Epoch: [440/500] Iter: [172040/195500] Loss: 0.728 Acc: 77.5%

 ** Valid ** Epoch: [440/500] Iter: [172040/195500] Loss: 1.874 Acc: 31.13%

 ** Time 14:13

 ** Train ** Epoch: [441/500] Iter: [172431/195500] Loss: 0.56 Acc: 85.0%

 ** Valid ** Epoch: [441/500] Iter: [172431/195500] Loss: 1.947 Acc: 30.4%

 ** Time 14:13

 ** Train ** Epoch: [442/500] Iter: [172822/195500] Loss: 0.543 Acc: 83.75%

 ** Valid ** Epoch: [442/500] Iter: [172822/195500] Loss: 1.903 Acc: 29.09%

 ** Time 14:13

 ** Train ** Epoch: [443/500] Iter: [173213/195500] Loss: 0.625 Acc: 81.25%

 ** Valid ** Epoch: [443/500] Iter: [173213/195500] Loss: 1.923 Acc: 29.38%

 ** Time 14:13

 ** Train ** Epoch: [444/500] Iter: [173604/195500] Loss: 0.782 Acc: 71.25%

 ** Valid ** Epoch: [444/500] Iter: [173604/195500] Loss: 1.936 Acc: 29.1%

 ** Time 14:13

 ** Train ** Epoch: [445/500] Iter: [173995/195500] Loss: 0.927 Acc: 70.0%

 ** Valid ** Epoch: [445/500] Iter: [173995/195500] Loss: 1.877 Acc: 30.52%

 ** Time 14:13

 ** Train ** Epoch: [446/500] Iter: [174386/195500] Loss: 0.832 Acc: 73.75%

 ** Valid ** Epoch: [446/500] Iter: [174386/195500] Loss: 1.923 Acc: 30.01%

 ** Time 14:14

 ** Train ** Epoch: [447/500] Iter: [174777/195500] Loss: 0.744 Acc: 73.75%

 ** Valid ** Epoch: [447/500] Iter: [174777/195500] Loss: 1.917 Acc: 30.19%

 ** Time 14:14

 ** Train ** Epoch: [448/500] Iter: [175168/195500] Loss: 0.57 Acc: 83.75%

 ** Valid ** Epoch: [448/500] Iter: [175168/195500] Loss: 1.964 Acc: 30.3%

 ** Time 14:14

 ** Train ** Epoch: [449/500] Iter: [175559/195500] Loss: 0.924 Acc: 75.0%

 ** Valid ** Epoch: [449/500] Iter: [175559/195500] Loss: 1.936 Acc: 30.75%

** Changing LR to 1e-05 


 ** Time 14:14

 ** Train ** Epoch: [450/500] Iter: [175950/195500] Loss: 0.769 Acc: 71.25%

 ** Valid ** Epoch: [450/500] Iter: [175950/195500] Loss: 1.936 Acc: 30.11%

 ** Time 14:14

 ** Train ** Epoch: [451/500] Iter: [176341/195500] Loss: 0.874 Acc: 75.0%

 ** Valid ** Epoch: [451/500] Iter: [176341/195500] Loss: 1.897 Acc: 29.62%

 ** Time 14:14

 ** Train ** Epoch: [452/500] Iter: [176732/195500] Loss: 0.782 Acc: 73.75%

 ** Valid ** Epoch: [452/500] Iter: [176732/195500] Loss: 1.937 Acc: 29.01%

 ** Time 14:14

 ** Train ** Epoch: [453/500] Iter: [177123/195500] Loss: 0.737 Acc: 76.25%

 ** Valid ** Epoch: [453/500] Iter: [177123/195500] Loss: 1.92 Acc: 29.32%

 ** Time 14:15

 ** Train ** Epoch: [454/500] Iter: [177514/195500] Loss: 0.678 Acc: 77.5%

 ** Valid ** Epoch: [454/500] Iter: [177514/195500] Loss: 1.892 Acc: 29.59%

 ** Time 14:15

 ** Train ** Epoch: [455/500] Iter: [177905/195500] Loss: 0.605 Acc: 81.25%

 ** Valid ** Epoch: [455/500] Iter: [177905/195500] Loss: 1.956 Acc: 28.73%

 ** Time 14:15

 ** Train ** Epoch: [456/500] Iter: [178296/195500] Loss: 0.824 Acc: 73.75%

 ** Valid ** Epoch: [456/500] Iter: [178296/195500] Loss: 1.922 Acc: 29.91%

 ** Time 14:15

 ** Train ** Epoch: [457/500] Iter: [178687/195500] Loss: 0.999 Acc: 65.0%

 ** Valid ** Epoch: [457/500] Iter: [178687/195500] Loss: 1.926 Acc: 29.39%

 ** Time 14:15

 ** Train ** Epoch: [458/500] Iter: [179078/195500] Loss: 0.774 Acc: 75.0%

 ** Valid ** Epoch: [458/500] Iter: [179078/195500] Loss: 1.879 Acc: 29.72%

 ** Time 14:15

 ** Train ** Epoch: [459/500] Iter: [179469/195500] Loss: 0.631 Acc: 81.25%

 ** Valid ** Epoch: [459/500] Iter: [179469/195500] Loss: 1.906 Acc: 30.38%

 ** Time 14:15

 ** Train ** Epoch: [460/500] Iter: [179860/195500] Loss: 0.686 Acc: 75.0%

 ** Valid ** Epoch: [460/500] Iter: [179860/195500] Loss: 1.908 Acc: 30.0%

 ** Time 14:16

 ** Train ** Epoch: [461/500] Iter: [180251/195500] Loss: 0.871 Acc: 71.25%

 ** Valid ** Epoch: [461/500] Iter: [180251/195500] Loss: 1.926 Acc: 29.29%

 ** Time 14:16

 ** Train ** Epoch: [462/500] Iter: [180642/195500] Loss: 0.736 Acc: 72.5%

 ** Valid ** Epoch: [462/500] Iter: [180642/195500] Loss: 1.882 Acc: 30.12%

 ** Time 14:16

 ** Train ** Epoch: [463/500] Iter: [181033/195500] Loss: 0.657 Acc: 80.0%

 ** Valid ** Epoch: [463/500] Iter: [181033/195500] Loss: 1.921 Acc: 29.95%

 ** Time 14:16

 ** Train ** Epoch: [464/500] Iter: [181424/195500] Loss: 0.859 Acc: 72.5%

 ** Valid ** Epoch: [464/500] Iter: [181424/195500] Loss: 1.967 Acc: 30.08%

 ** Time 14:16

 ** Train ** Epoch: [465/500] Iter: [181815/195500] Loss: 0.762 Acc: 73.75%

 ** Valid ** Epoch: [465/500] Iter: [181815/195500] Loss: 1.946 Acc: 28.88%

 ** Time 14:16

 ** Train ** Epoch: [466/500] Iter: [182206/195500] Loss: 1.056 Acc: 66.25%

 ** Valid ** Epoch: [466/500] Iter: [182206/195500] Loss: 1.911 Acc: 29.43%

 ** Time 14:16

 ** Train ** Epoch: [467/500] Iter: [182597/195500] Loss: 0.646 Acc: 70.0%

 ** Valid ** Epoch: [467/500] Iter: [182597/195500] Loss: 1.905 Acc: 29.57%

 ** Time 14:17

 ** Train ** Epoch: [468/500] Iter: [182988/195500] Loss: 0.804 Acc: 70.0%

 ** Valid ** Epoch: [468/500] Iter: [182988/195500] Loss: 1.883 Acc: 30.07%

 ** Time 14:17

 ** Train ** Epoch: [469/500] Iter: [183379/195500] Loss: 0.695 Acc: 80.0%

 ** Valid ** Epoch: [469/500] Iter: [183379/195500] Loss: 1.923 Acc: 29.96%

 ** Time 14:17

 ** Train ** Epoch: [470/500] Iter: [183770/195500] Loss: 0.644 Acc: 77.5%

 ** Valid ** Epoch: [470/500] Iter: [183770/195500] Loss: 1.919 Acc: 30.31%

 ** Time 14:17

 ** Train ** Epoch: [471/500] Iter: [184161/195500] Loss: 0.875 Acc: 72.5%

 ** Valid ** Epoch: [471/500] Iter: [184161/195500] Loss: 1.888 Acc: 30.98%

 ** Time 14:17

 ** Train ** Epoch: [472/500] Iter: [184552/195500] Loss: 0.831 Acc: 66.25%

 ** Valid ** Epoch: [472/500] Iter: [184552/195500] Loss: 1.863 Acc: 30.43%

 ** Time 14:17

 ** Train ** Epoch: [473/500] Iter: [184943/195500] Loss: 0.853 Acc: 71.25%

 ** Valid ** Epoch: [473/500] Iter: [184943/195500] Loss: 1.886 Acc: 29.74%

 ** Time 14:17

 ** Train ** Epoch: [474/500] Iter: [185334/195500] Loss: 0.639 Acc: 80.0%

 ** Valid ** Epoch: [474/500] Iter: [185334/195500] Loss: 1.944 Acc: 28.66%

 ** Time 14:17

 ** Train ** Epoch: [475/500] Iter: [185725/195500] Loss: 0.609 Acc: 82.5%

 ** Valid ** Epoch: [475/500] Iter: [185725/195500] Loss: 1.901 Acc: 29.53%

 ** Time 14:18

 ** Train ** Epoch: [476/500] Iter: [186116/195500] Loss: 0.644 Acc: 76.25%

 ** Valid ** Epoch: [476/500] Iter: [186116/195500] Loss: 1.898 Acc: 30.11%

 ** Time 14:18

 ** Train ** Epoch: [477/500] Iter: [186507/195500] Loss: 0.902 Acc: 70.0%

 ** Valid ** Epoch: [477/500] Iter: [186507/195500] Loss: 1.911 Acc: 29.08%

 ** Time 14:18

 ** Train ** Epoch: [478/500] Iter: [186898/195500] Loss: 0.748 Acc: 75.0%

 ** Valid ** Epoch: [478/500] Iter: [186898/195500] Loss: 1.934 Acc: 29.44%

 ** Time 14:18

 ** Train ** Epoch: [479/500] Iter: [187289/195500] Loss: 0.804 Acc: 72.5%

 ** Valid ** Epoch: [479/500] Iter: [187289/195500] Loss: 1.885 Acc: 29.44%

 ** Time 14:18

 ** Train ** Epoch: [480/500] Iter: [187680/195500] Loss: 0.896 Acc: 68.75%

 ** Valid ** Epoch: [480/500] Iter: [187680/195500] Loss: 1.903 Acc: 29.51%

 ** Time 14:18

 ** Train ** Epoch: [481/500] Iter: [188071/195500] Loss: 0.69 Acc: 77.5%

 ** Valid ** Epoch: [481/500] Iter: [188071/195500] Loss: 1.904 Acc: 29.76%

 ** Time 14:18

 ** Train ** Epoch: [482/500] Iter: [188462/195500] Loss: 0.652 Acc: 75.0%

 ** Valid ** Epoch: [482/500] Iter: [188462/195500] Loss: 1.885 Acc: 30.56%

 ** Time 14:19

 ** Train ** Epoch: [483/500] Iter: [188853/195500] Loss: 0.615 Acc: 80.0%

 ** Valid ** Epoch: [483/500] Iter: [188853/195500] Loss: 1.897 Acc: 29.47%

 ** Time 14:19

 ** Train ** Epoch: [484/500] Iter: [189244/195500] Loss: 0.555 Acc: 81.25%

 ** Valid ** Epoch: [484/500] Iter: [189244/195500] Loss: 1.874 Acc: 30.06%

 ** Time 14:19

 ** Train ** Epoch: [485/500] Iter: [189635/195500] Loss: 0.66 Acc: 80.0%

 ** Valid ** Epoch: [485/500] Iter: [189635/195500] Loss: 1.879 Acc: 31.32%

 ** Time 14:19

 ** Train ** Epoch: [486/500] Iter: [190026/195500] Loss: 0.762 Acc: 71.25%

 ** Valid ** Epoch: [486/500] Iter: [190026/195500] Loss: 1.864 Acc: 31.63%

 ** Time 14:19

 ** Train ** Epoch: [487/500] Iter: [190417/195500] Loss: 0.872 Acc: 67.5%

 ** Valid ** Epoch: [487/500] Iter: [190417/195500] Loss: 1.907 Acc: 28.9%

 ** Time 14:19

 ** Train ** Epoch: [488/500] Iter: [190808/195500] Loss: 0.686 Acc: 72.5%

 ** Valid ** Epoch: [488/500] Iter: [190808/195500] Loss: 1.937 Acc: 29.52%

 ** Time 14:19

 ** Train ** Epoch: [489/500] Iter: [191199/195500] Loss: 0.798 Acc: 72.5%

 ** Valid ** Epoch: [489/500] Iter: [191199/195500] Loss: 1.895 Acc: 30.3%

 ** Time 14:20

 ** Train ** Epoch: [490/500] Iter: [191590/195500] Loss: 0.808 Acc: 72.5%

 ** Valid ** Epoch: [490/500] Iter: [191590/195500] Loss: 1.96 Acc: 28.42%

 ** Time 14:20

 ** Train ** Epoch: [491/500] Iter: [191981/195500] Loss: 0.895 Acc: 70.0%

 ** Valid ** Epoch: [491/500] Iter: [191981/195500] Loss: 1.914 Acc: 29.67%

 ** Time 14:20

 ** Train ** Epoch: [492/500] Iter: [192372/195500] Loss: 0.784 Acc: 73.75%

 ** Valid ** Epoch: [492/500] Iter: [192372/195500] Loss: 1.883 Acc: 29.69%

 ** Time 14:20

 ** Train ** Epoch: [493/500] Iter: [192763/195500] Loss: 0.652 Acc: 80.0%

 ** Valid ** Epoch: [493/500] Iter: [192763/195500] Loss: 1.923 Acc: 29.8%

 ** Time 14:20

 ** Train ** Epoch: [494/500] Iter: [193154/195500] Loss: 0.928 Acc: 76.25%

 ** Valid ** Epoch: [494/500] Iter: [193154/195500] Loss: 1.882 Acc: 29.92%

 ** Time 14:20

 ** Train ** Epoch: [495/500] Iter: [193545/195500] Loss: 0.683 Acc: 73.75%

 ** Valid ** Epoch: [495/500] Iter: [193545/195500] Loss: 1.908 Acc: 29.48%

 ** Time 14:20

 ** Train ** Epoch: [496/500] Iter: [193936/195500] Loss: 0.636 Acc: 77.5%

 ** Valid ** Epoch: [496/500] Iter: [193936/195500] Loss: 1.9 Acc: 29.96%

 ** Time 14:21

 ** Train ** Epoch: [497/500] Iter: [194327/195500] Loss: 0.851 Acc: 70.0%

 ** Valid ** Epoch: [497/500] Iter: [194327/195500] Loss: 1.918 Acc: 29.84%

 ** Time 14:21

 ** Train ** Epoch: [498/500] Iter: [194718/195500] Loss: 0.674 Acc: 72.5%

 ** Valid ** Epoch: [498/500] Iter: [194718/195500] Loss: 1.904 Acc: 29.46%

 ** Time 14:21

 ** Train ** Epoch: [499/500] Iter: [195109/195500] Loss: 0.616 Acc: 75.0%

 ** Valid ** Epoch: [499/500] Iter: [195109/195500] Loss: 1.938 Acc: 28.75%

 ** Time 14:21

 ** Train ** Epoch: [500/500] Iter: [195500/195500] Loss: 0.872 Acc: 66.25%

 ** Valid ** Epoch: [500/500] Iter: [195500/195500] Loss: 1.906 Acc: 31.68%

Finished training... Time:  70.58
Lenght of results collected
+-------------+-------------+-------------+------------+
|    Model    | Epoch Train | Epoch Valid | Iter Train |
+-------------+-------------+-------------+------------+
| Single Deep |     500     |     500     |   195500   |
+-------------+-------------+-------------+------------+
Current set up
[ALERT]: Path to results (this may overwrite /home/ec2-user/Single_vs_Ensemble_of_NNs/results
[ALERT]: Path to checkpoint (this may overwrite None
Do you want to continue? [Y/n]: 